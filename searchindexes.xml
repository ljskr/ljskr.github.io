<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title/><url>/archives/_index.en-us/</url><categories/><tags/><content type="html">    </content></entry><entry><title>About</title><url>/about/</url><categories/><tags/><content type="html">    </content></entry><entry><title>Debian 图形和文本模式切换方法</title><url>/post/linux/console_mode/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>graphical</tag></tags><content type="html">  Debian 图形和文本模式切换方法 查看当前的默认模式。 multi-user 为多用户命令行模式（文本模式）， graphical 为图形界面模式。
1 systemctl get-default 设置启动时默认为多用户命令行模式（文本模式）：
1 systemctl set-default multi-user.target 设置启动时默认为图形界面模式（GUI）：
1 systemctl set-default graphical.target 立即进入多用户文本格式：
1 systemctl isolate multi-user 立即进入图形界面模式：
1 systemctl isolate graphical   </content></entry><entry><title>Linux 下查看 Smart 方法</title><url>/post/linux/smart/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>smart</tag></tags><content type="html">  Linux 下查看 Smart 方法 Linux 使用 smartctl
1 2 3 4 5 6 7 8 # 显示磁盘信息，查看磁盘是否支持 smart 。结果位于输出信息的后两行。 smartctl -i /dev/sda # 显示磁盘健康状态。PASSED 为良好； FAILED 为磁盘有问题，需要尽快更换。 smartctl -H /dev/sda # 详细列出 smart 属性和值。 smartctl -A /dev/sda ESXi 1 2 3 4 5 6 7 # 列出 nvme 设备 esxcli nvme device list # 列出磁盘设备 esxcli storage core device list # 列出 smart 属性和值。 esxcli storage core device smart get -d &amp;lt;device&amp;gt;   </content></entry><entry><title>docker 部署 Kafka</title><url>/post/docker/app/kafka/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>kafka</tag></tags><content type="html"><![CDATA[  docker 部署 Kafka docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 version: &#39;2&#39; services: zookeeper: image: confluentinc/cp-zookeeper:latest environment: ZOOKEEPER_CLIENT_PORT: 2181 ZOOKEEPER_TICK_TIME: 2000 ports: - 22181:2181 kafka: image: confluentinc/cp-kafka:latest depends_on: - zookeeper ports: - 29092:29092 - 9092:9092 environment: KAFKA_BROKER_ID: 1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 # 这里需要有一个是主机的ip KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://192.168.3.62:29092 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1 kafka-ui: image: provectuslabs/kafka-ui:latest depends_on: - kafka ports: - 28080:8080 environment: DYNAMIC_CONFIG_ENABLED: &#34;true&#34; KAFKA_CLUSTERS_0_NAME: local KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092   ]]></content></entry><entry><title>docker 部署 MongoDB</title><url>/post/docker/app/mongodb/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>mongodb</tag></tags><content type="html">  docker 部署 MongoDB docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 version: &amp;#39;3&amp;#39; services: mongo: image: mongo #restart: always ports: - 27017:27017 environment: MONGO_INITDB_ROOT_USERNAME: root MONGO_INITDB_ROOT_PASSWORD: 123456 volumes: - db_data:/data/db mongo-express: image: mongo-express #restart: always ports: - 8081:8081 environment: # default login: admin / pass ME_CONFIG_MONGODB_ADMINUSERNAME: root ME_CONFIG_MONGODB_ADMINPASSWORD: 123456 ME_CONFIG_MONGODB_URL: mongodb://root:123456@mongo:27017/ volumes: db_data:   </content></entry><entry><title>docker 部署 MinIO</title><url>/post/docker/app/minio/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>minio</tag></tags><content type="html"><![CDATA[  docker 部署 MinIO docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 version: &#39;3&#39; services: minio: image: minio/minio environment: - MINIO_VOLUMES=&#34;/data&#34; - MINIO_ROOT_USER=minioadmin - MINIO_ROOT_PASSWORD=minioadmin ports: - 9000:9000 - 9090:9090 volumes: - ./data:/data command: &#34;minio server --console-address \&#34;:9090\&#34;&#34;   ]]></content></entry><entry><title>Mysql windows 绿色版安装指南</title><url>/post/software/mysql_portable_install/</url><categories><category>software</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[  Mysql windows 绿色版安装指南 1. 下载并解压 从 mysql 官网下载 zip 格式（非安装版）的程序包，并解压出来。
2. 初始化服务器数据 打开 cmd ，进到解压出来的 mysql 目录
1 2 3 4 5 6 7 cd mysql/bin # 初始化数据。root 无密码 mysqld --initialize-insecure # 初始化数据。root 有密码，初始密码会打印到控制台中。 mysqld --initialize --console 3. 启动服务器 1 2 3 4 cd mysql/bin # 加 --console 会把日志信息打印到控制台中。否则日志需要查看日志文件。建议加上该参数。 mysqld --console 4. 使用客户端连接 1 2 3 4 5 6 7 cd mysql/bin # root 无密码时 mysql -u root # root 有密码时 mysql -u root -p 5. 修改 root 密码 使用 root 账号连接上之后，运行如下命令
1 mysql&gt; alter user root@&#39;localhost&#39; identified by &#39;123456&#39;; 其中后面的 &lsquo;123456&rsquo; 为密码，按实际需要进行修改。
6. 创建新用户(可选) 按需要创建新用户
1 2 3 create user test1@&#39;%&#39; identified by &#39;123456&#39;; Grant all on *.* to test1@&#39;%&#39;; flush privileges; 7. 以系统服务方式运行 7.1 安装服务 1 2 3 cd mysql/bin mysqld --install 7.2 启动服务 1 net start mysql 7.3 停止服务 1 net stop mysql 7.4 删除服务 1 2 3 4 sc delete mysql # 或 mysqld --remove   ]]></content></entry><entry><title>docker 部署 gitea</title><url>/post/docker/app/gitea/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>gitea</tag></tags><content type="html"><![CDATA[  docker 部署 gitea docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 version: &#34;3.7&#34; services: web: image: gitea/gitea:latest restart: always ports: - &#34;3000:3000&#34; - &#34;8022:22&#34; volumes: - git_data:/data environment: - TZ=Asia/Shanghai - GITEA__database__DB_TYPE=postgres - GITEA__database__HOST=db:5432 - GITEA__database__NAME=gitea - GITEA__database__USER=gitea - GITEA__database__PASSWD=gitea depends_on: - db db: image: postgres:alpine restart: always volumes: - db_data:/var/lib/postgresql/data # ports: # - &#34;5432:5432&#34; environment: # default user name: postgres - POSTGRES_USER=gitea - POSTGRES_PASSWORD=gitea - POSTGRES_DB=gitea - TZ=Asia/Shanghai adminer: image: adminer restart: always ports: - &#34;8023:8080&#34; volumes: git_data: db_data:   ]]></content></entry><entry><title>docker 部署 SonarQube</title><url>/post/docker/app/sonarqube/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>SonarQube</tag></tags><content type="html"><![CDATA[  docker 部署 SonarQube docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 version: &#34;3.7&#34; services: sonarqube: image: &#34;sonarqube:lts-community&#34; restart: always ports: - &#34;9000:9000&#34; environment: - TZ=Asia/Shanghai volumes: # 数据目录。h2数据库文件和es索引 - sonarqube-data:/opt/sonarqube/data # 日志目录。 - sonarqube-logs:/opt/sonarqube/logs # 第三方插件 - sonarqube-extensions:/opt/sonarqube/extensions # 配置文件 # - sonarqube-conf:/opt/sonarqube/conf volumes: sonarqube-data: sonarqube-logs: sonarqube-extensions: # sonarqube-conf: 1 说明 所有数据存储在 /opt/sonarqube 中。 运行后，默认用户名和密码均为 admin 。 首次登录系统会要求修改密码。 常用插件: sonar-pdfreport-plugin : 用于生成 pdf 报告。把对应的插件 jar 包放到 /opt/sonarqube/extensions/plugins 目录下，重启应用即可使用。   ]]></content></entry><entry><title>docker 部署 nexus3</title><url>/post/docker/app/nexus/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>nexus3</tag></tags><content type="html"><![CDATA[  docker 部署 nexus3 docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 version: &#34;3.7&#34; services: nexus: image: &#39;sonatype/nexus3&#39; restart: always ports: - &#39;8081:8081&#39; environment: - TZ=Asia/Shanghai volumes: - nexus-data:/nexus-data volumes: nexus-data: 1 说明 所有数据存储在 /nexus-data 中。 运行后，默认用户名为 admin ，默认密码需要查看 /nexus-data/admin.password 文件。   ]]></content></entry><entry><title>docker 部署 jenkins</title><url>/post/docker/app/jenkins/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>jenkins</tag></tags><content type="html"><![CDATA[  docker 部署 jenkins docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 version: &#34;3.7&#34; services: jenkins: image: &#39;jenkins/jenkins:lts-alpine&#39; restart: always ports: - &#39;8080:8080&#39; #- &#39;50000:50000&#39; environment: - TZ=Asia/Shanghai volumes: - jenkins-data:/var/jenkins_home java11-node1: image: &#39;gulucat/java-agent:jdk11&#39; restart: always volumes: - /home/deploy/dist:/dist - maven_repository:/root/.m2 environment: - TZ=Asia/Shanghai volumes: jenkins-data: maven_repository: 1 备份和升级说明 直接备份 /var/jenkins_home 中的所有内容即可。 升级时，直接把旧镜像删除，再使用新镜像创建容器即可。（数据已挂载到容器外） 2 任务节点制作示例 vi agent_jdk11.dockerfile
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 FROM maven:3-jdk-11 RUN sed -i &#34;s@http://deb.debian.org@http://mirrors.tuna.tsinghua.edu.cn@g&#34; /etc/apt/sources.list \ &amp;&amp; sed -i &#34;s@http://security.debian.org@http://mirrors.tuna.tsinghua.edu.cn@g&#34; /etc/apt/sources.list \ &amp;&amp; apt-get update \ &amp;&amp; apt-get install -y --no-install-recommends \ ssh \ curl \ vim-tiny \ &amp;&amp; rm -rf /var/lib/apt/lists/* \ &amp;&amp; mkdir /run/sshd RUN echo &#34;export PATH=/usr/local/openjdk-11/bin:\$PATH&#34; &gt;&gt; /root/.bashrc \ &amp;&amp; echo &#34;export JAVA_HOME=/usr/local/openjdk-11&#34; &gt;&gt; /root/.bashrc \ &amp;&amp; mkdir -p /home/jenkins \ &amp;&amp; mkdir /root/.ssh # jenkins 里创建一对密钥，把公钥提出来，放到节点镜像中，实现免密控制。 COPY ./certs/id_ed25519.pub /root/.ssh/authorized_keys CMD [&#34;/usr/sbin/sshd&#34;, &#34;-D&#34;] 1 docker build -f agent_jdk11.dockerfile -t gulucat/java-agent:jdk11 .   ]]></content></entry><entry><title>docker 部署 oracle 19c</title><url>/post/docker/app/oracle_19c/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>oracle19c</tag></tags><content type="html"><![CDATA[  docker 部署 oracle 19c docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 version: &#34;3.7&#34; services: oracle: image: &#39;registry.cn-hangzhou.aliyuncs.com/zhuyijun/oracle:19c&#39; restart: always ports: - &#39;1521:1521&#39; - &#39;5500:5500&#39; environment: - ORACLE_SID=ORCLCDB - ORACLE_PDB=ORCLPDB1 - ORACLE_PWD=123456 - ORACLE_EDITION=standard - ORACLE_CHARACTERSET=AL32UTF8 volumes: - db_data:/opt/oracle/oradata volumes: db_data: 1 2 3 4 5 6 初次运行时安装的时间比较久，需要耐心等待。 登录设置: - SID: ORCLCDB 或者 Service Name: ORCLCDB 或者 Service Name: ORCLPDB1 - 用户名密码: sys/123456(SYSDBA) 或者 system/123456(Normal) - 默认表空间为: SYSTEM   ]]></content></entry><entry><title>docker 部署 microsoft sql server</title><url>/post/docker/app/mssqlserver/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>mssqlserver</tag></tags><content type="html"><![CDATA[  docker 部署 microsoft sql server docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 version: &#34;3.7&#34; services: sqlserver: image: &#39;mcr.microsoft.com/mssql/server:2019-latest&#39; restart: always ports: - &#39;1433:1433&#39; environment: # default user name: sa - SA_PASSWORD=Password - ACCEPT_EULA=y #volumes: 1 创建数据库注意事项 由于 docker 版 SqlServer 没有管理端，创建数据库一般是通过数据库客户端(如 Navicat, DBeaver )来进行操作，此时如果没有指定数据库字符集，很有可能会产生中文乱码。
可以使用如下脚本进行创建指定字符集的数据库，防止中文乱码。
1 CREATE DATABASE XXX COLLATE Chinese_PRC_CI_AS; 若需要使用繁体中文，字符集可以为
1 CREATE DATABASE XXX COLLATE Chinese_Traditional_Pinyin_100_CS_AI;   ]]></content></entry><entry><title>docker 部署 openldap</title><url>/post/docker/app/openldap/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>openldap</tag></tags><content type="html"><![CDATA[  docker 部署 openldap docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 version: &#39;3.7&#39; services: ldap: # openldap 服务器 image: osixia/openldap:latest restart: always volumes: - ldap_config:/etc/ldap/slapd.d - ldap_data:/var/lib/ldap # - ldap_certs:/container/service/slapd/assets/certs ports: # port 636 for TLS - &#34;389:389&#34; # - &#34;636:636&#34; environment: - TZ=Asia/Shanghai - LDAP_DOMAIN=example.org - LDAP_ORGANISATION=Example Inc. - LDAP_ADMIN_PASSWORD=admin - LDAP_CONFIG_PASSWORD=config - LDAP_READONLY_USER=true - LDAP_READONLY_USER_USERNAME=readonly - LDAP_READONLY_USER_PASSWORD=readonly - LDAP_TLS=false # - LDAP_TLS_CRT_FILENAME=ldap.crt # - LDAP_TLS_KEY_FILENAME=ldap.key # - LDAP_TLS_DH_PARAM_FILENAME=dhparam.pem # - LDAP_TLS_CA_CRT_FILENAME=ca.crt # lam: # # 账号管理（管理员使用） # image: ldapaccountmanager/lam:latest # # restart: always # ports: # - &#34;8100:80&#34; # environment: # - TZ=Asia/Shanghai ldapadmin: # 另一个账号管理的工具 image: osixia/phpldapadmin:latest # restart: always ports: - &#34;8443:443&#34; environment: - TZ=Asia/Shanghai - PHPLDAPADMIN_LDAP_HOSTS=ldap volumes: - ldapadmin_data:/var/www/phpldapadmin ssp: # 自助密码服务（普通用户使用） image: tiredofit/self-service-password:latest restart: always ports: - &#34;8200:80&#34; environment: - TZ=Asia/Shanghai - LDAP_SERVER=ldap://ldap - LDAP_STARTTLS=false - LDAP_BINDDN=cn=admin,dc=example,dc=org - LDAP_BINDPASS=admin - LDAP_BASE_SEARCH=dc=example,dc=org - LDAP_LOGIN_ATTRIBUTE=uid - LDAP_FULLNAME_ATTRIBUTE=cn volumes: ldap_config: ldap_data: #ldap_certs: ldapadmin_data: 1. 服务可用性验证 管理员使用 ldapsearch 验证（需要安装 ldap-utils 包）
1 2 3 4 5 6 7 8 9 10 ldapsearch -x -LLL -H ldap:/// -b dc=example,dc=org -D cn=admin,dc=example,dc=org -W dn # -x: 使用简单认证方式 # -H: ldap url # -b: searchbase 搜索路径 # -D: binddn ，可以理解为有权限的用户 # -W: 使用交互的方式输入密码。非交互方式使用 -w &lt;password&gt; # 最后的 dn 表示只搜索(过滤) dn 属性 ldapsearch -x -LLL -H ldap:/// -b cn=config -D cn=admin,cn=config -W dn # 参数解释同上。-b cn=config 表示搜索 config 的内容。config admin 的密码见 LDAP_CONFIG_PASSWORD 。 普通用户验证密码
1 2 3 4 5 ldapsearch -x -LLL -H ldap:/// -b cn=test,dc=example,dc=org -D cn=test,dc=example,dc=org -W # 参数解释同上。由于普通用户权限有限，所以 -b 只能看他自己，-b 范围太大时，会提供找不到对象。 ldapwhoami -x -H ldap:/// -D cn=test,dc=example,dc=org -W # 另一个验证密码的方式。此命令不需要指定 searchbase ，更快捷，不过能获取的信息较少。 2. phpldapadmin 个性化配置 通过调整 phpldapadmin 的配置，可以做自定义设定。 参考 https://phpldapadmin.sourceforge.net/wiki/index.php/Config.php 修改 /var/www/phpldapadmin/config/config.php 文件
1 2 3 4 # 先修改文件属性为可读写。每次容器启动之后，该文件都会被重置为只读。 chmod 600 /var/www/phpldapadmin/config/config.php vi /var/www/phpldapadmin/config/config.php 自定义树的显示方式 : 在配置文件的末尾添加下列配置项
1 2 // 数组里的显示方式列表，如果前一种方式里指定的属性不存在，则会尝试使用下一种显示方式。 原始默认值为 &#39;%rdn&#39; $config-&gt;custom-&gt;appearance[&#39;tree_display_format&#39;] = array(&#39;%uidNumber - %displayName (%rdn)&#39;, &#39;%displayName (%rdn)&#39;, &#39;%rdn&#39;); 自定义 uidNumber 的初始值 : 在配置文件的末尾添加下列配置项
1 2 // uidNumber 从 10001 开始递增。 原始默认值为 1000 。 $servers-&gt;setValue(&#39;auto_number&#39;, &#39;min&#39;, array(&#39;uidNumber&#39;=&gt;10001, &#39;gidNumber&#39;=&gt;1000));   ]]></content></entry><entry><title>docker 部署 consul</title><url>/post/docker/app/consul/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>consul</tag></tags><content type="html"><![CDATA[  docker 部署 consul 单节点
docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 version: &#39;3.7&#39; services: consul: image: consul # restart: always ports: - &#34;8500:8500&#34; command: &#34;agent -server -client 0.0.0.0 -bootstrap -node consul1 -ui -bind 0.0.0.0&#34; 多节点
docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: &#39;3.7&#39; services: consul1: image: consul # restart: always ports: - &#34;8500:8500&#34; command: &#34;agent -server -client 0.0.0.0 -bootstrap-expect 3 -node consul1 -ui -bind 0.0.0.0&#34; consul2: image: consul # restart: always command: &#34;agent -server -client 0.0.0.0 -retry-join=consul1 -node consul2 -bind 0.0.0.0&#34; consul3: image: consul # restart: always command: &#34;agent -server -client 0.0.0.0 -retry-join=consul1 -node consul3 -bind 0.0.0.0&#34;   ]]></content></entry><entry><title>docker 部署 etcd</title><url>/post/docker/app/etcd/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>etcd</tag></tags><content type="html"><![CDATA[  docker 部署 etcd docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 version: &#34;3.7&#34; services: etcd: image: bitnami/etcd:latest # restart: always ports: - &#34;2379:2379&#34; - &#34;2380:2380&#34; environment: - ALLOW_NONE_AUTHENTICATION=yes - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379 - TZ=Asia/Shanghai # etcdkeeper: # image: evildecay/etcdkeeper # ports: # - &#34;8080:8080&#34;   ]]></content></entry><entry><title>docker 部署 clickhouse server</title><url>/post/docker/app/clickhouse/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>clickhouse</tag></tags><content type="html"><![CDATA[  docker 部署 clickhouse server docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 version: &#34;3.7&#34; services: clickhouse-server: # 默认用户名: default ，密码通过配置文件来设置。 image: yandex/clickhouse-server:latest # restart: always ports: - &#34;8123:8123&#34; - &#34;9000:9000&#34; ulimits: nofile: soft: 262144 hard: 262144 # 时区的环境变量在该镜像中无效。 #environment: # TZ: &#34;Asia/Shanghai&#34; volumes: - db_data:/var/lib/clickhouse # 用户自定义配置 - ./users.d:/etc/clickhouse-server/users.d:ro # 初始脚本 - ./initdb.d:/docker-entrypoint-initdb.d:ro volumes: db_data: 创建一个 users.d 目录，存放用户自定义配置，示例为配置默认用户的登录密码： default-password.xml
users.d/default-password.xml 示例：
1 2 3 4 5 6 7 &lt;yandex&gt; &lt;users&gt; &lt;default&gt; &lt;password&gt;123456&lt;/password&gt; &lt;/default&gt; &lt;/users&gt; &lt;/yandex&gt; 创建一个 initdb.d 目录，存放自定义的初始化脚本。示例为创建一个数据库
initdb.d/init-db.sh 示例：
1 2 3 4 5 6 #!/bin/bash set -e clickhouse client --password 123456 -n &lt;&lt;-EOSQL CREATE DATABASE IF NOT EXISTS my_database; EOSQL   ]]></content></entry><entry><title>docker 部署 RabbitMQ</title><url>/post/docker/app/rabbitmq/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>RabbitMQ</tag></tags><content type="html"><![CDATA[  docker 部署 RabbitMQ docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 version: &#34;3.7&#34; services: rabbitmq: image: rabbitmq:alpine restart: always environment: # default username/password: guest / guest RABBITMQ_DEFAULT_USER: &#34;rabbitmq&#34; RABBITMQ_DEFAULT_PASS: &#34;123456&#34; # RABBITMQ_DEFAULT_VHOST: &#34;RabbitMq&#34; ports: # 5672 client端通信端口 # 15672 管理界面ui端口。管理插件默认关闭，如要打开，则需要进入容器内运行 rabbitmq-plugins enable rabbitmq_management # 管理端也可以单独启动 rabbitmq:management-alpine 镜像 - &#34;5672:5672&#34; - &#34;15672:15672&#34; # 1883 mqtt通信端口。mqtt插件默认关闭，如要打开，则需要进入容器内运行 rabbitmq-plugins enable rabbitmq_mqtt - &#34;1883:1883&#34; volumes: - rabbitmq_data:/var/lib/rabbitmq volumes: rabbitmq_data:   ]]></content></entry><entry><title>docker 部署 redis</title><url>/post/docker/app/redis/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>redis</tag></tags><content type="html"><![CDATA[  docker 部署 redis docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 version: &#39;3.7&#39; services: redis: image: redis:alpine restart: always ports: - &#34;6379:6379&#34; environment: TZ: &#34;Asia/Shanghai&#34; volumes: - redis_data:/data volumes: redis_data:   ]]></content></entry><entry><title>docker 部署 portainer</title><url>/post/docker/app/portainer/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>portainer</tag></tags><content type="html"><![CDATA[  docker 部署 portainer 官网： https://www.portainer.io https://hub.docker.com/r/portainer/portainer docker 管理工具 web 版，管理员通过浏览器访问 9000 端口进行控制 docker 。
单机版通过 socket 跟主机 docker 进行通信获取信息，运行和挂载命令如下：
1 2 3 docker run -d -p 9000:9000 \ -v /var/run/docker.sock:/var/run/docker.sock \ portainer/portainer 集群版未实验，参见其他网上文档。
&mdash; // 2023/03/28 21:32 更新下面内容 //
https://hub.docker.com/r/portainer/portainer-ce 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 version: &#39;3&#39; services: portainer: image: &#39;portainer/portainer-ce&#39; restart: always ports: # - &#39;8000:8000&#39; # - &#39;9443:9443&#39; - &#39;9000:9000&#39; environment: - TZ=Asia/Shanghai volumes: - /var/run/docker.sock:/var/run/docker.sock - portainer_data:/data volumes: portainer_data:   ]]></content></entry><entry><title>docker 部署 registry</title><url>/post/docker/app/registry/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>registry</tag></tags><content type="html">  docker 部署 registry 官网： https://docs.docker.com/registry/ https://docs.docker.com/registry/deploying/ docker 私有仓库，官方出品。
运行方式:
1 2 3 4 5 6 docker run -d \ -p 5000:5000 \ --restart=always \ --name registry \ -v /mnt/registry:/var/lib/registry \ registry 提交到私有仓库示例:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 从Docker Hub官网拉取镜像。 $ docker pull ubuntu:16.04 # 重新打标签，记得加上私有仓库ip和端口。具体含义见 docker 镜像命名方式。 $ docker tag ubuntu:16.04 localhost:5000/my-ubuntu # 提交镜像到私有仓库。 $ docker push localhost:5000/my-ubuntu # 本机可以删除掉缓存的原标签。 $ docker image remove ubuntu:16.04 # 后续拉取镜像可从私有仓库拉取。 $ docker pull localhost:5000/my-ubuntu   </content></entry><entry><title>docker 镜像导出和加载</title><url>/post/docker/docker_save_and_load/</url><categories><category>docker</category></categories><tags><tag>docker</tag></tags><content type="html">  docker 镜像导出和加载 导出一个或多个镜像 1 2 3 4 5 6 7 8 # 把 busybox 镜像导出到 tar 文件中 docker save -o busybox.tar busybox:latest # 一次可以导出多个镜像 docker save -o busybox.tar busybox:1 busybox:2 busybox:3 # 导出镜像并使用 gzip 进行压缩 docker save busybox:latest | gzip &amp;gt; busybox_latest.tar.gz 加载镜像 1 2 3 4 5 # 加载镜像 docker load -i busybox.tar # 加载 gzip 压缩过的镜像 gunzip -c busybox.tar.gz | docker load   </content></entry><entry><title>docker 部署 redmine</title><url>/post/docker/app/redmine/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>redmine</tag></tags><content type="html"><![CDATA[  docker 部署 redmine docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 version: &#34;3.7&#34; services: redmine: image: redmine:5 restart: always ports: - &#34;3000:3000&#34; volumes: - redmine_files:/usr/src/redmine/files environment: - TZ=Asia/Shanghai - REDMINE_DB_POSTGRES=db - REDMINE_DB_PORT=5432 - REDMINE_DB_USERNAME=redmine - REDMINE_DB_PASSWORD=redmine - REDMINE_DB_DATABASE=redmine depends_on: - db healthcheck: test: [&#34;CMD-SHELL&#34;, &#34;curl -f http://127.0.0.1:3000 || exit 1&#34;] interval: 2m timeout: 10s retries: 3 db: image: postgres:alpine restart: always volumes: - db_data:/var/lib/postgresql/data # - ./init.sql:/docker-entrypoint-initdb.d/init.sql # ports: # - &#34;5432:5432&#34; # env_file: # - .env environment: # default user name: postgres - POSTGRES_USER=redmine - POSTGRES_PASSWORD=redmine - POSTGRES_DB=redmine - TZ=Asia/Shanghai healthcheck: test: [&#34;CMD-SHELL&#34;, &#34;pg_isready -U postgres&#34;] interval: 2m timeout: 5s retries: 5 start_period: 1m #adminer: # image: adminer # restart: always # ports: # - &#34;8080:8080&#34; volumes: redmine_files: db_data: db 相关的配置参考 docker 部署 postgresql   ]]></content></entry><entry><title>使用 Python 3 进行反向代理</title><url>/post/python/python_proxy_server/</url><categories><category>python</category></categories><tags><tag>python</tag><tag>proxy</tag></tags><content type="html"><![CDATA[  使用 Python 3 进行反向代理 使用 python 3.x 快速启动一个反向代理服务。 (python 版本需要大于 3.7)
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import asyncio import sys # 转发客户端到服务器的流量 async def trans_c2s(reader, r_writer): while not reader.at_eof(): data = await reader.read(256) r_writer.write(data) await r_writer.drain() r_writer.close() # 转发服务器到客户端的流量 async def trans_s2c(r_reader, writer): while not r_reader.at_eof(): r_data = await r_reader.read(256) writer.write(r_data) await writer.drain() writer.close() async def handle(reader, writer): addr = writer.get_extra_info(&#39;peername&#39;) print(f&#39;&gt; Receive connection: {addr}!&#39;) # 启动反向代理连接 r_reader, r_writer = await asyncio.open_connection(r_addr, r_port) ret = await asyncio.gather( trans_c2s(reader, r_writer), trans_s2c(r_reader, writer) ) print(f&#39;&gt; Close connection: {addr} !&#39;) # 主服务器进程 async def main(): server = await asyncio.start_server( handle, &#34;0.0.0.0&#34;, port) addr = server.sockets[0].getsockname() print(f&#39;Serving on {addr}&#39;) async with server: await server.serve_forever() if __name__ == &#34;__main__&#34;: if len(sys.argv) &lt; 4: print(&#39;&gt; usage: python proxy.py [your_port] [romote_addr] [remote_port]&#39;) exit(1) port = int(sys.argv[1]) r_addr = sys.argv[2] r_port = int(sys.argv[3]) asyncio.run(main()) 参考地址: https://www.cnblogs.com/Mz1-rc/p/17191643.html|   ]]></content></entry><entry><title>Python 3 启动 http server</title><url>/post/python/python_http_server/</url><categories><category>python</category></categories><tags><tag>python</tag><tag>http</tag></tags><content type="html">  Python 3 启动 http server 使用 python 3.x 快速启动一个 http server
1 2 3 4 5 6 7 8 9 10 11 # 在当前目录下启动 http server ，端口号为 8000 python -m http.server # 指定端口号 python -m http.server 8080 # 指定目录: 使用 -d 参数 python -m http.server -d /www-data/ # 指定监听地址: 使用 --bind 参数 python -m http.server --bind 127.0.0.1 参考地址: https://docs.python.org/3/library/http.server.html|   </content></entry><entry><title>Debian 11 新系统安装配置指南</title><url>/post/linux/debian_11_install/</url><categories><category>linux</category></categories><tags><tag>linux</tag></tags><content type="html"><![CDATA[  Debian 11 新系统安装配置指南 以 Linux 新系统安装配置清单 为蓝本，针对 Debian 11 系统进行相应的调整。
一、 bash 配置 /root/.bashrc
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 PS1=&#39;\n${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ &#39; # If this is an xterm set the title to user@host:dir case &#34;$TERM&#34; in xterm*|rxvt*) PS1=&#34;\[\e]0;${debian_chroot:+($debian_chroot)}\u@\h \a\]$PS1&#34; ;; *) ;; esac export LS_OPTIONS=&#39;--color=auto&#39; eval &#34;`dircolors`&#34; alias ls=&#39;ls $LS_OPTIONS&#39; alias ll=&#39;ls $LS_OPTIONS -lh&#39; alias rm=&#39;rm -i&#39; alias cp=&#39;cp -i&#39; alias mv=&#39;mv -i&#39; 二、 公共组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 备份原来的 sources.list DATE_TIME_NOW=`date +&#34;%Y%m%d_%H%M&#34;` mv /etc/apt/sources.list /etc/apt/sources.list.bak_${DATE_TIME_NOW} # 设置 sources.list ，使用清华的镜像源 cat &lt;&lt; \EOF &gt; /etc/apt/sources.list deb https://mirrors.tuna.tsinghua.edu.cn/debian bullseye main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian bullseye-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free EOF # 安装常用工具 apt install -y \ curl \ gnupg2 \ vim \ tmux \ nfs-common \ zip \ unzip \ unar \ p7zip-full \ fonts-noto-cjk \ fonts-wqy-microhei \ fonts-wqy-zenhei # vim 设置，写到 vimrc.local 中，避免更新时冲突。 cat &lt;&lt; \EOF &gt; /etc/vim/vimrc.local &#34; 显示行号 set nu &#34; 设置 yaml 文件缩进 autocmd FileType yaml,yml setlocal ts=2 sts=2 sw=2 expandtab indentkeys-=&lt;:&gt; EOF 三、 python 环境 1. pip 私服
/etc/pip.conf
1 2 3 4 5 6 7 [global] # 豆瓣源 # index-url = https://pypi.douban.com/simple # 清华源 index-url = https://pypi.tuna.tsinghua.edu.cn/simple # 阿里云源 # index-url = https://mirrors.aliyun.com/pypi/simple 使用方法参考 Python 设置 PYPI 私服说明 2. 虚拟环境设置
安装虚拟环境工具
1 apt install python3-virtualenvwrapper 配置 /etc/bash.bashrc
1 2 3 4 5 6 7 8 9 # 加载 virtualenvwrapper 脚本 if [ -f /usr/share/virtualenvwrapper/virtualenvwrapper.sh ]; then export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 export WORKON_HOME=&#39;~/.virtualenvs&#39; source /usr/share/virtualenvwrapper/virtualenvwrapper.sh fi # 让 pip 使用系统证书 export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt 使用方法参考 virtualenvwrapper 安装配置说明 四、 docker 环境 运行以下命令进行安装
1 apt install docker.io docker-compose   ]]></content></entry><entry><title>SwitchyOmega 安装使用说明</title><url>/post/software/switchyomega_install/</url><categories><category>software</category></categories><tags><tag>proxy</tag><tag>switchyomega</tag></tags><content type="html">  SwitchyOmega 安装使用说明 SwitchyOmega 是浏览器上的一个插件，主要用于配置代理。火狐和谷歌浏览器上都有该插件。
推荐使用 Microsoft Edge 浏览器，该浏览器使用了谷歌内核，并且在国内可以正常打开扩展程序市场。
本文以 Edge 浏览器为例，介绍该插件的安装配置方式。
1. 安装 打开 Edge 浏览器，在新标签页中输入 edge://extensions 打开扩展管理标签页，点击 “获取 Microsoft Edge 扩展” ，跳转到扩展程序市场。
在微软扩展程序市场中搜索 SwitchyOmega ，下载安装 Proxy SwitchyOmega 。
2. 配置 待补充
  </content></entry><entry><title>弱密码检测</title><url>/post/software/wp_check/</url><categories><category>software</category></categories><tags><tag>weakpassword</tag><tag>linux</tag><tag>debian</tag></tags><content type="html"><![CDATA[  弱密码检测 本文主要介绍如何在 Debian 下使用工具检测密码强度。
1. 使用 cracklib-check cracklib-check 是一个弱密码检测工具。如果密码是弱密码，会给出原因；否则返回 OK 。
若没有命令 cracklib-check，则先安装 cracklib 1 apt install libcrack2 检测是否是弱密码 1 2 3 4 5 # 交互式。直接运行 cracklib-check ，然后输入一行密码，回车确认。可以多次输入密码，退出按 Ctrl + D 。 cracklib-check # 非交互式。缺点：在 shell 的历史记录中能看到这条命令，容易泄漏密码。 echo &#34;123456&#34; | cracklib-check 2. 使用 pwscore pwscore 是给密码强度打分工具，分值越高，密码强度越强。
使用方式 1 2 3 4 5 # 交互式。直接运行 pwscore ，然后输入一行密码，回车确认。一次只给一个密码打分。 pwscore # 非交互式。缺点：在 shell 的历史记录中能看到这条命令，容易泄漏密码。 echo &#34;12345678&#34; | pwscore   ]]></content></entry><entry><title>Code Server 安装指南</title><url>/post/software/code_server_install/</url><categories><category>software</category></categories><tags><tag>vscode</tag></tags><content type="html">  Code Server 安装指南 本文以 Debian 11 为例，进行安装 Code Server 。
1. 简介 Code Server 是 VS Code 的 Web 版本，可以随时随地通过浏览器获得一个 VS Code 环境。
官网地址:
github - code-server coder - 安装指南 2. 安装 从 github 上下载最新的 code-server 安装包，这里以 4.11.0 版本为例。
1 curl -fOL https://github.com/coder/code-server/releases/download/v4.11.0/code-server_4.11.0_amd64.deb 运行以下命令进行安装
1 sudo dpkg -i code-server_4.11.0_amd64.deb 运行以下命令进行启用服务
1 sudo systemctl enable --now code-server@$USER 3. 配置 code-server 默认加载的配置路径为 ~/.config/code-server/config.yaml
编辑该配置文件，示例如下：
1 2 3 4 5 6 # 监听端口 bind-addr: 0.0.0.0:8080 # 认证模式: 使用密码认证。 （其他认证模式参考官方文档） auth: password # 密码。此时为固定密码 password: 123456 修改完成后，重启服务即可
1 sudo systemctl restart code-server@$USER 4. 删除 1 2 3 4 sudo systemctl stop code-server@$USER sudo systemctl disable code-server@$USER sudo apt remove code-server 5. 更新 由于用户数据都存放在 ~/.local/share/code-server 目录下，所以更新只需要删除旧版本，并安装新版本即可。
  </content></entry><entry><title>Debian KVM 安装与配置</title><url>/post/linux/kvm/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>debian</tag><tag>kvm</tag><tag>cockpit</tag></tags><content type="html">  Debian KVM 安装与配置 本文以 Debian 11 为例，介绍 kvm 的安装与配置方法。
参考资料：
KVM - Debian Wiki 一、确认支持 kvm 运行以下命令，确认可以看到 kvm 相关的输出
1 lsmod | grep kvm 如果无结果，需要先在 BIOS 中打开 VT 选项。
二、安装相关依赖 安装 kvm 管理工具
1 apt install --no-install-recommends qemu-system libvirt-clients libvirt-daemon-system libvirt 有 GUI 管理工具（virt-manager），这里由于用在服务器，不考虑安装 GUI 工具。
安装 cockpit ，用于远程 web 管理虚拟机。
1 apt install cockpit cockpit-machines 安装完成后，即可通过 https://ip:9090 远程管理服务器。
三、创建虚拟机 通过 https://ip:9090 登录服务器，在虚拟机管理菜单中创建虚拟机，运行即可。（界面操作，比较简单，暂不详细介绍）
四、其他 4.1. 创建桥接网络 1.1 安装桥接工具
1 apt install bridge-utils 1.2 创建网桥 bridge
vi /etc/network/interfaces ，增加如下内容
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## 其中 br-default 不需要事先创建， enp0s3 需要按实际接口填写，同时把原来 enp0s3 的配置注释掉 auto br-default ## static 配置 iface br-default inet static address 192.168.0.100 netmask 255.255.255.0 gateway 192.168.0.1 bridge_ports enp0s3 bridge_stp off bridge_fd 0 bridge_maxwait 0 # dns-nameservers 8.8.8.8 4.4.2.2 ## dhcp 配置 #iface br-default inet dhcp #	bridge_ports enp0s3 1.3 重启网络服务
重启网络服务，让 br-default 生效
1 systemctl restart networking.service 1.4 cockpit 配置
在 cockpit-machines 中点击添加网络接口， 类型为 direct ， 源为上面创建的 br-default （这里不能使用 enp0s3 ，官方有说明这里只能选择网桥）
然后在虚拟机里就能看到这个网卡，且与实体机在同一个网段
  </content></entry><entry><title>curl 用法备忘</title><url>/post/linux/curl/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>curl</tag></tags><content type="html"><![CDATA[  curl 用法备忘 1. 使用指定文件作为请求数据 1 curl -X POST -H &#34;Content-Type:text/xml;charset=UTF-8&#34; -d @test.xml https://url:port/api 参数说明:
X: 请求类型，默认为 GET H: 自定义请求头 d: 请求参数。使用 @ 表示把一个文件的内容作为请求参数发送出去。 2. 上传文件 1 curl -X POST -F &#34;file=@/home/user/test.jpg&#34; https://url:port/api 参数说明:
X: 请求类型，默认为 GET F: 发送类型为 multipart/form-data 的表单数据 3. 通过 FTP 上传和下载文件 上传
1 curl -u &lt;username&gt;:&lt;password&gt; --ftp-create-dirs -T &lt;local_file&gt; ftp://&lt;ftp_server&gt;/&lt;remote_path&gt;/&lt;remote_file&gt; 参数说明:
&lt;username&gt;: FTP 用户名 &lt;password&gt;: FTP 密码 &ndash;ftp-create-dirs: 若 FTP 上的目标目录不存在，则自动创建目录 &lt;local_file&gt;: 待上传的本地文件 &lt;ftp_server&gt;/&lt;remote_path&gt;/&lt;remote_file&gt;: 要保存到 FTP 上的目标文件路径 下载
1 curl -u &lt;username&gt;:&lt;password&gt; -o &lt;local_file&gt; ftp://&lt;ftp_server&gt;/&lt;remote_file&gt; 参数说明:
&lt;username&gt;: FTP 用户名 &lt;password&gt;: FTP 密码 &lt;local_file&gt;: 要保存的本地路径 &lt;ftp_server&gt;/&lt;remote_file&gt;: FTP 上待下载的文件路径   ]]></content></entry><entry><title>dnsmasq 安装与配置</title><url>/post/linux/dnsmasq/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>debian</tag><tag>dnsmasq</tag><tag>dns</tag><tag>dhcp</tag><tag>tftp</tag></tags><content type="html"><![CDATA[  dnsmasq 安装与配置 dnsmasq 可提供 DNS 、 DHCP 、 TFTP 服务。
本文以 Debian 11 为例，介绍 dnsmasq 的安装与配置方法。
参考资料：
dnsmasq 官网 dnsmasq 官网文档 1. 安装 安装 dnsmasq 程序包。
1 sudo apt install dnsmasq 2. 配置 主要配置文件为 /etc/dnsmasq.conf ，可通过在 /etc/dnsmasq.d 目录下添加配置文件的方式进行扩展(适用于debian系)。
2.1 基本配置 1 2 3 4 5 6 7 8 # 设置启动 uid 。 user=nobody # 设置启动 gid 。 group=nogroup # 监听地址。必须加上 127.0.0.1 listen-address=::1,127.0.0.1 2.2 DNS 服务器配置 dnsmasq 在接受到用户的一个 DNS 请求时，首先会查找 /etc/hosts 这个文件，如果 /etc/hosts 文件没有请求的记录，则查找 /etc/resolv.conf 中定义的外部 DNS （也叫上游 DNS 服务器， nameserver 配置），外部 DNS 通过递归查询查找到请求后响应给客户端，然后 dnsmasq 将请求结果缓存下来（缓存到内存）供后续的解析请求。
因此使用 dnsmasq 进行自定义域名解析时，只需要更改 /etc/hosts 即可。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 示例 DNS 服务器配置 # DNS 服务监听端口。默认为 53 。设为 0 时，禁用 DNS 服务。DHCP 和 TFTP 不受此影响。 port=53 # 上游 DNS 服务器配置文件，默认为 /etc/resolv.conf 。 resolv-file=/etc/resolv.conf # 按照 resolv-file 中从上到下的 dns server 顺序进行指派解析。 strict-order # address 指定一个域名的解析值。 # 如把 *.example.com 解析成 192.168.1.1 。 address=/example.com/192.168.1.1 # server 指定上游 dns 服务器。 server=223.5.5.5 # 如把 *.google.com 域名通过 8.8.8.8 这个 DNS 服务器进行解析。 server=/google.com/8.8.8.8 # 额外的hosts文件。 addn-hosts=/etc/hosts2 2.3 DHCP 服务器配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Optionally set a domain name domain=example.com # Set default gateway dhcp-option=3,0.0.0.0 # Set DNS servers to announce dhcp-option=6,0.0.0.0 # DHCP 地址段和租约时间。地址段从 192.168.1.100 到 192.168.1.200 ，租约时间为 12 小时。 dhcp-range=192.168.1.100,192.168.1.200,12h # 静态 ip 地址分配。指定 MAC 及其 ip 。 dhcp-host=aa:bb:cc:dd:ee:ff,192.168.1.50 dhcp-host=aa:bb:cc:ff:dd:ee,192.168.1.51 # 静态 ip 分配通过外部文件来定义，格式跟上面的一样。优点是变更之后不需要重启 dnsmasq 。 dhcp-hostsfile=/etc/hostsfile # 最大租约数，默认为 150 dhcp-lease-max=150 # 租约列表文件。默认为 /var/lib/misc/dnsmasq.leases dhcp-leasefile=/var/lib/misc/dnsmasq.leases 2.4 TFTP 服务器配置 1 2 3 4 5 6 7 8 # 启用 tftp enable-tftp # tftp 根路径 tftp-root=/var/ftpd # 安全选项，启用之后，只有属于 dnsmasq 用户的文件可以通过 tftp 进行访问 tftp-secure 2.5 PXE 服务器配置 如果需要启用 PXE 服务，则需要同时启用 DHCP 和 TFTP 功能。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 指明 pxe 启动文件，该文件放到 tftp 根目录下 dhcp-boot=lpxelinux.0 # 不同的启动方式，显示不同的菜单，并加载不同的 pxe 启动文件 pxe-service=x86PC,&#34;PXELINUX (BIOS)&#34;,bios/lpxelinux pxe-service=X86-64_EFI,&#34;PXELINUX (EFI)&#34;,efi64/syslinux.efi dhcp-match=set:efi-x86_64,option:client-arch,7 dhcp-match=set:efi-x86_64,option:client-arch,9 dhcp-match=set:efi-x86,option:client-arch,6 dhcp-match=set:bios,option:client-arch,0 dhcp-boot=tag:efi-x86_64,efi64/syslinux.efi dhcp-boot=tag:efi-x86,efi32/syslinux.efi dhcp-boot=tag:bios,bios/lpxelinux.0   ]]></content></entry><entry><title>Windows 右键菜单添加以管理员打开 cmd</title><url>/post/windows/open_cmd_as_admin/</url><categories><category>windows</category></categories><tags><tag>windows</tag><tag>cmd</tag></tags><content type="html"><![CDATA[  Windows 右键菜单添加以管理员打开 cmd open_cmd_as_admin.reg 文件内容：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Windows Registry Editor Version 5.00 ; 以管理员身份打开 CMD ; 注册表项的路径必须为 runas ，否则无效。文件编码为 ansi ，使用 utf-8 中文会显示乱码。 ; Extended 表示要 shift+右键 才会显示 ; HasLUAShield 显示管理员图标 [HKEY_CLASSES_ROOT\Directory\Background\shell\runas] @=&#34;在此处打开 CMD (管理员)&#34; &#34;Extended&#34;=&#34;&#34; &#34;HasLUAShield&#34;=&#34;&#34; &#34;ShowBasedOnVelocityId&#34;=dword:00639bc8 [HKEY_CLASSES_ROOT\Directory\Background\shell\runas\command] @=&#34;cmd.exe /s /k pushd \&#34;%V\&#34;&#34;   ]]></content></entry><entry><title>对 Html 文件进行 Gzip 压缩</title><url>/post/html/gzip_bash/</url><categories><category>html</category></categories><tags><tag>html</tag><tag>gzip</tag></tags><content type="html"><![CDATA[  对 Html 文件进行 Gzip 压缩 gzip 压缩 对目录下的所有 html, js, css 文件进行 gzip 压缩
1 find /usr/share/nginx/html -type f -regex &#34;.*\.\(html\|js\|css\)&#34; -exec sh -c &#34;gzip &lt; {} &gt; {}.gz&#34; \; 配置 nginx 支持 1 2 3 4 5 6 7 8 9 10 11 12 13 # 启用静态压缩，如果存在同名的以.gz结尾的文件，则优先使用.gz文件。优先级高于gzip。 gzip_static on; # 启用压缩。 gzip on; # 文件大小大于2k时才进行压缩。 gzip_min_length 2k; # 压缩级别，1-10。数字越大压缩率越高，CPU占用率也越高。 gzip_comp_level 5; gzip_buffers 4 16k; # 对以下MIME类型的文件进行压缩。text/html无论是否指定，都进行压缩。gzip_types设置对gzip_static无效。 gzip_types text/plain text/css application/javascript application/xml; # 允许根据请求头的信息来判断返回压缩或非压缩数据。 gzip_vary on;   ]]></content></entry><entry><title>Trojan-go 安装指南</title><url>/post/software/trojan_go_install/</url><categories><category>software</category></categories><tags><tag>trojan</tag><tag>docker</tag><tag>vpn</tag></tags><content type="html"><![CDATA[  Trojan-go 安装指南 本文以 Debian 11 为例。
参考资料：
官方文档 github github release 1. 安装 Trojan-go 1.1 二进制安装方式 1 2 3 4 5 6 7 8 wget https://github.com/p4gefau1t/trojan-go/releases/download/v0.10.6/trojan-go-linux-amd64.zip unzip trojan-go-linux-amd64.zip cp trojan-go /usr/local/bin/ mkdir /etc/trojan-go cp *.dat /etc/trojan-go 相关文件路径为：
/usr/local/bin/trojan-go /etc/trojan-go/geoip.dat /etc/trojan-go/geosite.dat /etc/trojan-go/geoip-only-cn-private.dat 1.2 Docker 安装方式 1 docker pull p4gefau1t/trojan-go:latest 镜像中各文件的路径为：
/usr/local/bin/trojan-go /usr/local/bin/geoip.dat /usr/local/bin/geosite.dat /usr/local/bin/geoip-only-cn-private.dat 2. 配置服务端 由于 443 端口已经由 nginx 使用，负责代理其他站点了。这里实现的目标为
原 443 端口的所有内容不变。 trojan-go 运行的端口为 22250 。 nginx 增加监听 8443 端口，如果是 trojan-go 数据则转发到 22250 端口，如果是其他数据，则转发到原 443 端口。 2.1 编写配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 run-type: server # 对外监听端口 local-addr: 0.0.0.0 local-port: 22250 # fallback 端口 remote-addr: 127.0.0.1 remote-port: 80 # 密码 password: - your_password # 自己的域名和证书 ssl: cert: /etc/certs/gulucat.crt key: /etc/certs/gulucat.key sni: trojan.gulucat.com router: enabled: true block: - &#39;geoip:private&#39; # 不同的安装方式，这些文件的路径会不一样 geoip: /etc/trojan-go/geoip.dat geosite: /etc/trojan-go/geosite.dat 2.2 运行 trojan 2.2.1 二进制方式运行 把上面的配置文件 server.yaml 拷贝到 /etc/trojan-go 目录下。
创建系统服务文件 /etc/systemd/system/trojan-go.service
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [Unit] Description=Trojan-Go - An unidentifiable mechanism that helps you bypass GFW Documentation=https://p4gefau1t.github.io/trojan-go/ After=network.target nss-lookup.target [Service] User=www-data CapabilityBoundingSet=CAP_NET_ADMIN CAP_NET_BIND_SERVICE AmbientCapabilities=CAP_NET_ADMIN CAP_NET_BIND_SERVICE NoNewPrivileges=true ExecStart=/usr/local/bin/trojan-go -config /etc/trojan-go/server.yaml Restart=on-failure RestartSec=10s LimitNOFILE=infinity [Install] WantedBy=multi-user.target 然后启动服务。
1 2 3 systemctl daemon-reload systemctl enable trojan-go.service systemctl start trojan-go.service 2.2.2 Docker 方式运行 1 2 3 4 5 6 7 docker run -itd \ --name trojan-go \ --restart=always \ --network host \ -v ./server.yaml:/etc/trojan-go/server.yaml:ro \ p4gefau1t/trojan-go \ /etc/trojan-go/server.yaml 因为有 fallback ，所以要注意网络配置。
2.3 配置 nginx 转发 创建文件 /etc/nginx/modules-available/95-stream-trojan.conf
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 流量转发核心配置 stream { # 这里就是 SNI 识别，将域名映射成一个配置名 map $ssl_preread_server_name $backend_name { trojan.gulucat.com trojan; # 域名都不匹配情况下的默认值 default web; } # web，配置转发详情 upstream web { server 127.0.0.1:443; } # trojan，配置转发详情。需要跟 trojan 的监听端口一致。 upstream trojan { server 127.0.0.1:22250; } # 监听 8443 并开启 ssl_preread server { listen 8443 reuseport; listen [::]:8443 reuseport; proxy_pass $backend_name; ssl_preread on; } } 使 nginx 配置生效
1 2 3 ln -s /etc/nginx/modules-available/95-stream-trojan.conf /etc/nginx/modules-enabled/ systemctl reload nginx.service 3. 配置客户端(Linux) 3.1 编写配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 run-type: client # 本地监听端口 local-addr: 0.0.0.0 local-port: 1080 # 服务器端口 remote-addr: trojan.example.com remote-port: 8443 # 密码 password: - your_password # 设置路由 router: enabled: true # 直连清单 bypass: - &#34;geoip:cn&#34; - &#34;geoip:private&#34; - &#34;geosite:cn&#34; - &#34;geosite:geolocation-cn&#34; # 拦截清单 block: - &#34;geosite:category-ads&#34; # 代理清单 proxy: - &#34;geosite:geolocation-!cn&#34; # 配置文件路径 geoip: /etc/trojan-go/geoip.dat geosite: /etc/trojan-go/geosite.dat 3.2 运行 3.2.1 二进制方式运行 把上面的 client.yaml 放到 /etc/trojan-go 目录下
创建服务配置文件 /etc/systemd/system/trojan-go-client.service
1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description=Trojan-Go - An unidentifiable mechanism that helps you bypass GFW Documentation=https://p4gefau1t.github.io/trojan-go/ After=network.target nss-lookup.target [Service] Type=simple DynamicUser=true CapabilityBoundingSet=CAP_NET_BIND_SERVICE AmbientCapabilities=CAP_NET_BIND_SERVICE ExecStart=/usr/local/bin/trojan-go -config /etc/trojan-go/client.yaml [Install] WantedBy=multi-user.target 启动服务
1 2 3 systemctl daemon-reload systemctl enable trojan-go-client.service systemctl start trojan-go-client.service 3.2.2 Docker 方式运行 1 docker run -itd --name trojan-go --restart=always -p 1080:1080 -v ./client.yaml:/etc/trojan-go/client.yaml:ro p4gefau1t/trojan-go /etc/trojan-go/client.yaml   ]]></content></entry><entry><title>Etcd + Confd 动态配置 nginx 站点</title><url>/post/software/nginx_proxy/</url><categories><category>software</category></categories><tags><tag>etcd</tag><tag>confd</tag><tag>nginx</tag><tag>nginx-proxy</tag><tag>docker</tag><tag>debian</tag></tags><content type="html"><![CDATA[  Etcd + Confd 动态配置 nginx 站点 运行环境为 Debian 11 和 docker 。
1. 安装 nginx-proxy (该方案无直接安装 nginx 方便) 使用 docker 下载 nginx-proxy
1 2 docker pull nginxproxy/nginx-proxy:alpine docker network create nginx-proxy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 version: &#39;2&#39; services: nginx-proxy: image: nginxproxy/nginx-proxy:alpine restart: always ports: - &#34;80:80&#34; - &#34;443:443&#34; environment: - ENABLE_IPV6=true volumes: - ./conf.d:/etc/nginx/conf.d - ./vhost.d:/etc/nginx/vhost.d:ro - ./certs:/etc/nginx/certs:ro - /var/run/docker.sock:/tmp/docker.sock:ro networks: - nginx-proxy networks: nginx-proxy: external: true 2. 安装 nginx 直接安装源里的 nginx 。
1 apt install nginx 3. 运行 etcd 参考 使用 docker 运行 etcd 可以把 etcd keeper 一并运行，方便以图形化的界面管理 etcd 的值。
4. 运行 confd 参考资料: 官网 1. 下载 1 2 3 4 wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64 mv confd-0.16.0-linux-amd64 /usr/local/sbin/confd chmod +x /usr/local/sbin/confd 2. 配置 创建目录
1 mkdir -p /etc/confd/{conf.d,templates} 新建默认配置文件 /etc/confd/confd.toml
1 2 3 4 5 6 7 backend = &#34;etcdv3&#34; confdir = &#34;/etc/confd&#34; log-level = &#34;debug&#34; interval = 600 nodes = [ &#34;http://127.0.0.1:2379&#34; ] 新建模板配置文件 /etc/confd/conf.d/nginx-demo-web.toml
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [template] src = &#34;nginx-demo-web.tmpl&#34; dest = &#34;/etc/nginx/sites-enabled/demo_sites&#34; keys = [ &#34;/demo-web&#34; ] owner = &#34;root&#34; mode = &#34;0644&#34; check_cmd = &#34;nginx -t&#34; reload_cmd = &#34;nginx -s reload&#34; 新建模板文件 /etc/confd/templates/nginx-demo-web.tmpl
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ![*&#34; ]( range gets &#34;/demo-web/*&#34; ) upstream upstream_![ replace (base .Key) &#34;.&#34; &#34;_&#34; -1 ]( replace (base .Key) &#34;.&#34; &#34;_&#34; -1 ) { ![= printf &#34;%s/*&#34; .Key ]( $server_dir := printf &#34;%s/*&#34; .Key ) ![ range gets $server_dir ]( range gets $server_dir ) server ![ base .Key ]( base .Key ); ![ end ]( end ) } server { # listen 80; listen 443 ssl http2; server_name ![ base .Key ]( base .Key ); ssl_certificate /etc/nginx/certs/demo.example.com.crt; ssl_certificate_key /etc/nginx/certs/demo.example.com.key; index index.html index.htm index.nginx-debian.html; client_max_body_size 20M; location / { #try_files $uri $uri/ =404; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-PORT $remote_port; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://upstream_![ replace (base .Key) &#34;.&#34; &#34;_&#34; -1 ]( replace (base .Key) &#34;.&#34; &#34;_&#34; -1 ); } } ![ end ]( end ) 3. 注册服务 新建文件 /etc/systemd/system/confd.service
1 2 3 4 5 6 7 8 9 10 11 [Unit] Description=Confd Wants=network-online.target After=network-online.target [Service] ExecStart=/usr/local/sbin/confd Restart=always [Install] WantedBy=default.target 运行
1 2 systemctl daemon-reload systemctl start confd 4. 测试 增加站点示例
打开 etcd keeper ，在 etcd 中增加如下示例节点
1 2 3 4 /demo-web/demo1.example.com/127.0.0.1:8080 /demo-web/demo1.example.com/127.0.0.1:8081 /demo-web/demo2.example.com/127.0.0.1:8082 /demo-web/demo2.example.com/127.0.0.1:8083 过一会儿可以看到生成 /etc/nginx/sites-enabled/demo_sites 文件，文件里的内容便是上面配置的网站。
TODO: 与 nginx-proxy 整合 整合之后，既可以通过 etcd 动态配置外部 web server，也能代理 docker 里面的 web server。
  ]]></content></entry><entry><title>Windows 内置工具简介</title><url>/post/windows/windows_tools/</url><categories><category>windows</category></categories><tags><tag>windows</tag><tag>ssh</tag><tag>hash</tag><tag>base64</tag><tag>csv</tag></tags><content type="html"><![CDATA[  Windows 内置工具简介 Windows 10 之后，操作系统内置了一系列比较实用的工具，此处对这些工具进行梳理介绍。
1. File Hash 可选的算法有： MD2 MD4 MD5 SHA1 SHA256 SHA384 SHA512
1 2 3 4 5 # cmd certutil -hashfile filename md5 # powershell Get-FileHash filename -algorithm md5 2. CSV 文件格式转换 把 csv 的文件格式进行标准化，如全部字段加上引号。
1 2 # powershell Import-Csv &#34;.\a.csv&#34; | Export-Csv &#34;.\b.csv&#34; -NoTypeInformation 3. Base64 编码解码 Base64 编码。把 InFile 文件编码成 base64 ，输出到 OutFile 中。
1 CertUtil -encode InFile OutFile Base64 解码。把 InFile 文件中的 base64 字符串解码，输出到 OutFile 中。
1 CertUtil -decode InFile OutFile 4. OpenSSH 客户端 Windows 7 之前，若需要进行 ssh 连接， SecureCRT 、 Putty 等 ssh 客户端是必装软件。但从 Windows 10 开始，系统默认内置了 OpenSSH 客户端。
使用示例
1 2 # cmd or powershell ssh root@192.168.1.100 ssh-keygen 也能使用
1 2 # cmd or powershell ssh-keygen -t ed25519 如果管理的服务器比较多，需要像 SecureCRT 里的保存连接功能，可以参考 ssh config 使用说明 进行配置。
  ]]></content></entry><entry><title>维护启动盘 Ventoy 备注</title><url>/post/software/ventoy/</url><categories><category>software</category></categories><tags><tag>ventoy</tag></tags><content type="html"><![CDATA[  维护启动盘 Ventoy 备注 参考资料： github: Ventoy 1. 制作启动盘 下载 Ventoy 工具，使用该工具对 U 盘进行格式化。
2. 修改配置文件 配置文件所在路径: /ventoy/ventoy.json
示例
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 { &#34;control&#34;: [ { &#34;VTOY_DEFAULT_SEARCH_ROOT&#34;: &#34;/ISO&#34; }, { &#34;VTOY_MENU_TIMEOUT&#34;: &#34;10&#34; }, { &#34;VTOY_DEFAULT_IMAGE&#34;: &#34;/ISO/debian-11.1.0-amd64-netinst.iso&#34; }, { &#34;VTOY_HELP_TXT_LANGUAGE&#34;: &#34;zh_CN&#34; } ], &#34;theme&#34;: { &#34;file&#34;: &#34;/ventoy/themes/gulucat/theme.txt&#34;, &#34;gfxmode&#34;: &#34;1920x1080&#34;, &#34;fonts&#34;: [ &#34;/ventoy/themes/gulucat/ascii.pf2&#34;, &#34;/ventoy/themes/gulucat/DejaVuSans10.pf2&#34;, &#34;/ventoy/themes/gulucat/DejaVuSans12.pf2&#34;, &#34;/ventoy/themes/gulucat/DejaVuSans-Bold14.pf2&#34;, &#34;/ventoy/themes/gulucat/droidlogo_bold_26.pf2&#34; ], &#34;ventoy_left&#34;: &#34;100%&#34;, &#34;ventoy_top&#34;: &#34;100%&#34;, &#34;ventoy_color&#34;: &#34;gainsboro&#34; }, &#34;menu_class&#34;: [ { &#34;key&#34;: &#34;debian&#34;, &#34;class&#34;: &#34;debian&#34; }, { &#34;key&#34;: &#34;ubuntu&#34;, &#34;class&#34;: &#34;ubuntu&#34; }, { &#34;key&#34;: &#34;windows&#34;, &#34;class&#34;: &#34;windows&#34; }, { &#34;key&#34;: &#34;win&#34;, &#34;class&#34;: &#34;windows&#34; } ], &#34;auto_install&#34;: [ { &#34;image&#34;: &#34;/ISO/debian-11.1.0-amd64-netinst.iso&#34;, &#34;template&#34;: &#34;/ventoy/script/debian-11.seed&#34; }, { &#34;image&#34;: &#34;/ISO/zh-cn_windows_10_enterprise_ltsc_2021_x64_dvd_033b7312.iso&#34;, &#34;template&#34;: &#34;/ventoy/script/windows-unattended.xml&#34; } ] } 3. 放置镜像文件 把各个安装镜像文件放到 /ISO 目录下。
附录1. 计划放置镜像列表 Debian 11 netinstall Windows 10 LTSC 2021 Ubuntu 2004 Windows Server 2022 TrueNas Windows 7 CentOS 8 附录2. 自用主题 自用配置和主题:   ]]></content></entry><entry><title>Debian 解压 zip 文件名乱码解决方案</title><url>/post/linux/unar/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>unar</tag></tags><content type="html">  Debian 解压 zip 文件名乱码解决方案 zip 文件对于文件名的编码没有进行统一，因此有可能对于不同编码的系统，解压出来的文件名会产生乱码。
对于 Debian 来说，比较方便快捷的一个解决方案是使用 unar 进行解压。
安装 unar 程序
1 2 # root apt install unar 使用 unar 解压文件
1 unar test.zip   </content></entry><entry><title>安装 Office 2021</title><url>/post/windows/office_2021_install/</url><categories><category>windows</category></categories><tags><tag>windows</tag><tag>office</tag></tags><content type="html"><![CDATA[  安装 Office 2021 下载 Office Deployment Tool 相关工具请查看上一篇 安装 Office 2019 从 Office Deployment Tool 下载 Office Deployment Tool ，解压得到 setup.exe 。
准备配置文件 可以到 Office 365 客户端配置 生成自定义的安装配置文件。
这里列出本人使用的一个示例配置 （不安装 Access,Lync,Outlook,Pulisher,Teams）
configuration-Office_2021_VL.xml 文件内容：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 &lt;Configuration ID=&#34;b4cb214f-ea51-41a3-a533-6a9095026986&#34;&gt; &lt;Add OfficeClientEdition=&#34;64&#34; Channel=&#34;PerpetualVL2021&#34;&gt; &lt;Product ID=&#34;ProPlus2021Volume&#34; PIDKEY=&#34;FXYTK-NJJ8C-GB6DW-3DYQT-6F7TH&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;ExcludeApp ID=&#34;Access&#34; /&gt; &lt;ExcludeApp ID=&#34;Lync&#34; /&gt; &lt;ExcludeApp ID=&#34;Outlook&#34; /&gt; &lt;ExcludeApp ID=&#34;Publisher&#34; /&gt; &lt;ExcludeApp ID=&#34;Teams&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;VisioPro2021Volume&#34; PIDKEY=&#34;KNH8D-FGHT4-T8RK3-CTDYJ-K2HT4&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;ExcludeApp ID=&#34;Access&#34; /&gt; &lt;ExcludeApp ID=&#34;Lync&#34; /&gt; &lt;ExcludeApp ID=&#34;Outlook&#34; /&gt; &lt;ExcludeApp ID=&#34;Publisher&#34; /&gt; &lt;ExcludeApp ID=&#34;Teams&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;ProjectPro2021Volume&#34; PIDKEY=&#34;FTNWT-C6WBT-8HMGF-K9PRX-QV9H8&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;ExcludeApp ID=&#34;Access&#34; /&gt; &lt;ExcludeApp ID=&#34;Lync&#34; /&gt; &lt;ExcludeApp ID=&#34;Outlook&#34; /&gt; &lt;ExcludeApp ID=&#34;Publisher&#34; /&gt; &lt;ExcludeApp ID=&#34;Teams&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;ProofingTools&#34;&gt; &lt;Language ID=&#34;en-us&#34; /&gt; &lt;/Product&gt; &lt;/Add&gt; &lt;Property Name=&#34;SharedComputerLicensing&#34; Value=&#34;0&#34; /&gt; &lt;Property Name=&#34;FORCEAPPSHUTDOWN&#34; Value=&#34;FALSE&#34; /&gt; &lt;Property Name=&#34;DeviceBasedLicensing&#34; Value=&#34;0&#34; /&gt; &lt;Property Name=&#34;SCLCacheOverride&#34; Value=&#34;0&#34; /&gt; &lt;Property Name=&#34;AUTOACTIVATE&#34; Value=&#34;0&#34; /&gt; &lt;Updates Enabled=&#34;FALSE&#34; /&gt; &lt;Display Level=&#34;Full&#34; AcceptEULA=&#34;TRUE&#34; /&gt; &lt;/Configuration&gt; 在线安装 Office 以管理员身份打开 cmd ，进入当前目录，运行以下命令：
1 setup.exe /configure configuration-Office_2021_VL.xml 该命令会根据配置文件直接安装 office ，全程不需要干预。
下载离线包 上一个命令直接从网络下载数据并安装。若要离线安装，则可以使用以下命令先下载离线包：
1 setup.exe /download configuration-Office_2021_VL.xml 下载的离线包数据位置当前目录的 Office 目录下。此时再执行上一步的命令，则不需要网络，直接从本地读取安装包数据。
  ]]></content></entry><entry><title>vlmcsd 安装指南</title><url>/post/software/vlmcsd_install/</url><categories><category>software</category></categories><tags><tag>vlmcsd</tag><tag>docker</tag><tag>windows</tag><tag>linux</tag></tags><content type="html">  vlmcsd 安装指南 这是个好东西，不多做介绍，用途请自行搜索。
参考资料：
https://github.com/Wind4/vlmcsd https://hub.docker.com/r/mikolatero/vlmcsd 1. 编译安装 1 2 3 4 5 git clone https://github.com/Wind4/vlmcsd cd vlmcsd make make install 2. 直接运行 1 vlmcsd -D -d -t 3 -e -v 3. 以 systemd 服务方式运行 vi /etc/systemd/system/vlmcsd.service
1 2 3 4 5 6 7 8 9 10 11 12 [Unit] Description=vlmcsd Wants=network-online.target After=network-online.target [Service] User=nobody Group=nogroup ExecStart=/usr/local/bin/vlmcsd -D -d -t 3 -e -v [Install] WantedBy=default.target 1 2 systemctl enable vlmcsd.service systemctl start vlmcsd.service 4. 以 docker 方式运行 1 docker run -d -p 1688:1688 --restart=always --name vlmcsd mikolatero/vlmcsd   </content></entry><entry><title>Git 备份仓库(mirror)</title><url>/post/software/git_mirror/</url><categories><category>software</category></categories><tags><tag>git</tag></tags><content type="html">  Git 备份仓库(mirror) 参考资料： https://docs.github.com/en/github/creating-cloning-and-archiving-repositories/duplicating-a-repository| 1. 以 mirror 的方式 clone 仓库 1 git clone --mirror https://github.com/exampleuser/repository-to-mirror.git 2. 设置目标地址 1 2 cd repository-to-mirror git remote add mirror_host https://github.com/exampleuser/mirrored 3. 更新并同步到目标地址 1 2 git fetch -p origin git push --mirror mirror_host   </content></entry><entry><title>远程上传证书并调用更新脚本</title><url>/post/linux/update_certs/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>acme.sh</tag></tags><content type="html"><![CDATA[  远程上传证书并调用更新脚本 背景： 由于有多个服务器需要更新 https 证书，如果每个服务器单独更新自己的证书，在迁移应用的时候，需要把证书也迁移过去，非常麻烦。因此考虑由一台服务器进行更新 https 证书，并通过 ssh 分发和调用更新命令。
前期准备：
做好 ssh 免密码登录。 每台服务器创建 /etc/certs 目录用于存放证书，并创建 /etc/certs/reload.sh 脚本用于如何更新证书。 运行过程：
把当前目录下的 ./certs 里的证书通过 ssh 上传到远程服务器上 调用远程服务器上的 reload.sh 脚本。 应用场景： 使用 acme.sh 进行定时更新证书，更新完毕后调用此脚本给其他服务器更新证书。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 #!/bin/bash # Author: liujun &lt;ljskryj@163.com&gt; # Date: 2020-12-27 # Description: # 远程上传证书并调用 reload 脚本。 # upload certs and run remote reload.sh . set -e DIR=$(dirname &#34;${BASH_SOURCE[0]}&#34;) cd &#34;${DIR}&#34; echo &#34;start update certs&#34; SERVERS=(&#34;server1&#34; &#34;server2&#34; &#34;server3&#34; ) BASE_DIR=/etc/certs for SERVER in &#34;${SERVERS[@]}&#34; do echo &#34;=&gt; start for server $SERVER&#34; echo &#34; [$SERVER] mkdir dir $BASE_DIR&#34; ssh $SERVER &#34;if [ ! -d &#39;$BASE_DIR&#39; ]; then mkdir $BASE_DIR ; fi&#34; echo &#34; [$SERVER] mkdir done!&#34; echo &#34; [$SERVER] copy certs&#34; scp ./certs/gulucat.key $SERVER:$BASE_DIR/ scp ./certs/gulucat.crt $SERVER:$BASE_DIR/ echo &#34; [$SERVER] copy done!&#34; echo &#34; [$SERVER] call reload cmd&#34; ssh $SERVER &#34;if [ -f &#39;$BASE_DIR/reload.sh&#39; ]; then bash $BASE_DIR/reload.sh ; fi&#34; echo &#34; [$SERVER] reload done!&#34; done echo &#34;all done!&#34;   ]]></content></entry><entry><title>Shiro 使用介绍</title><url>/post/java/shiro_use/</url><categories><category>java</category></categories><tags><tag>java</tag><tag>shiro</tag></tags><content type="html">  Shiro 使用介绍 文档   </content></entry><entry><title>Elasticsearch 相关文档</title><url>/post/software/elasticsearch_note/</url><categories><category>software</category></categories><tags><tag>elasticsearch</tag></tags><content type="html">  Elasticsearch 相关文档 文件列表如下，有空再整理
DSL查询举例.ipynb DSL查询举例.md Logstash基本使用.md Metricbeat+ELK实现性能监控.md Python从Elasticsearch中读取CPU数据.md 基于Python+EL实现的数据采集器.md   </content></entry><entry><title>鼠标点击字体特效</title><url>/post/html/js_click_text/</url><categories><category>html</category></categories><tags><tag>html</tag><tag>js</tag></tags><content type="html"><![CDATA[  鼠标点击字体特效 JQuery 版本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /* 鼠标特效 */ var a_idx = 0; var a = new Array(&#34;❤Python❤&#34;,&#34;❤Julia❤&#34;,&#34;❤PHP❤&#34;,&#34;❤C❤&#34;,&#34;❤C++❤&#34;,&#34;❤C#❤&#34;,&#34;❤Java❤&#34;,&#34;❤Go❤&#34;,&#34;❤ASM❤&#34;,&#34;❤SQL❤&#34;,&#34;❤HTML❤&#34;,&#34;❤CSS❤&#34;,&#34;❤Javascript❤&#34;); jQuery(document).ready(function($) { $(&#34;body&#34;).click(function(e) { var $i = $(&#34;&lt;span&gt;&lt;/span&gt;&#34;).text(a[a_idx]); a_idx = (a_idx + 1) % a.length; var x = e.pageX, y = e.pageY; $i.css({ &#34;z-index&#34;: 9999, &#34;top&#34;: y - 20, &#34;left&#34;: x, &#34;position&#34;: &#34;absolute&#34;, &#34;font-weight&#34;: &#34;bold&#34;, &#34;color&#34;: &#34;rgb(&#34;+~~(255*Math.random())+&#34;,&#34;+~~(255*Math.random())+&#34;,&#34;+~~(255*Math.random())+&#34;)&#34; }); $(&#34;body&#34;).append($i); $i.animate({ &#34;top&#34;: y - 180, &#34;opacity&#34;: 0 }, 1500, function() { $i.remove(); }); }); }); Javascript 原生版 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 class ClickFontEffect { constructor(fontArray, colorArray) { // 文字列表 this.fontArray = fontArray || [&#34;快乐&#34;, &#34;欢欣&#34;, &#34;愉快&#34;, &#34;欢喜&#34;]; // 颜色列表 this.colorArray = colorArray || [&#34;red&#34;, &#34;green&#34;, &#34;blue&#34;, &#34;orange&#34;, &#34;purple&#34;, &#34;yellow&#34;]; // 获取body元素 this.body = document.getElementsByTagName(&#34;body&#34;)[0]; // 默认的css样式 this.cssStyle = &#34;position:absolute; width: 40px; height: 20px; cursor: default; transform: translate(-50%,-50%); font-weight: bold; opacity: 1; z-index: 1000; transition: 1s; -moz-user-select: none;-webkit-user-select: none;-ms-user-select: none;user-select: none;&#34;; let that = this; document.addEventListener(&#34;click&#34;, (e) =&gt; { that.showFont(e); }) }; showFont(e) { // 创建一个随机节点 let newNode = document.createElement(&#39;span&#39;); // 随机字体和颜色 let fontIdx = Math.floor(Math.random() * this.fontArray.length); let coloryIdx = Math.floor(Math.random() * this.colorArray.length); let randomFront = this.fontArray[fontIdx]; let randomColor = this.colorArray[coloryIdx]; // 向body中添加元素 this.body.appendChild(newNode); // 添加样式 newNode.style.cssText = this.cssStyle; newNode.style.color = randomColor; newNode.innerHTML = randomFront; // 鼠标点击位置 newNode.style.left = e.clientX + &#39;px&#39;; newNode.style.top = e.clientY + &#39;px&#39;; // 动画 setTimeout(function () { newNode.style.opacity = 0; newNode.style.top = newNode.offsetTop - 100 + &#39;px&#39;; }, 100); // 清除 let that = this; setTimeout(function () { that.body.removeChild(newNode); }, 2000); } }; window.onload = function () { let fontEffect = new ClickFontEffect(); }   ]]></content></entry><entry><title>ISC KEA 服务器安装与配置</title><url>/post/linux/isc_kea/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>debian</tag><tag>isc-kea</tag></tags><content type="html"><![CDATA[  ISC KEA 服务器安装与配置 本文以 Debian 10 为例，介绍 Kea 服务器的安装与配置方法。
一、Kea 安装与配置 待补充
二、Kea Stork 安装与配置 Stork 为 Kea 服务的一个可视化前端。
参考资料：
官方说明文档 Stork 分为 Server 和 Agent 两部分。Agent 需要跟 kea 或者 bind9 服务安装在同一台机器上，用于获取这些服务的数据。Server 从 Agent 处获取信息并展示。Server 可以单独安装其他机器上。
2.1 前置准备 Stork Agent 无需额外依赖。
Stork Server 需要一个 PostgreSQL 数据作为存储后端，并且默认使用 stork 作为用户名和数据库名，因此需要先准备相应的环境。 (数据库连接配置可以通过 /etc/stork/server.env 文件进行修改。)
安装 PostgreSQL 略，可以通过 docker 快速启动一个环境。
创建 stork 用户和数据库
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ psql postgres psql (11.5) Type &#34;help&#34; for help. postgres=# postgres=# CREATE USER stork WITH PASSWORD &#39;stork&#39;; CREATE ROLE postgres=# CREATE DATABASE stork; CREATE DATABASE postgres=# GRANT ALL PRIVILEGES ON DATABASE stork TO stork; GRANT postgres=# \c stork You are now connected to database &#34;stork&#34; as user &#34;thomson&#34;. stork=# create extension pgcrypto; CREATE EXTENSION 2.2 安装 1 2 3 4 5 6 7 curl -1sLf &#39;https://dl.cloudsmith.io/public/isc/stork/cfg/setup/bash.deb.sh&#39; | sudo bash # 安装 Stork Server sudo apt install isc-stork-server # 安装 Stork Agent sudo apt install isc-stork-agent Stork Server 的配置文件为 /etc/stork/server.env
Stork Agent 的配置文件为 /etc/stork/agent.env
2.3 启动 通过 systemd 来启动
1 sudo systemctl start isc-stork-server.service 然后就可以访问了。 （默认监听 8080 端口。）
  ]]></content></entry><entry><title>DHCP 服务器安装与配置</title><url>/post/linux/isc_dhcp_server/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>debian</tag><tag>dhcp</tag></tags><content type="html"><![CDATA[  DHCP 服务器安装与配置 本文以 Debian 10 为例，介绍 DHCP 服务器的安装与配置方法。
参考资料：
DHCP_Server 1. 安装 安装 isc-dhcp-server 程序包。
1 sudo apt install isc-dhcp-server 2. 配置 2.1 指定监听的网络接口 编辑 /etc/default/isc-dhcp-server 文件，修改如下选项，把 eth0 改为自己的网络接口名称
1 INTERFACESv4=&#34;eth0&#34; 2.2 基本配置 编辑 /etc/dhcp/dhcpd.conf 文件，选项说明如下
全局配置
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 域名 option domain-name &#34;example.com&#34;; # 自定义 DNS 服务器 option domain-name-servers 1.1.1.1, 114.114.114.114, 233.5.5.5, dns.example.com; # 网关 option routers 192.168.1.1; # 租约时间，单位秒 default-lease-time 3600; max-lease-time 7200; # 授权服务器 (视情况配置，这里暂不配置) # authoritative; 定义子网
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 subnet 192.168.1.0 netmask 255.255.255.0 { # 全局的配置可以在子网里重定义 # option domain-name &#34;sub.example.com&#34;; # option domain-name-servers 192.168.1.1; # option routers 192.168.1.1; # default-lease-time 3600; # max-lease-time 7200; # 其他选项 # option subnet-mask 255.255.255.0; # option broadcast-address 192.168.1.255; # 定义可分配的地址范围 range 192.168.1.100 192.168.1.200; range 192.168.1.210 192.168.1.220; } 静态地址分配
1 2 3 4 5 6 7 8 9 10 11 # MAC 地址与 IP 进行静态绑定。 host server-1 { hardware ethernet 00:0D:87:B3:AE:A1; fixed-address 192.168.1.11; } host server-2 { hardware ethernet 00:0D:87:B3:AE:A2; fixed-address 192.168.1.12; } 配置完成后重启 dhcp 服务
1 sudo systemctl restart isc-dhcp-server.service 3. 查看已分配的客户端列表 客户端列表保存在 /var/lib/dhcp/dhcpd.leases 文件中。
可以通过命令 dhcp-lease-list 查看格式化后的信息列表。
  ]]></content></entry><entry><title>Debian 自动安装配置备忘</title><url>/post/linux/debian_preseed/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>debian</tag><tag>preseed</tag></tags><content type="html">  Debian 自动安装配置备忘 参考资料：
DebianInstaller Preseed Preseed file example 使用预置自动进行安装 自用的配置文件：
https://conf.gulucat.com/debian/buster.txt https://conf.gulucat.com/debian/bullseye.txt https://conf.gulucat.com/debian/bookworm.txt   </content></entry><entry><title>Kubernetes 配置节点支持 GPU</title><url>/post/kubernetes/config_gpu_support/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes 配置节点支持 GPU 本文以 Debian 10, kubernetes 1.19.3 为例，进行配置 GPU 支持。
参考资料：
nvidia-runtime install docker 添加 nvidia 运行环境 Schedule GPUs https://github.com/NVIDIA/k8s-device-plugin https://www.kubeflow.org/docs/notebooks/setup/ 1. 前提条件 节点上已经安装了 nvidia 显卡驱动。驱动版本必须大于 384.81 。 节点上已经安装了 nvidia-docker 2.0 插件。安装过程见 docker 添加 nvidia 运行环境 。 nvidia-container-runtime 作为默认的 runtime 。 即在 /etc/docker/daemon.json 中设置 &quot;default-runtime&quot;: &quot;nvidia&quot; 2. 安装插件 1 kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.7.0/nvidia-device-plugin.yml 3. 查看节点 gpu 数量 1 kubectl get nodes &#34;-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu&#34;   ]]></content></entry><entry><title>Kubernetes 安装 Kubeflow</title><url>/post/kubernetes/install_kubeflow/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes 安装 Kubeflow 本文以 Debian 10, kubernetes 1.19.3 为例，进行 Kubeflow 1.1.0 的安装讲解。
参考资料：
Kubeflow Deployment with kfctl_k8s_istio 基础版本 Multi-user, auth-enabled Kubeflow with kfctl_istio_dex 多用户认证版本 1. 准备环境 1.1 配置动态卷供应 Kubernetes 里需要配置了一个默认的动态卷供应 dynamic volume provisioner （重要，一些应用需要这个来存储数据） 。可通过此文档 Kubernetes 配置 NFS StorageClass 配置一个 NFS StorageClass 。
1.2 下载 打开 https://github.com/kubeflow/kfctl/releases/ 页面，下载合适的版本。这里以 V1.1.0 版本为例。
1 2 3 4 5 # 下载二进制文件 wget https://github.com/kubeflow/kfctl/releases/download/v1.1.0/kfctl_v1.1.0-0-g9a3621e_linux.tar.gz # 解压 tar -zxvf kfctl_v1.1.0-0-g9a3621e_linux.tar.gz 这里把解压出来的 kfctl 放在 ~/kubeflow/bin 目录下。
2. 安装基础版本 参考： https://www.kubeflow.org/docs/started/k8s/kfctl-k8s-istio/ 2.1 创建一个环境变量文件 创建目录
mkdir ~/kubeflow/kfctl-k8s-istio
创建环境变量文件
vi ~/kubeflow/kfctl-k8s-istio/env.sh
1 2 3 4 5 6 7 8 9 10 11 12 # 把 kfctl 加到 PATH 中。 export PATH=$PATH:~/kubeflow/bin # 设置 Config 文件下载地址 export CONFIG_URI=&#34;https://raw.githubusercontent.com/kubeflow/manifests/v1.1-branch/kfdef/kfctl_k8s_istio.v1.1.0.yaml&#34; # 设置 KF_NAME 。可随便设置，官方示例是以它作为文件夹名称，暂不知道应用内部是否需要此变量。 export KF_NAME=kfctl-k8s-istio # 设置 KF_DIR 。按需设置，官方示例是以它作为文件夹名称，暂不知道应用内部是否需要此变量。 export BASE_DIR=~/kubeflow export KF_DIR=${BASE_DIR}/${KF_NAME} 2.2 安装和部署 kubeflow 1 2 3 4 5 6 7 8 # 进入 KF_DIR ， 这里是 ~/kubeflow/kfctl-k8s-istio cd ~/kubeflow/kfctl-k8s-istio # 加载环境变量，主要是 PATH 和 CONFIG_URI source env.sh # 应用配置文件 kfctl apply -V -f ${CONFIG_URI} 此时经过漫长的部署，等所有应用都正常运行，即为部署成功。
3. 安装多用户认证版本 3.1 安装和部署 部署过程跟基础版本类似， 只是 CONFIG_URI 改为 https://raw.githubusercontent.com/kubeflow/manifests/v1.1-branch/kfdef/kfctl_istio_dex.v1.1.0.yaml
结尾: 删除 kubeflow 若不想使用 kubeflow 了，运行以下命令进行删除。
1 2 3 cd ${KF_DIR} kfctl delete -f ${CONFIG_FILE} 其他: 可能遇到的问题 Q1. failed calling webhook &ldquo;webhook.cert-manager.io&rdquo; Q1: 部署过程中，日志报 failed calling webhook &ldquo;webhook.cert-manager.io&rdquo; 错误。
A1: 可能是 kubernetes 网络不通。如果是 debian 10，可以考虑把 iptables 改成 legacy 版本（官方说 iptables 的兼容性问题已解决，本人尚未做验证）。
Q2. CustomResourceDefinition.apiextensions.k8s.io &ldquo;seldondeployments.machinelearning.seldon.io&rdquo; is invalid Q2: 部署过程中，日志报 CustomResourceDefinition.apiextensions.k8s.io &ldquo;seldondeployments.machinelearning.seldon.io&rdquo; is invalid 错误。
A2:
修改 kfctl_k8s_istio.v1.1.0.yaml 文件，最后那部分改为：
1 2 3 4 repos: - name: manifests uri: https://github.com/DavidSpek/manifests/archive/v1.1-branch.tar.gz version: v1.1-branch Q3. 镜像总是拉取不下来 Q3: 部署过程中，需要下载大量镜像，而且不少镜像是位于 gcr.io 和 quay.io 服务器中。由于众所周知的原因，国内可能访问不了这两个服务器，手动下载也很难找全，导致应用无法启动。
A3: 参考 docker 配置代理 中关于 http 代理那部分，挂上梯子，可以解决所有镜像问题。
Q4. MountVolume.SetUp failed for volume &ldquo;istio-token&rdquo; : failed to fetch token: the API server does not have TokenRequest endpoints enabled Q4: 有的应用报 MountVolume.SetUp failed for volume &ldquo;istio-token&rdquo; : failed to fetch token: the API server does not have TokenRequest endpoints enabled 错误。
A4:
修改 /etc/kubernetes/manifests/kube-apiserver.yaml ，增加
1 2 - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key - --service-account-issuer=kubernetes.default.svc 保存即可，k8s会自动重新加载
  ]]></content></entry><entry><title>Kubernetes 配置 NFS StorageClass</title><url>/post/kubernetes/configure_storageclass_nfs/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes 配置 NFS StorageClass 前置条件：
安装 Helm 1. 安装 nfs-client-provisioner 1 helm install nfs-provisioner stable/nfs-client-provisioner --set nfs.server=192.168.1.100 --set nfs.path=/nfs/your_path 2. 配置为默认的 StorageClass 当 pvc 没有指定 StorageClass 时，使用该 nfs 作为默认存储
设置为默认 StorageClass
1 2 # 设置 default class 为 true 。 其中 nfs-client 为上一步创建的 nfs storageclass 的名称。 kubectl patch storageclass nfs-client -p &#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;true&#34;}}}&#39; 解除指定默认 StorageClass
1 2 # 设置 default class 为 false。 kubectl patch storageclass nfs-client -p &#39;{&#34;metadata&#34;: {&#34;annotations&#34;:{&#34;storageclass.kubernetes.io/is-default-class&#34;:&#34;false&#34;}}}&#39;   ]]></content></entry><entry><title>Helm 安装</title><url>/post/kubernetes/install_helm/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html">  Helm 安装 参考资料：
Helm Quick Start Installing Helm 1. 安装 对于 debian/ubuntu 来说，可以直接通过 apt 安装。
这里使用手动下载二进制文件的方式。
打开 https://github.com/helm/helm/releases 网页，找到适合自己平台的版本，下载。
这里使用 Helm V3.3.4 linux amd64 版本作为示例。
1 2 3 4 5 6 7 8 # 下载 wget https://get.helm.sh/helm-v3.3.4-linux-amd64.tar.gz # 解压 tar -zxvf helm-v3.3.4-linux-amd64.tar.gz # 解压出来后是一个目录，把目录里的 helm 可执行文件移动到 bin 路径下 mv linux-amd64/helm /usr/local/bin/helm 2. 添加仓库(Repository) Repository 是 Helm 的软件源，安装完成时并没有默认的软件源，这里添加官方的 stable 源。
1 helm repo add stable https://charts.helm.sh/stable 3. 日常使用 1 2 3 4 5 6 7 8 9 10 11 12 13 # 更新 helm repo update # 安装 mysql 示例。 --generate-name 表示自动分配名字 helm install stable/mysql --generate-name # 或者手动分配名字 helm install my-mysql stable/mysql # 列出已安装软件 helm ls # 卸载软件 helm uninstall &amp;lt;RELEASE_NAME&amp;gt; 4. 查找软件 官方软件仓库网站： https://artifacthub.io/   </content></entry><entry><title>Kubernetes 安装 rook ceph</title><url>/post/kubernetes/rook_ceph/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes 安装 rook ceph 本文以 Debian 10 , kubernetes 1.19 为例。 kubernetes 安装参考站内另一篇文章 Kubernetes 安装 参考资料：
官方文档: Ceph Storage Quickstart Ceph-Toolbox: Rook Ceph Toolbox 由于实验环境中没有足够的空闲磁盘空间，最终实验未完成。这里仅记录前面的实验步骤，作为备忘笔记，最终过程待补充。
前置条件 需要有未格式化的硬盘，或者未格式化的分区，或者有 block 模式的 PV。 前置条件 1. 下载 rook 仓库 (选做) 1 git clone --single-branch --branch release-1.4 https://github.com/rook/rook.git 这里也可以不下载，主要是需要它仓库里定义好的几个 yaml 文件。
2. 启动 ceph 1 2 3 4 5 cd rook/cluster/examples/kubernetes/ceph kubectl create -f common.yaml kubectl create -f operator.yaml kubectl create -f cluster.yaml 其中
common.yaml 定义通用配置 operator.yaml 负责启动 rook-ceph-operator 。需要先确定 rook-ceph-operator 启动完成后再进行下一步。 cluster.yaml 会启动 ceph 的关键组件，如 rook-ceph-mgr, rook-ceph-mon, rook-ceph-osd 等。 3. 验证 ceph 启动成功 参考 Rook Ceph Toolbox 3.1 创建 ceph-toolbox 应用 创建文件 toolbox.yaml
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 apiVersion: apps/v1 kind: Deployment metadata: name: rook-ceph-tools namespace: rook-ceph labels: app: rook-ceph-tools spec: replicas: 1 selector: matchLabels: app: rook-ceph-tools template: metadata: labels: app: rook-ceph-tools spec: dnsPolicy: ClusterFirstWithHostNet containers: - name: rook-ceph-tools image: rook/ceph:v1.4.6 command: [&#34;/tini&#34;] args: [&#34;-g&#34;, &#34;--&#34;, &#34;/usr/local/bin/toolbox.sh&#34;] imagePullPolicy: IfNotPresent env: - name: ROOK_CEPH_USERNAME valueFrom: secretKeyRef: name: rook-ceph-mon key: ceph-username - name: ROOK_CEPH_SECRET valueFrom: secretKeyRef: name: rook-ceph-mon key: ceph-secret volumeMounts: - mountPath: /etc/ceph name: ceph-config - name: mon-endpoint-volume mountPath: /etc/rook volumes: - name: mon-endpoint-volume configMap: name: rook-ceph-mon-endpoints items: - key: data path: mon-endpoints - name: ceph-config emptyDir: {} tolerations: - key: &#34;node.kubernetes.io/unreachable&#34; operator: &#34;Exists&#34; effect: &#34;NoExecute&#34; tolerationSeconds: 5 启动
1 kubectl create -f toolbox.yaml 3.2 查看 ceph 状态 在确保 toolbox 启动成功后，运行以下命令进入容器
1 kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l &#34;app=rook-ceph-tools&#34; -o jsonpath=&#39;{.items[0].metadata.name}&#39;) -- bash 并在容器内执行 ceph status 命令，如果返回类似以下结果(HEALTH_OK)的话，则 ceph 启动成功
1 2 3 4 5 6 7 8 9 10 $ ceph status cluster: id: a0452c76-30d9-4c1a-a948-5d8405f19a7c health: HEALTH_OK services: mon: 3 daemons, quorum a,b,c (age 3m) mgr: a(active, since 2m) osd: 3 osds: 3 up (since 1m), 3 in (since 1m) ... 2020-10-22：由于没有空闲磁盘，rook-ceph-mon 和 rook-ceph-osd 服务都未启动成功，ceph status 报找不到服务。后续步骤无法继续。
4. 打开 Ceph Dashboard 未实现，待补充。
最后: 卸载 按安装顺序的逆序进行删除即可
1 2 3 4 5 cd rook/cluster/examples/kubernetes/ceph kubectl delete -f cluster.yaml kubectl delete -f operator.yaml kubectl delete -f common.yaml   ]]></content></entry><entry><title>Kubernetes Dashboard 安装</title><url>/post/kubernetes/dashboard/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes Dashboard 安装 本文以 Debian 10 , kubernetes 1.19 为例。 kubernetes 安装参考站内另一篇文章 Kubernetes 安装 参考资料：
官方文档: Web UI (Dashboard) 创建示例用户: Creating sample user 站内相关资料：
Kubernetes 安装 kubernetes RBAC 鉴权简单介绍 1. 部署 Kubernetes Dashboard 部署
1 kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml 通过以下命令查看服务运行情况
1 kubectl get pods -n kuberenetes-dashboard 2. 配置 Dashboard 服务的访问模式为 NodePort 使用以下命令编辑服务，这里将使用vi编辑器打开服务的yaml定义。
1 kubectl edit service kubernetes-dashboard -n kubernetes-dashboard 找到 spec 定义，修改其中两处地方，以下是示例
1 2 3 4 5 6 7 8 spec: type: NodePort # type 从 ClusterIP 改为 NodePort ports: - port: 443 targetPort: 8443 nodePort: 38080 # 增加该项，定义对外暴露的端口 selector: k8s-app: kubernetes-dashboard 3. 创建账号 按照 Creating sample user 中的示例创建账号。（注意，官方声明这个账号权限过大，仅作为演示使用，风险自担。如果了解规则的话，可以自己创建自己的账号）
认证方面的内容可以参考站内另一篇文章 kubernetes RBAC 鉴权简单介绍 3.1 创建 ServiceAccount 在命名空间 kubernetes-dashboard 下创建一个名为 admin-user 的 ServiceAccount
1 2 3 4 5 6 7 cat &lt;&lt;EOF | kubectl apply -f - apiVersion: v1 kind: ServiceAccount metadata: name: admin-user namespace: kubernetes-dashboard EOF 3.2 创建 ClusterRoleBinding 把上一步创建的 admin-user 绑定到名字为 cluster-admin 的 ClusterRole 中。这样，admin-user 就具有了 cluster-admin 角色所定义的权限。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 cat &lt;&lt;EOF | kubectl apply -f - apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: admin-user roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: admin-user namespace: kubernetes-dashboard EOF 4. 访问 Dashboard 经过第2步之后，就可以通过 https://node-ip:node-port 的方式打开 Dashboard 管理页面。这里需要有 Token 才能登录。
使用以下命令获取登录 Token
1 2 # 这里 grep admin-user 需要跟你的实际账号名一致 kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk &#39;{print $1}&#39;) 此命令会输出类似以下的信息
1 2 3 4 5 6 7 8 9 10 11 12 13 Name: admin-user-token-v57nw Namespace: kubernetes-dashboard Labels: &lt;none&gt; Annotations: kubernetes.io/service-account.name: admin-user kubernetes.io/service-account.uid: 0303243c-4040-4a58-8a47-849ee9ba79c1 Type: kubernetes.io/service-account-token Data ==== ca.crt: 1066 bytes namespace: 20 bytes token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXY1N253Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwMzAzMjQzYy00MDQwLTRhNTgtOGE0Ny04NDllZTliYTc5YzEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.Z2JrQlitASVwWbc-s6deLRFVk5DWD3P_vjUFXsqVSY10pbjFLG4njoZwh8p3tLxnX_VBsr7_6bwxhWSYChp9hwxznemD5x5HLtjb16kI9Z7yFWLtohzkTwuFbqmQaMoget_nYcQBUC5fDmBHRfFvNKePh_vSSb2h_aYXa8GV5AcfPQpY7r461itme1EXHQJqv-SN-zUnguDguCTjD80pFZ_CmnSE1z9QdMHPB8hoB4V68gtswR1VLa6mSYdgPwCHauuOobojALSaMc3RH7MmFUumAgguhqAkX3Omqd3rJbYOMRuMjhANqd08piDC3aIabINX6gP5-Tuuw2svnV6NYQ 复制最后 token 的内容，粘贴到 Dashboard 登录页面上，就能成功登录进去了。
  ]]></content></entry><entry><title>kubernetes RBAC 鉴权简单介绍</title><url>/post/kubernetes/rbac/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  kubernetes RBAC 鉴权简单介绍 本文内容截取自官方文档，用于备忘与快速理解，完整信息请参考官方文档。
参考资料：
kubernetes 使用 RBAC 鉴权 1. 简介 基于角色（Role）的访问控制（RBAC）是一种基于企业中用户的角色来调节控制对计算机或网络资源的访问方法。
RBAC 使用 rbac.authorization.k8s.io API 组 来驱动鉴权操作，允许管理员通过 Kubernetes API 动态配置策略。
在 1.8 版本中，RBAC 模式是稳定的并通过 rbac.authorization.k8s.io/v1 API 提供支持。
2. 角色 Role 角色有两种:
Role ClusterRole Role 作用域为某个命名空间(namespace)上 。 而 ClusterRole 作用域为整个集群。
Role 定义示例
1 2 3 4 5 6 7 8 9 apiVersion: rbac.authorization.k8s.io/v1 # api 组 kind: Role # 类型 metadata: namespace: default # 作用到 default 命名空间 name: pod-reader # 名称 rules: - apiGroups: [&#34;&#34;] # &#34;&#34; 指定核心 API 组 resources: [&#34;pods&#34;] verbs: [&#34;get&#34;, &#34;watch&#34;, &#34;list&#34;] ClusterRole 定义示例
1 2 3 4 5 6 7 8 9 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole # 类型 metadata: # 此处的 &#34;namespace&#34; 被省略掉是因为 ClusterRoles 是没有命名空间的。 name: secret-reader rules: - apiGroups: [&#34;&#34;] resources: [&#34;secrets&#34;] verbs: [&#34;get&#34;, &#34;watch&#34;, &#34;list&#34;] 3. 角色绑定 RoleBinding 角色绑定也有两种:
RoleBinding ClusterRoleBinding RoleBinding 用来在指定的命名空间中执行授权。它可以引用同一命名空间中的 Role ，也可以引用 ClusterRole 。 当 RoleBingding 引用 ClusterRole 时，可以允许管理者在整个集群中定义一组通用的角色，然后在多个命名空间中重用它们。
ClusterRoleBinding 用来在集群级别或对所有命名空间执行授权。它只可以引用 ClusterRole 。
RoleBinding 定义示例
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 此角色绑定使得用户 &#34;jane&#34; 能够读取 &#34;default&#34; 命名空间中的 Pods apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: read-pods namespace: default # 作用到 default 命名空间 subjects: - kind: User # 用户信息 name: jane # 名称区分大小写 apiGroup: rbac.authorization.k8s.io roleRef: kind: Role # 这里可以是 Role 或者 ClusterRole name: pod-reader # 这里的名称必须与你想要绑定的 Role 或 ClusterRole 名称一致 apiGroup: rbac.authorization.k8s.io ClusterRoleBinding 定义示例
1 2 3 4 5 6 7 8 9 10 11 12 13 # 这个集群角色绑定允许 &#34;manager&#34; 组中的任何用户读取任意命名空间中 &#34;secrets&#34;。 apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: read-secrets-global subjects: - kind: Group name: manager # 名称区分大小写 apiGroup: rbac.authorization.k8s.io roleRef: kind: ClusterRole name: secret-reader apiGroup: rbac.authorization.k8s.io 注意： 你不能修改绑定对象所引用的 Role 或 ClusterRole 。 试图改变绑定对象的 roleRef 将导致验证错误。想要改变现有绑定对象中 roleRef 字段的内容，必须删除并重新创建绑定对象。
4. 聚合集群角色 Aggregated ClusterRoles 略。见官网 ( https://kubernetes.io/zh/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles )
5. 对资源的引用 即上面角色的示例中， rules 定义的那部分。
略。待补充。
6. 对主体的引用 即上面角色绑定的示例中， roleRef 定义的那部分。
RoleBinding 或者 ClusterRoleBinding 需要绑定角色到主体。 主体可以是组(Group)，用户(User)或者服务账户(ServiceAccount)。
自定义的用户和组不能使用 system: 作为前缀。
系统保留的一些账号和组：
system:serviceaccount: 服务账号的用户名前缀 system:serviceaccounts: 服务账号的用户组名前缀 system:authenticated 所有认证过的用户 system:unauthenticated 所有未认证的用户   ]]></content></entry><entry><title>tmux 常用命令一览</title><url>/post/linux/tmux/</url><categories><category>linux</category></categories><tags><tag>linux</tag></tags><content type="html"><![CDATA[  tmux 常用命令一览 一、 session 相关 1. 创建新的 session
1 2 3 4 # 直接运行 tmux ，不指定 session 名字 ，session 名字将会以数字命名，从 0 开始自动递增。 tmux # 创建特定名字的 session tmux new -s &lt;name&gt; 2. 从 session 中脱离 (session 仍会在后台运行)
在 session 里面按组合键 Ctrl b + d 。
( Ctrl b 为 tmux 默认的前缀键，用于触发它内部的快捷键，可通过配置文件修改。 )
3. 列出正在运行的 session
1 tmux ls 4. 重新进入 session
1 2 # name 可以不输全，只输入前两三个字符就可以了 tmux a -t &lt;name&gt; 5. 重命名 session
在 session 里面运行 Ctrl b + $
二、 window 相关 一个 session 里面可以打开多个 window 。当需要运行多个后台程序时，即可以创建多个 session ，也可以在一个 session 中创建多个 window ，两种使用方式没有什么区别。
以下命令都是在 session 内运行，主要介绍快捷键的方式，命令方式可以自行查看 help
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 以树型列出所有 session 和 window Ctrl b + s # 创建 window (create-window) Ctrl b + c # 跳到下一个 window (next-window) Ctrl b + n # 跳到上一个 window (previous-window) Ctrl b + p # 跳到上一次的 window (last-window) Ctrl b + l # 跳到指定序号的 window Ctrl b + &lt;数字&gt; # window 重命名 Ctrl b + , 三、 panel 相关 前面介绍了 session 和 window ，不过用前面的方式，一屏只能运行一个终端。如果想在一屏内显示运行多个终端，则需要使用 panel 。 panel 是对 window 进行分割显示。
以下命令都是在 session 内运行，主要介绍快捷键的方式，命令方式可以自行查看 help
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 左右分割 window Ctrl b + % # 上下分割 window Ctrl b + &#34; # 跳到上一次的 panel (last-panel) Ctrl b + ; # panel 之间跳转 Ctrl b + &lt;上下左右方向键&gt; # 当前 panel 与上一个 panel 进行交换位置 Ctrl b + { # 当前 panel 与下一个 panel 进行交换位置 Ctrl b + } 四、其他 1 2 3 4 5 6 7 8 9 10 11 # 显示快捷键列表 Ctrl b + ? # 显示 时钟 面板 (time) Ctrl b + t # 进入 copy-mode (常用来查看之前的输出信息) Ctrl b + [ # 命令模式 (输入并执行 tmux 命令) Ctrl b + :   ]]></content></entry><entry><title>Kubernetes 安装</title><url>/post/kubernetes/install/</url><categories><category>kubernetes</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  Kubernetes 安装 本文以 Debian 10 为例，进行 Kubernetes 的安装讲解。
参考资料：
kubernetes安装（国内环境） 每天5分钟玩转 Docker 容器技术 1. 安装 docker 和 kubernetes 每台电脑都需要安装。参考本篇文章 Linux 新系统安装配置清单 里安装 docker 和 kubernetes 的步骤。
2. 准备阶段(所有服务器) 2.1 关闭 swap 运行 kubernetes 需要关闭 swap 。
使用以下命令临时关闭 swap
1 sudo swapoff -a 永久关闭可以直接编辑 /etc/fstab ， 把 swap 的挂载部分注释掉。
2.2 提前拉取所需镜像(可忽略，已集成到下面初始化命令中) 由于众所周知的原因，直接初始化 k8s 可能拉取不到镜像，这里先手动拉取一次，加速后续的初始化步骤。
1 2 3 4 5 6 7 8 9 10 11 12 13 # 查看所需镜像 kubeadm config images list # 使用国内代理拉取镜像 kubeadm config images pull --image-repository=registry.cn-hangzhou.aliyuncs.com/google_containers # 镜像重命名 for tag in `docker images --format &#34;![.Repository](.Repository):![.Tag](.Tag)&#34; | grep registry.cn-hangzhou.aliyuncs.com/google_containers`; do new_tag=${tag/registry.cn-hangzhou.aliyuncs.com\/google_containers/k8s.gcr.io} docker tag ${tag} ${new_tag} docker rmi ${tag} done 3. 初始化(主 master 服务器) 使用 root 账号执行：
1 2 3 4 5 6 kubeadm init --pod-network-cidr=10.244.0.0/16 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers # --pod-network-cidr=10.244.0.0/16 表示使用 flannel 网络 # 可以通过参数 --apiserver-advertise-address 192.168.56.105 指定监听ip # --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers # 使用国内代理拉取镜像，后续子节点也是从该代理获取镜像，一次配置即可。 4. 配置授权信息(主 master 服务器) 推荐使用普通账号，平时只用普通账号来控制 k8s 。
1 2 3 4 5 6 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config # 启用 kubectl 命令的自动补全功能 echo &#34;source &lt;(kubectl completion bash)&#34; &gt;&gt; ~/.bashrc 5. 加入集群(node 服务器) 在 node 服务器上执行 kubeadm join 语句，该语句在初始化后会显示出来。
6. 安装 flannel (主 master 服务器) 1 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 其他: 可能会用到的控制命令 1 2 3 4 5 6 7 8 9 10 11 kubectl get nodes # 查看节点状态 kubectl describe nodes &lt;ip&gt; # 查看单个 node 信息 kubectl get pods # 查看运行的镜像 kubectl get pods --all-namespaces # 查看所有命名空间的 pod kubectl get deployments # 查看部署情况 kubectl get services # 查看运行的服务 kubectl apply -f app.yml # 应用 kubectl delete -f app.yml # 删除 kubeadm reset # 重置 (退出集群) 其他: 可能出现的问题 由于 kube-proxy 与 nftables 有兼容性问题(官方说已解决，待验证)。如果系统用的是 iptables 且 iptables 用的是 nftables ，建议把 iptables 改成 legacy 版本。
1 2 3 4 5 # 参考 https://wiki.debian.org/iptables update-alternatives --set iptables /usr/sbin/iptables-legacy update-alternatives --set ip6tables /usr/sbin/ip6tables-legacy update-alternatives --set arptables /usr/sbin/arptables-legacy update-alternatives --set ebtables /usr/sbin/ebtables-legacy   ]]></content></entry><entry><title>Linux 新系统安装配置清单</title><url>/post/linux/new_install/</url><categories><category>linux</category></categories><tags><tag>linux</tag></tags><content type="html"><![CDATA[  Linux 新系统安装配置清单 主要以 debian 系统为示例
一、 bash 配置 /root/.bashrc
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 PS1=&amp;#39;\n${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ &amp;#39; # If this is an xterm set the title to user@host:dir case &amp;#34;$TERM&amp;#34; in xterm*|rxvt*) PS1=&amp;#34;\[\e]0;${debian_chroot:+($debian_chroot)}\u@\h \a\]$PS1&amp;#34; ;; *) ;; esac export LS_OPTIONS=&amp;#39;--color=auto&amp;#39; eval &amp;#34;`dircolors`&amp;#34; alias ls=&amp;#39;ls $LS_OPTIONS&amp;#39; alias ll=&amp;#39;ls $LS_OPTIONS -lh&amp;#39; alias rm=&amp;#39;rm -i&amp;#39; alias cp=&amp;#39;cp -i&amp;#39; alias mv=&amp;#39;mv -i&amp;#39; 二、 公共组件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 备份原来的 sources.list DATE_TIME_NOW=`date +&amp;#34;%Y%m%d_%H%M&amp;#34;` mv /etc/apt/sources.list /etc/apt/sources.list.bak_${DATE_TIME_NOW} # 设置 sources.list ，使用清华的镜像源 cat &amp;lt;&amp;lt; \EOF &amp;gt; /etc/apt/sources.list deb https://mirrors.tuna.tsinghua.edu.cn/debian buster main contrib non-free deb …  ]]></content></entry><entry><title>Mysql 踩坑及优化笔记</title><url>/post/software/mysql_faq/</url><categories><category>software</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[  Mysql 踩坑及优化笔记 Q: server has gone away 排查方向：
查看 server 端的 wait_timeout 1 mysql&gt; show global variables like &#39;%timeout%&#39;; client 端使用连接池，并把连接池的超时检测值设置为小于 wait_timeout 的值。 Q: 使用了 order by limit 语句导致查询慢 排查方向：
查看执行计划 1 explain select ... 检查 session 数，是不是有太多并发连接 1 mysql&gt; show processlist; 变更 sql 语句 1 2 3 4 5 6 SELECT * FROM large ORDER BY id LIMIT 10000, 30 -- 变更为 (id加到条件里) SELECT * FROM large WHERE id &gt; 10000 ORDER BY id LIMIT 30 -- 或 SELECT * FROM large WHERE id &gt;=(SELECT id FROM large ORDER BY id LIMIT 10000, 1) ORDER BY id LIMIT 30   ]]></content></entry><entry><title>acme.sh 使用备注</title><url>/post/software/acme_sh/</url><categories><category>software</category></categories><tags><tag>acme.sh</tag><tag>letsencrypt</tag><tag>ssl</tag></tags><content type="html"><![CDATA[  acme.sh 使用备注 官方网站： https://github.com/acmesh-official/acme.sh 1. 使用 aliyun 直接注册证书 使用 ecc 算法
1 2 3 4 export Ali_Key=&#34;&#34; export Ali_Secret=&#34;&#34; acme.sh --issue -d example.com --keylength ec-256 --dns dns_ali 2. 使用别名方式注册证书 使用 ecc 算法
1 2 3 4 export Ali_Key=&#34;&#34; export Ali_Secret=&#34;&#34; acme.sh --issue -d example.com --keylength ec-256 --dns dns_ali --challenge-alias example2.com 3. 安装到 nginx 1 2 3 4 acme.sh --install-cert --ecc -d example.com \ --key-file /path/to/keyfile/in/nginx/key.pem \ --fullchain-file /path/to/fullchain/nginx/cert.pem \ --reloadcmd &#34;service nginx force-reload&#34; 4. 删除证书 1 acme.sh --remove --ecc -d example.com   ]]></content></entry><entry><title>Shadowsocks 安装指南</title><url>/post/software/ss_install/</url><categories><category>software</category></categories><tags><tag>shadowsocks</tag><tag>docker</tag></tags><content type="html"><![CDATA[  Shadowsocks 安装指南 1. 简介 shadowsocks 原版是使用 python 开发的，后来推出了其他语言实现的版本。这里推荐使用 shadowsocks-libev 版本，这是 C 语言的实现版，运行速度更快，占用资源更少。
shadowsocks-libev 主要包含以下组件：
ss-server (服务端-单用户) ss-local (客户端) ss-manager (服务端-多用户) ss-tunnel ss-redir (转发-可做透明代理) ss-nat 参考资料: https://github.com/shadowsocks/shadowsocks-libev 这里主要介绍前三个组件的使用，其他组件待补充。
1.1 ss-server ss-server 是服务端程序。它跟 python 版本的 ssserver 类似，不过它不再支持 &amp;ldquo;port_password&amp;rdquo; 的配置，变成了单端口单用户模式。
示例配置如下：
1 2 3 4 5 6 7 8 9 10 { &amp;#34;server&amp;#34;: &amp;#34;0.0.0.0&amp;#34;, &amp;#34;server_port&amp;#34;: 8388, &amp;#34;password&amp;#34;: &amp;#34;password&amp;#34;, &amp;#34;timeout&amp;#34;: 60, &amp;#34;method&amp;#34;: &amp;#34;chacha20-ietf-poly1305&amp;#34;, &amp;#34;user&amp;#34;: &amp;#34;nobody&amp;#34;, &amp;#34;fast_open&amp;#34;: true, &amp;#34;reuse_port&amp;#34;: true } 关键参数：
参数 解释 server 服务器监听地址，一般可设为 0.0.0.0 。 server_port 服务器监听端口。 password 密码。 method 加密方式。推荐使用 chacha20-ietf-poly1305 。 1.2 ss-manager python 版本的 ssserver 既是单端口单用户程序，也是多端口多用户。 而 libev 版本做了区分，把多端口多用户做成了 ss-manager 。
示例配置如下：
1 2 3 4 5 6 7 8 9 10 11 { &amp;#34;server&amp;#34;: …  ]]></content></entry><entry><title>Git 设置代理</title><url>/post/software/git_proxy/</url><categories><category>software</category></categories><tags><tag>git</tag></tags><content type="html">  Git 设置代理 1. 设置代理 全局代理
1 git config --global http.proxy 127.0.0.1:1080 局部代理
在 git 仓库内执行
1 git config --local http.proxy 127.0.0.1:1080 注意：
这里的 127.0.0.1:1080 只是示例，代理地址请按实际情况填写。 无论仓库的地址是 http 还是 https ，都是使用 http.proxy 这个设置。 2. 取消代理 1 2 git config --global --unset http.proxy git config --local --unset http.proxy 3. 查询当前代理设置 1 2 3 4 5 6 7 8 # 查询全局代理 git config --global http.proxy # 查询局部代理 git config --local http.proxy # 查询所有设置 git config -l   </content></entry><entry><title>Maven 镜像配置</title><url>/post/java/maven_mirror/</url><categories><category>java</category></categories><tags><tag>java</tag><tag>maven</tag></tags><content type="html"><![CDATA[  Maven 镜像配置 参考： https://maven.aliyun.com 全局 修改 ~/.m2/settings.xml 或者 maven 安装目录下的 conf/settings.xml 文件，在 mirrors 配置中加上如下代码
1 2 3 4 5 6 7 8 9 &lt;mirrors&gt; &lt;!-- 阿里云仓库 --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/central&lt;/url&gt; &lt;/mirror&gt; &lt;/mirrors&gt; 单个项目 在项目的 pom.xml 中添加
1 2 3 4 5 6 7 8 9 10 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;https://maven.aliyun.com/repository/central&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt;   ]]></content></entry><entry><title>Node.js 安装说明</title><url>/post/nodejs/install/</url><categories><category>nodejs</category></categories><tags><tag>nodejs</tag><tag>electron</tag></tags><content type="html">  Node.js 安装说明 安装 参考资料：
https://nodejs.org/en/ https://github.com/nodesource/distributions/blob/master/README.md For Debian / Ubuntu
Node.js LTS (v16.x)
1 2 curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - apt-get install nodejs Node.js v13.x:
1 2 curl -sL https://deb.nodesource.com/setup_13.x | sudo -E bash - sudo apt-get install nodejs Node.js v12.x:
1 2 curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - sudo apt-get install nodejs 设置 npm 代理 国内使用 npm 速度很慢，你可以使用淘宝的代理服务器来加速下载。
1 npm config set registry https://registry.npm.taobao.org 也可以安装淘宝定制的 cnpm (gzip 压缩支持) 命令行工具代替默认的 npm ，后续直接使用 cnpm 来进行安装模块。
1 2 3 4 npm install -g cnpm --registry=https://registry.npm.taobao.org # 使用 cnpm 安装模块 cnpm install [name] 若代理使用的是自签证证书，则在下载包时会报证书错误。此时需要使用环境变量来指定信任证书（不建议把证书验证选项关闭）。
1 2 3 4 5 # linux 。 以下是使用系统证书，若使用其他证书，路径请按实际情况设定。 export NODE_EXTRA_CA_CERTS=/etc/ssl/certs/ca-certificates.crt # windows cmd set NODE_EXTRA_CA_CERTS=C:\\path\\to\\certificate.pem 设置 npm electron 代理 1 npm config set ELECTRON_MIRROR https://npmmirror.com/mirrors/electron/   </content></entry><entry><title>Prometheus 安装指南</title><url>/post/software/prometheus_install/</url><categories><category>software</category></categories><tags><tag>prometheus</tag><tag>linux</tag><tag>grafana</tag><tag>docker</tag></tags><content type="html">  Prometheus 安装指南 1. 准备工作 推荐使用一个普通用户运行 prometheus 。
1 2 3 useradd -m -s /bin/bash prometheus su - prometheus # 切换用户 2. Prometheus 2.1 下载 打开网址 https://prometheus.io/download/ 找到 prometheus 下载那部分，找相应的版本下载。
然后解压到 /home/prometheus/prometheus 目录中。
2.2 配置系统服务 以 root 用户新建文件 /etc/systemd/system/prometheus.service
1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description=Prometheus Server Documentation=https://prometheus.io/docs/introduction/overview/ After=network-online.target [Service] User=prometheus Restart=on-failure #Change this line if you download the #Prometheus on different path user ExecStart=/home/prometheus/prometheus/prometheus \ --config.file=/home/prometheus/prometheus/prometheus.yml \ --storage.tsdb.path=/home/prometheus/prometheus/data [Install] WantedBy=multi-user.target 2.3 创建配置文件 创建配置文件 /home/prometheus/prometheus/prometheus.yml
以下是一份示例，从官方的 docker 版本里拿的配置文件。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # my global config global: scrape_interval: …  </content></entry><entry><title>Docker 配置代理</title><url>/post/docker/docker_config/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>proxy</tag></tags><content type="html"><![CDATA[  Docker 配置代理 一、 docker 使用国内镜像源 编辑文件 /etc/docker/daemon.json
1 2 3 4 5 6 { &#34;registry-mirrors&#34;: [ &#34;https://registry.docker-cn.com&#34;, &#34;http://hub-mirror.c.163.com&#34; ] } 然后重启 docker 服务
1 systemctl restart docker 二、 docker 配置 http 代理 2020-10-21 补充。推荐使用该方式
参考资料： https://docs.docker.com/config/daemon/systemd/ 创建目录 1 mkdir -p /etc/systemd/system/docker.service.d 创建文件 1 vim /etc/systemd/system/docker.service.d/http-proxy.conf 编写文件内容 1 2 3 4 [Service] Environment=&#34;HTTP_PROXY=http://proxy.example.com:80&#34; Environment=&#34;HTTPS_PROXY=https://proxy.example.com:443&#34; Environment=&#34;NO_PROXY=localhost,127.0.0.1,docker-registry.example.com&#34; 上述内容是示例，HTTP_PROXY 和 HTTPS_PROXY 中的 host 和 port 需要按实际情况填写。 NO_PROXY 定义的是不走代理的 host 列表，按需要增加。
重启服务 1 2 systemctl daemon-reload systemctl restart docker 确认是否生效 1 2 3 systemctl show --property=Environment docker Environment=HTTP_PROXY=http://proxy.example.com:80 HTTPS_PROXY=https://proxy.example.com:443 NO_PROXY=localhost,127.0.0.1,docker-registry.example.com,   ]]></content></entry><entry><title>安装 Office 2019</title><url>/post/windows/office_2019_install/</url><categories><category>windows</category></categories><tags><tag>windows</tag><tag>office</tag></tags><content type="html"><![CDATA[  安装 Office 2019 下载 Office Deployment Tool Office Deployment Tool 是微软官方的 Office 部署工具，可以直接在官网下载
Office Deployment Tool Office 部署工具概述 该工具很小，官网下载只有3M不到，运行后会解压出来一个 setup.exe 和一些 xml 配置文件。 这个 setup.exe 就是今天的主角。
编辑配置文件 setup.exe 的运行需要配置文件，官方自带了一些配置文件，可以直接使用，也可以自定义。 如果不知道自定义的规则，可以使用官方的在线自定义配置文件功能： office 客户端配置 这里贴一份本人使用的配置文件，仅当备忘。该配置包含了 Office 全部组件 , Visio , Project 。
Office_2019_VL_setup.xml 文件内容：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 &lt;Configuration ID=&#34;39fb4981-dc87-41ab-9a2d-6b0ab1691f16&#34;&gt; &lt;Add OfficeClientEdition=&#34;64&#34; Channel=&#34;PerpetualVL2019&#34;&gt; &lt;Product ID=&#34;ProPlus2019Volume&#34; PIDKEY=&#34;NMMKJ-6RK4F-KMJVX-8D9MJ-6MWKP&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;VisioPro2019Volume&#34; PIDKEY=&#34;9BGNQ-K37YR-RQHF2-38RQ3-7VCBB&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;ProjectPro2019Volume&#34; PIDKEY=&#34;B4NPR-3FKK7-T2MBV-FRQ4W-PKD2B&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;/Product&gt; &lt;Product ID=&#34;LanguagePack&#34;&gt; &lt;Language ID=&#34;zh-cn&#34; /&gt; &lt;/Product&gt; &lt;/Add&gt; &lt;Property Name=&#34;AUTOACTIVATE&#34; Value=&#34;0&#34; /&gt; &lt;Updates Enabled=&#34;FALSE&#34; /&gt; &lt;Display Level=&#34;Full&#34; AcceptEULA=&#34;TRUE&#34; /&gt; &lt;/Configuration&gt; 下载镜像 首次安装时，需要先下载安装包内容。 运行如下命令
1 setup.exe /download Office_2019_VL_setup.xml setup.exe 会在当前目录下创建一个 Office 目录，并从网上下载 office 的安装包内容。
安装 Office 下载的内容中没有 exe 来直接运行安装，还是需要用这个 setup.exe 来进行安装。
1 setup.exe /configure Office_2019_VL_setup.xml 该命令会根据配置文件直接安装 office ，全程不需要干预。
激活 嗯，这个应该是大家比较关心的。方法比较多，自己找去吧8-) 。 (可以参考 Windows 激活使用说明 )
  ]]></content></entry><entry><title>ssh config 说明</title><url>/post/linux/ssh_config/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>ssh</tag></tags><content type="html">  ssh config 说明 使用说明 使用 ssh 连接时，经常需要输入命令 ssh user@host 。服务器少的时候还能记在脑中，当服务器多了起来，这就是一个心智负担了。
可以通过增加 ssh config 配置，解决这个问题。
新建文件 ~/.ssh/config ，增加类似以下配置的片段
1 2 3 4 5 6 7 8 9 Host server1 HostName 192.168.1.101 User root Host server2 HostName 192.168.1.102 User root Port 22 IdentityFile ~/.ssh/id_rsa 后续使用 ssh 连接时，可以直接使用命令 ssh server1 ，还支持 tab 键补全。
使用该方法，一方面减少了输入量，另一方面不再需要额外记住各个服务器的用户名和 ip ，省时省力，值得推荐。
FAQ 1. 使用时出现 Bad owner or permissions on ~/.ssh/config 错误
检查该 config 文件的权限，它应该只允许用户自己读写，其他用户不能访问。可能使用以下命令解决：
1 2 chmod 600 ~/.ssh/config chown $USER ~/.ssh/config   </content></entry><entry><title>常用 python 包列表</title><url>/post/python/requirement_list/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html">  常用 python 包列表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 numpy scipy pandas matplotlib sklearn opencv-python pillow jupyterlab pylint autopep8 pipenv virtualenvwrapper   </content></entry><entry><title>Debian 在安全启动模式下如何正确加载模块</title><url>/post/linux/secure_boot/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>secureboot</tag></tags><content type="html">  Debian 在安全启动模式下如何正确加载模块 参考资料
Debian Secure Boot Initial Shim 以 nvidia 驱动为例，安装驱动时，安装程序提示现在已经开启了安全启动模式，是否需要对生成的驱动进行签名，这时选择是，并使用合适的密钥进行签名。 相应的密钥记得要保存好。
1. 导入密钥
使用命令进行导入密钥
1 2 # 这里是导入公钥 mokutil --import MOK.der 该命令会要求输入密码，该密码在下一个步骤中验证时使用。
2. 确认导入
重启系统，由于有未验证的驱动，此时系统会停留在 MOK 管理器界面。
此时选择 enroll MOK ，并在后续输入上一步中设置的密码，再次重启即可正常加载。
注意
签名的密钥对记得做好备份，后续更新 kernel 需要重新安装 nvidia 驱动，并使用该 key 签名。 安装的驱动不能使用 dkms 更新。   </content></entry><entry><title>Debian 10 UEFI 相关</title><url>/post/linux/debian_uefi/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>uefi</tag></tags><content type="html">  Debian 10 UEFI 相关 bios 未识别出 uefi 分区 最近在新磁盘上安装 debian 10 时，出现过安装完成后，bios 未识别出 uefi 分区，从而系统不能正常启动的问题。
根据官网( https://wiki.debian.org/UEFI )介绍，正确的 uefi 启动文件的命名路径为：
1 \EFI\$vendor\$bootloader.efi 对于 debian 10 ， 需要加载的 efi 文件为：
1 2 3 4 5 Architecture Path amd64 \EFI\debian\grubx64.efi i386 \EFI\debian\grubia32.efi arm64 \EFI\debian\grubaa64.efi armhf \EFI\debian\grubarm.efi 对于便携设备来说，默认是加载以下的 efi 文件：
1 2 3 4 5 Architecture Path amd64 \EFI\boot\bootx64.efi i386 \EFI\boot\bootia32.efi arm64 \EFI\boot\bootaa64.efi armhf \EFI\boot\bootarm.efi 由于某些 bios 的 uefi 启动程序有 bug ，不认 $vendor 底下的内容，只去 boot 目录底下查找 boot*.efi 。 因此 debian 无法正常 启动。 windows 系统会默认把自己的 efi 拷贝一份到 boot 目录中， debian 没有参考这种做法。因此，如果出现这种问题，需要手工创建 boot 目录，把 grub*.efi 移动到 boot 目录，并重命名成 boot*.efi 即可。
  </content></entry><entry><title>iptables</title><url>/post/linux/iptables/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>iptables</tag></tags><content type="html">  iptables 下面列出一段比较通用的服务器 iptable 设置
1 2 3 4 5 6 7 8 9 10 11 12 # 允许回环地址 iptables -A INPUT -i lo -j ACCEPT # 允许已建立的连接 iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT # 允许自定义的端口进行 TCP 通讯，按需要增减 iptables -A INPUT -p tcp -m multiport --dports 22,443,8388:8400 -j ACCEPT # 允许自定义的端口进行 UDP 通讯，按需要增减 # iptables -A INPUT -p udp -m multiport --dports 53 -j ACCEPT # 允许 ping 包 iptables -A INPUT -p icmp -j ACCEPT # 其余都禁止 iptables -A INPUT -j DROP 附一份比较通俗易懂的 iptables 介绍文档。 ( http://www.zsythink.net/archives/tag/iptables/ )
  </content></entry><entry><title>恢复 windows server 和 win10 ltsb 的图片查看功能</title><url>/post/windows/photo_viewer/</url><categories><category>windows</category></categories><tags><tag>windows</tag></tags><content type="html"><![CDATA[  恢复 windows server 和 win10 ltsb 的图片查看功能 (参考连接: https://jingyan.baidu.com/article/14bd256e40e472bb6c26125b.html )
以管理员身份运行命令提示符（cmd.exe）
在命令提示符输入以下命令并运行即可：
1 2 3 4 5 FTYPE Paint.Picture=%SystemRoot%\System32\rundll32.exe &#34;%ProgramFiles%\Windows Photo Viewer\PhotoViewer.dll&#34;, ImageView_Fullscreen %1 FTYPE jpegfile=%SystemRoot%\System32\rundll32.exe &#34;%ProgramFiles%\Windows Photo Viewer\PhotoViewer.dll&#34;, ImageView_Fullscreen %1 FTYPE pngfile=%SystemRoot%\System32\rundll32.exe &#34;%ProgramFiles%\Windows Photo Viewer\PhotoViewer.dll&#34;, ImageView_Fullscreen %1   ]]></content></entry><entry><title>virtualenvwrapper 安装配置说明</title><url>/post/python/virtualenvwrapper/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html"><![CDATA[  virtualenvwrapper 安装配置说明 virtualenvwrapper 是对 python 虚拟环境的使用进行了简单的封装，更方便用户使用虚拟环境。
1. 安装与配置 1.1 Linux 安装
1 sudo pip3 install virtualenvwrapper 编译 /etc/bash.bashrc 文件，增加以下语句
1 2 3 4 5 if [ -f /usr/local/bin/virtualenvwrapper.sh ]; then export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3 export WORKON_HOME=&#39;~/.virtualenvs&#39; source /usr/local/bin/virtualenvwrapper.sh fi 1.2 Windows 安装
1 pip install virtualenvwrapper-win 增加一个环境变量 WORKON_HOME ，自定义虚拟环境保存路径，如 D:\python_venvs\ 。(默认保存在 C:\Users&lt;user&gt;\Evns 目录下)
2. 使用说明 1 2 3 mkvirtualenv &lt;name&gt; # 创建一个虚拟环境 workon &lt;name&gt; # 激活虚拟环境 deactivate # 退出虚拟环境   ]]></content></entry><entry><title>Python 设置 PYPI 私服说明</title><url>/post/python/pip_setting/</url><categories><category>python</category></categories><tags><tag>python</tag><tag>pip</tag></tags><content type="html"><![CDATA[  Python 设置 PYPI 私服说明 私服设置 Linux 下编辑文件 /etc/pip.conf 或者 ~/.pip/pip.conf ， Windows 下编辑文件 C:\ProgramData\pip\pip.ini 或者 %USERPROFILE%\pip\pip.ini 或者 %APPDATA%\pip\pip.ini， 添加 extra-index-url 修改 index-url
私服在找不到包时，会替我们到外面找包，因此只需要一个 index-url 即可
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [global] # 豆瓣源 # index-url = https://pypi.douban.com/simple # 清华源 index-url = https://pypi.tuna.tsinghua.edu.cn/simple # 阿里云源 # index-url = https://mirrors.aliyun.com/pypi/simple # 私服url # extra-index-url = http://192.168.0.200:8080/simple # 私服url # index-url = http://192.168.0.200:8080/root/public # trusted-host = 192.168.0.200 [search] # index = http://192.168.0.200:8080/root/public 然后直接使用 pip install 即可。
由于 python 默认没有使用系统的证书，如果需要 python 使用系统的证书，则在 ~/.bashrc 中增加如下设置： (对于 windows 系统，还是先使用上面的 trusted-host 设置吧)
1 export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt 某些情况下，由于 pip 已经缓存了一个不可用地址，导致即使私服里存在对应的包，也抛出找不到包的错误。这时可以尝试添加 --no-cache-dir 选项进行忽略已有缓存，完整命令为 pip install --no-cache-dir &lt;pkg&gt; 。
镜像上传方式介绍 编辑文件 ~/.pypirc
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [distutils] index-servers = # pypi local #注意上面必须有缩进 #[pypi] #username:&lt;your_pypi_username&gt; #password:&lt;your_pypi_passwd&gt; [local] # repository: http://192.168.0.200:8080 # 注意下面这个 url 后面必须带 / repository: http://192.168.0.200:8080/root/public/ username: &lt;some_username&gt; password: &lt;some_passwd&gt; 上传命令
1 2 3 4 5 6 7 8 9 10 11 12 # python setup.py register -r local # python setup.py sdist upload -r local # 以上命令已废弃，推荐使用下列命令 # 打包 python3 setup.py sdist bdist_wheel # 检查 twine check dist/* # 上传 twine upload -r local dist/*   ]]></content></entry><entry><title>dokuwiki 安装 (使用 docker)</title><url>/post/software/dokuwiki_install_by_docker/</url><categories><category>software</category></categories><tags><tag>docker</tag><tag>dokuwiki</tag></tags><content type="html"><![CDATA[  dokuwiki 安装 (使用 docker) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 version: &#39;3&#39; services: dokuwiki: image: &#39;bitnami/dokuwiki:latest&#39; ports: - &#39;80:80&#39; #environment: # - TZ=Asia/Shanghai volumes: - dokuwiki:/bitnami - certs:/certs volumes: dokuwiki: certs:   ]]></content></entry><entry><title>EasyPR 编译使用说明 (Debian)</title><url>/post/software/easypr/</url><categories><category>software</category></categories><tags><tag>easypr</tag><tag>opencv</tag></tags><content type="html">  EasyPR 编译使用说明 (Debian) EasyPR 是一个车牌识别库，识别率高，功能齐全，非常适合直接拿来使用。 官方地址： https://github.com/liuruoze/EasyPR 这里记录一下 EasyPR 在 Linux 底下编译及再次封装供 Python 使用的过程。
一、准备工作 安装相应的编译工具包
1 sudo apt install build-essential cmake 二、编译 OpenCV EasyPR 依赖于 OpenCV ，且其官方未提供 Linux 版本的 OpenCV 二进制库，因此需要自行编译。对于 EasyPR 项目，最新测试通过的 OpenCV 版本为 3.4.8， 下面以 OpenCV 3.4.8 版本为例。
2.1 下载 方法1. 从 OpenCV 官方 下载页面 找到 3.4.8 版本的 Source 包，并下载解压。
方法2. 从 github 上签出所有源码。
1 2 3 4 5 6 7 8 9 # 下载 git clone https://github.com/opencv/opencv.git cd opencv # 查看 tag 列表 git tag # 签出特定版本。 git checkout 3.4.8 2.2 编译 这里假设把源码放在了 ~/src/opencv 目录下，路径按自己实际路径。
编译方式：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 进入 opencv 源码的上层路径。 cd ~/src # 在 opencv 源码的同级目录下创建一个 opencv-build-3.4.8 目录。 没有在 opencv 里面创建 build 目录，是方便后续 checkout 其他版本时，还保留当前编译好的版本。 mkdir opencv-build-3.4.8 cd opencv-build-3.4.8 # cmake # 1. 由于是跟 opencv 同级，所以源码路径为 ../opencv 。 # 2. 安装目录设置为自己的 home 目录，方便随时删除，而且 make install 不需要 sudo 权限。 # 3. ippicv 下载较慢，使用本地共享中的文件。 # 4. 不编译 cuda 。 # …  </content></entry><entry><title>slim库中的预处理方法分析</title><url>/post/tensorflow/slim_preprocessing/</url><categories><category>tensorflow</category></categories><tags><tag>tensorflow</tag></tags><content type="html">  slim库中的预处理方法分析 research/slim/preprocessing/cifarnet_preprocessing.py 源码 对图片的预处理过程为：
训练数据集：
对图片进行填充。（tf.pad） 按指定大小随机裁剪图像。（tf.random_crop） 随机水平翻转。（tf.image.random_flip_left_right） 随机亮度。（tf.image.random_brightness） 随机对比度。 （tf.image.random_contrast） 图像标准化。 （tf.image.per_image_standardization） 验证数据集:
图片裁剪或填充至指定大小。（tf.image.resize_image_with_crop_or_pad） 图像标准化。 （tf.image.per_image_standardization） research/slim/preprocessing/inception_preprocessing.py 源码 对图片的预处理过程为：
训练数据集:
添加标注框（tf.image.draw_bounding_boxes）。 随机裁剪原图像的一部分（ 使用 tf.image.sample_distorted_bounding_box 为图像生成单个随机变形的边界框，并用tf.slice 进行裁剪）。 缩放图片到指定大小（tf.image.resize_images， 第3个参数method随机指定）。 随机水平翻转（tf.image.random_flip_left_right）。 随机扭曲颜色（tf.image.random_brightness 随机亮度， tf.image.random_saturation 随机饱和度， tf.image.random_hue 随机色相， tf.image.random_contrast 随机对比度， tf.clip_by_value 随机完之后重新把值限定到0和1之间）。 图片减去0.5，即 tf.subtract(image, 0.5)。 图片乘以2，即 tf.multiply(image, 2.0)。 验证数据集：
裁剪图片，只要中间87.5%区域（tf.image.central_crop）。 使用双线性插值法缩放图片到指定大小 …  </content></entry><entry><title>06 - Tensorflow Serving 使用说明</title><url>/post/tensorflow/06_serving/</url><categories><category>tensorflow</category></categories><tags><tag>tensorflow</tag></tags><content type="html"><![CDATA[  06 - Tensorflow Serving 使用说明 本文大部分是对官网的描述做些备注和个人理解。如有需要，请直接查看官网原文。
https://tensorflow.google.cn/serving/serving_basic?hl=zh-CN (官方网址)
前置知识： 建议阅读 05 - Tensorflow 模型保存与恢复 1. 准备工作 一般来说，算法开发人员负责设计和训练模型，而运维人员（或业务开发人员）负责把模型导出并部署到线上。那么在设计时，由于个人习惯或各部门规范不同，模型所使用的输入名称有可能会相差甚远。更不用说有时候网络结构是从网上找来的。以上的种种情况，都会导致 Tensor 的输入输出名称难以做到统一，形成规范，给部署带来一定的麻烦。
因此，Tensorflow 支持在使用 saved_model 模块导出模型时，给输入和输出起个“别名”，达到不改变模型源码的情况下，形成一套规范的目的。
请看以下示例，使用 saved_model 导出模型的一般性代码为：
1 2 3 4 5 6 7 8 9 import tensorflow as tf builder = tf.saved_model.builder.SavedModelBuilder(export_dir=&amp;#34;/path/to/save/model&amp;#34;) builder.add_meta_graph_and_variables( sess, [tf.saved_model.tag_constants.SERVING], strip_default_attrs=True) builder.save() 此时，如果原来模型的 input_tensor 为 &amp;ldquo;X&amp;rdquo;，output_tensor 为 &amp;ldquo;Y&amp;rdquo;，那么，我们只能通过文档或者其他方式告诉以后的使用者，输入输出的名称和形状分别是什么。
使用 saved_model 导出带签名(signature)的模型：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import tensorflow as tf # 假设模型的输入是X，最终输出是Y # …  ]]></content></entry><entry><title>05 - Tensorflow 模型保存与恢复</title><url>/post/tensorflow/05_saved_model/</url><categories><category>tensorflow</category></categories><tags><tag>tensorflow</tag></tags><content type="html"><![CDATA[  05 - Tensorflow 模型保存与恢复 本文大部分是对官网的描述做些备注和个人理解。如有需要，请直接查看官网原文。
https://tensorflow.google.cn/programmers_guide/saved_model (英文原版)
https://tensorflow.google.cn/programmers_guide/saved_model?hl=zh-CN (中文原版)
1. 保存与恢复变量 （即 Checkpoint） 1.1 保存变量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import tensorflow as tf # build network # ... # define checkpoint saver saver = tf.train.Saver() with tf.Session() as sess: # init variables sess.run(tf.global_variables_initializer()) # 保存 checkpoint saver.save(sess, save_path=&amp;#34;/path/to/save/checkpoints&amp;#34;, global_step=tf.train.get_global_step()) 说明： save_path 是到文件名层面的。若保存路径设为&amp;quot;/data/model&amp;quot;，则 checkpoint 的文件以&amp;quot;/data/model-{global_step}&amp;ldquo;开头。一次会生成三个文件，分别以&amp;quot;data-00000-of-00001&amp;rdquo;、&amp;ldquo;index&amp;rdquo;、&amp;ldquo;meta&amp;quot;为扩展名。
如 save_path 为&amp;rdquo;/data/model&amp;quot;，step 为 100 时，生成&amp;quot;/data/model-100.data-00000-of-00001&amp;quot;、&amp;quot;/data/model-100.index&amp;quot;、&amp;quot;/data/model-100.meta&amp;quot;三个文件。
使用 estimator 时，开发者不需要关心 checkpoint 的保存和恢复。 …  ]]></content></entry><entry><title>02 - Tensorflow Object Detection 环境快速安装及更新脚本</title><url>/post/tensorflow/02_preinstall_models_for_object_detection/</url><categories><category>tensorflow</category></categories><tags><tag>tensorflow</tag></tags><content type="html"><![CDATA[  02 - Tensorflow Object Detection 环境快速安装及更新脚本 该脚本用于快速准备好 object detection 所需要的代码环境。
如脚本运行出错，则确保已安装 git, protobuf-compiler, make, python3 以及 python 下的 cython, matplotlib 。
更多说明请参考:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md quick_install_models.sh 文件内容：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 #!/bin/bash # Description: 快速更新至最新 tensorflow-models 代码 # Author: liujun # Date: 2019-05-28 set -e if [ ! -d &#34;./models&#34; ]( ! -d &#34;./models&#34; ); then # 如果未存在 models ，则先下载 echo &#34;== 01 == 未找到 models 目录，准备下载。&#34; git clone https://github.com/tensorflow/models.git echo &#34;== 02 == 下载 models 完毕。&#34; else # 还原并更新代码 echo &#34;== 01 == 还原并更新 models 代码开始。&#34; cd models git reset --hard git clean -xdf git checkout master git pull cd .. echo &#34;== 02 == 还原并更新 models 代码完毕。&#34; fi # 如果未存在 cocoapi ，则先下载 if [ ! -d &#34;./cocoapi&#34; ]( ! -d &#34;./cocoapi&#34; ); then echo &#34;== 03 == 未找到 cocoapi 目录，准备下载。&#34; git clone https://github.com/cocodataset/cocoapi.git echo &#34;== 04 == 下载 cocoapi 完毕。&#34; else # 还原并更新代码 echo &#34;== 03 == 还原并更新 cocoapi 代码开始。&#34; cd cocoapi git reset --hard git clean -xdf git checkout master git pull cd .. echo &#34;== 04 == 还原并更新 cocoapi 代码完毕。&#34; fi # 编译 cocoapi 并拷贝到 models 中。 echo &#34;== 05 == 准备编译 cocoapi 。&#34; cd ./cocoapi/PythonAPI # make python3 setup.py build_ext --inplace rm -rf build cd ../../ echo &#34;== 06 == 编译 cocoapi 完毕。&#34; rm -rf ./models/research/pycocotools/ cp -a ./cocoapi/PythonAPI/pycocotools ./models/research/pycocotools echo &#34;== 07 == 已拷贝 cocoapi 至 models 中。&#34; # 编译 models object detection 。 echo &#34;== 08 == 准备编译 object detection 。&#34; cd ./models/research protoc ./object_detection/protos/*.proto --python_out=. cd ../../ echo &#34;== 09 == 编译 object detection 完毕。&#34;   ]]></content></entry><entry><title>Windows 激活使用说明</title><url>/post/windows/windows_act/</url><categories><category>windows</category></categories><tags><tag>windows</tag></tags><content type="html"><![CDATA[  Windows 激活使用说明 以管理员的身份打开 cmd ，执行下述命令。以下命令中的 &lt;ip&gt; 需要替换为真实的激活服务器地址。
Windows
1 2 3 slmgr.vbs -skms &lt;ip&gt; slmgr.vbs -ato slmgr.vbs -dlv Office x86
1 2 3 4 cd \Program Files (x86)\Microsoft Office\Office16 cscript ospp.vbs /sethst:&lt;ip&gt; cscript ospp.vbs /act cscript ospp.vbs /dstatusall Office x86_64
1 2 3 4 cd \Program Files\Microsoft Office\Office16 cscript ospp.vbs /sethst:&lt;ip&gt; cscript ospp.vbs /act cscript ospp.vbs /dstatusall GVLK keys
1 2 3 Windows: https://technet.microsoft.com/en-us/library/jj612867(v=ws.11).aspx Office 2013: https://technet.microsoft.com/en-us/library/dn385360.aspx Office 2016: https://technet.microsoft.com/en-us/library/dn385360(v=office.16).aspx 参考资料：
vlmcsd 安装指南 https://github.com/Wind4/vlmcsd https://hub.docker.com/r/mikolatero/vlmcsd/   ]]></content></entry><entry><title>基于 LDAP 的 PAM 验证</title><url>/post/linux/pam_ldap/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>ldap</tag></tags><content type="html">  基于 LDAP 的 PAM 验证 参考资料：
https://wiki.debian.org/LDAP/PAM https://wiki.debian.org/LDAP/NSS https://wiki.samba.org/index.php/Nslcd https://uit.stanford.edu/service/directory/pam/local-home https://stackoverflow.com/questions/30725840/active-directory-and-linux-nslcd-binding-without-extending-the-ad-schema https://blogs.technet.microsoft.com/activedirectoryua/2016/02/09/identity-management-for-unix-idmu-is-deprecated-in-windows-server/ 一、前言 Linux 可以通过 PAM (Pluggable Authentication Modules, 可插入认证模块)来提供认证功能，不少系统服务认证是通过 pam 来进行。 pam 的配置文件放在 /etc/pam.d/ 目录下， 其中以 common 开关的配置文件是通用认证，里面通过 pam_unix.so 模块来进行认证，该模块读取 /etc/passwd 、 /etc/shadow 等系统配置信息，做到与系统账号同步。
通过 debian 的 wiki 可以知道，目前有两个包可以实现 pam_ldap 功能的，分别是 libpam-ldap 和 libpam-ldapd (注意，后面这个包名称后面多了个&amp;amp;rsquo;d&amp;#39;)
其中， 后者(libpam-ldapd)是更新的解决方案，但是前者配置上比较简单。
二、libpam-ldap (无法调通，放弃，仅做记录) 安装
1 apt install libpam-ldap 与 libpam-ldap 相关的几个配置文件：
/etc/ldap/ldap.conf （系统级 ldap 配置文件） /etc/pam_ldap.conf 安装完毕后，该包会修改 /etc/pam.d/ 目录下的几个 common 开头的配置文件，加入跟 …  </content></entry><entry><title>Git 合并经验总结</title><url>/post/software/git_merge_exp/</url><categories><category>software</category></categories><tags><tag>git</tag></tags><content type="html">  Git 合并经验总结 合并提交log 一、 主要方式： rebase merge（推荐）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 转到子分支（源分支） git checkout develop # 使用 rebase 合并 log。 -i 是交互式。 git rebase -i master # 转回主分支（目标分支） git checkout master # 合并 develop # 方式一：带一条 merge 记录 git merge --no-ff develop # 方式二：不带 merge 记录 git merge develop 二、 另一种方式：squash merge（不推荐）
1 2 3 4 5 6 7 8 # 转到主分支（目标分支） git checkout master # 合并 develop。 这里只是把代码拉过来，但并未提交。 git merge --squash develop # 再 commit 。 这时日志就能自己定了。 git commit 优缺点：
第一种方式 保留了原作者信息，同时也能合并历史 log ，值得推荐作为管理者的首要方式。
第二种方式 由于只是拉取了代码，提交是管理者再次提交，所以会丢失原作者信息。不推荐。 但是还是有可以应用的场景，如只是一个人开发，然后需要合并分支和 log 时，可以用这种简便方式。
  </content></entry><entry><title>Git 删除历史记录中的大文件</title><url>/post/software/git_delete_large_history/</url><categories><category>software</category></categories><tags><tag>git</tag></tags><content type="html">  Git 删除历史记录中的大文件 1. 查看历史记录中最大的10个文件id 。
1 git verify-pack -v .git/objects/pack/pack-*.idx | sort -k 3 -g | tail -10 列出的结果有四列，第一列是object-id，下面要使用；第二列是文件大小，单位是字节；第三列是压缩后的大小；第四列是起始数据偏移量。
2. 根据 object-id 查看是哪个文件。
1 git rev-list --objects --all | grep {object-id} 3. 从历史记录中去掉该文件。
1 git filter-branch --force --prune-empty --index-filter &amp;#39;git rm -rf --cached --ignore-unmatch {your-file-name}&amp;#39; --tag-name-filter cat -- --all 4. 提交变更。
注意要加 &amp;ndash;force 。
1 git push --force --all 5. 清除（重建）本地缓存。
1 2 3 4 rm -Rf .git/refs/original rm -Rf .git/logs/ git gc git prune   </content></entry><entry><title>docker 基本使用</title><url>/post/docker/docker_usage/</url><categories><category>docker</category></categories><tags><tag>docker</tag></tags><content type="html">  docker 基本使用 帮助（信息齐全，没事可以看看）
1 docker help docker 最常用的几个概念
1 2 3 4 image 镜像。别人或者自己打包和发布的程序，只读。 container 容器。镜像运行起来的实例，一个镜像可以同时运行多个（容器）实例。 network 网络。多个容器可以通过关联同一个网络来组合成一个局域网。 volume 卷。 容器里的数据需要通过卷来持久化，否则把一个容器删除之后，里面的数据就全丢了。 每个都有对应的增删查命令(create ls inspect rm)
常用命令一览，说明见后文或者自行查询：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 日常使用系列 docker pull - 拉取镜像 docker images - 列出所有镜像 docker rmi - 删除镜像 docker run - 运行镜像，创建一个容器 docker rm - 删除容器 docker start | stop | restart - 启动/停止/重启 容器 # debug 系列 docker inspect - 查看所有对象的详细信息 docker logs - 查看容器运行日志 docker exec - 在一个运行中的容器内执行命令 # 开发者系列 docker build - 创建镜像 docker tag - 给镜像打标签 docker push - 上传镜像 docker save - 导出镜像 docker load - 加载镜像 image相关:
1 2 3 4 5 6 7 8 9 10 11 12 docker help image - 查看镜像相关命令。 docker image ls - 列出所有镜像。 可简写成 docker images 。 docker image pull - 从网上拉取镜像。 可简写成 docker pull 。 docker image push - 上传自己的镜像。 可简写成 docker push 。 docker image rm - 删除本地的镜像。当镜像在运行时，镜像不允许删除。 可简写成 docker rmi 。 docker image inspect - 显示镜像详细信息。 可简写成 docker …  </content></entry><entry><title>Docker Swarm 集群使用备忘</title><url>/post/docker/docker_swarm_usage/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>docker swarm</tag></tags><content type="html">  Docker Swarm 集群使用备忘 建立集群 1. 主 manager 初始化 主 manager 节点通过 docker swarm init 初始化集群
1 2 3 4 5 6 7 8 $ manager1: docker swarm init --advertise-addr 192.168.1.101 Swarm initialized: current node (n0ub7dpn90rxjq97dr0g8we0w) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-envtxo4dl6df2ar3qldcccfdg 192.168.1.101:2377 To add a manager to this swarm, run &amp;#39;docker swarm join-token manager&amp;#39; and follow the instructions. 2. worker 加入 其他 worker 节点通过给出的命令加入集群
1 2 $ node1: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-envtxo4dl6df2ar3qldcccfdg 192.168.1.101:2377 This node joined a swarm as a worker. 3. 次 manager 加入 次 manager 节点通过在主 manager 上运行以下命令获取以 manager 身份加入集群的命令
1 2 3 4 $ manager1: docker swarm join-token manager To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-0koz1b98sco8r5cn3g61eahnu 192.168.1.101:2377 1 2 $ manager2: docker swarm join --token SWMTKN-1-5uwpqibnvmho1png8zmhcw8274yanohee32jyrcjlait9djhsk-0koz1b98sco8r5cn3g61eahnu 192.168.1.101:2377 This node joined a swarm as a manager. 常用命令一览 docker machine 常用命令 命令 说明 docker-machine create 创建一个 Docker 主机（常用-d virtualbox） docker-machine ls 查看所有的 Docker 主机 docker-machine ssh SSH 到主机上执行命令 docker-machine env 显示连接到某个主机需要的环境变量 docker-machine inspect 输出主机更多信息 docker-machine start 启动一个主机 docker-machine stop 停止一个主机 docker-machine restart 重启某台主机 docker-machine kill 停止某个主机 docker-machine rm 删除某台主机 docker-machine status 查看主机状态 docker-machine scp 在主机之间复制文件 eval $(docker-machine env manager1) 配置 docker 连接到远程主机 eval $(docker-machine env -u) 配置 docker 取消连接到远程主机 docker swarm 常用命令 命令 说明 docker swarm init 初始化集群 docker swarm join-token worker 查看工作节点的 token docker swarm join-token manager 查看管理节点的 token docker swarm join 加入集群中 docker node 常用命令 命令 说明 docker node ls 查看所有集群节点 docker node rm 删除某个节点（-f强制删除） docker node inspect 查看节点详情 docker node demote 节点降级，由管理节点降级为工作节点 docker node promote 节点升级，由工作节点升级为管理节点 docker node update 更新节点 docker node ps 查看节点中的 Task 任务 docker service 常用命令 命令 说明 docker service create 部署服务 docker service inspect 查看服务详情 docker service logs 产看某个服务日志 docker service ls 查看所有服务详情 docker service rm 删除某个服务（-f强制删除） docker service scale 设置某个服务个数 docker service update 更新某个服务 docker stack 常用命令 命令 说明 docker stack deploy 部署新的堆栈或更新现有堆栈 docker stack ls 列出现有堆栈 docker stack ps 列出堆栈中的任务 docker stack rm 删除堆栈 docker stack services 列出堆栈中的服务 docker stack down 移除某个堆栈（不会删除数据）   </content></entry><entry><title>docker 推荐软件列表</title><url>/post/docker/docker_recommend/</url><categories><category>docker</category></categories><tags><tag>docker</tag></tags><content type="html">  docker 推荐软件列表 registry - docker 私有仓库 官网： https://docs.docker.com/registry/ https://docs.docker.com/registry/deploying/ docker 私有仓库，官方出品，必属精品。
运行方式:
1 2 3 4 5 6 docker run -d \ -p 5000:5000 \ --restart=always \ --name registry \ -v /mnt/registry:/var/lib/registry \ registry 提交到私有仓库示例:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 从Docker Hub官网拉取镜像。 $ docker pull ubuntu:16.04 # 重新打标签，记得加上私有仓库ip和端口。具体含义见 docker 镜像命名方式。 $ docker tag ubuntu:16.04 localhost:5000/my-ubuntu # 提交镜像到私有仓库。 $ docker push localhost:5000/my-ubuntu # 本机可以删除掉缓存的原标签。 $ docker image remove ubuntu:16.04 # 后续拉取镜像可从私有仓库拉取。 $ docker pull localhost:5000/my-ubuntu portainer - docker web 管理工具 官网： https://www.portainer.io https://hub.docker.com/r/portainer/portainer docker 管理工具 web 版，管理员通过浏览器访问 9000 端口进行控制 docker 。
单机版通过 socket 跟主机 docker 进行通信获取信息，运行和挂载命令如下：
1 2 3 docker run -d -p 9000:9000 \ -v /var/run/docker.sock:/var/run/docker.sock \ portainer/portainer 集群版未实验，参见其他网上文档。
vlmcsd 不多说，自行搜索这是什么东西。
官方说明： https://hub.docker.com/r/mikolatero/vlmcsd 运行方式:
1 docker run -d -p 1688:1688 --restart=always --name vlmcsd mikolatero/vlmcsd OnlyOffice - 开源 office 最佳方案 OnlyOffice 是开源 office 里做得比较大的，它有三大 Server： Document Server, Mail Server, Community Server 。 三件套整合起来可以撑起办公半边天。
这里只用了 Document Server ，其跟 Nextcloud 、 seafile 等结合，可以让私有云在线编辑 office 文档，做到协同办公。
docker 使用方式介绍页： https://hub.docker.com/r/onlyoffice/documentserver 运行方式示例:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 docker run -i -t -d -p 8380:80 -p 8343:443 \ --restart=always \ -v /ext/data/docker-volumes/onlyoffice/DocumentServer/logs:/var/log/onlyoffice \ -v /ext/data/docker-volumes/onlyoffice/DocumentServer/data:/var/www/onlyoffice/Data \ -v /ext/data/docker-volumes/onlyoffice/DocumentServer/lib:/var/lib/onlyoffice \ -v /ext/data/docker-volumes/onlyoffice/DocumentServer/db:/var/lib/postgresql \ -v /ext/data/docker-volumes/onlyoffice/DocumentServer/default.json:/etc/onlyoffice/documentserver/default.json \ --name onlyoffice_ds \ onlyoffice/documentserver # -e CA_CERTIFICATES_PATH=/var/www/onlyoffice/Data/certs/ca.crt \ # -e SSL_VERIFY_CLIENT=true \ # 需要把data下的default.json 替换到 /etc/onlyoffice/documentserver 下 # 参考： https://github.com/ONLYOFFICE/Docker-DocumentServer/issues/96 通过浏览器访问对应端口，显示 &amp;ldquo;Document Server is running&amp;rdquo; 即为成功。
其他两个组件视情况选用。
mysql - 数据库 mysql 是最常用的数据库之一，属于基础组件，不多做介绍。使用 docker 部署省时省力，可以针对开发、测试、发布分别运行单独的 docker 实例，隔离无压力。群集暂不在考虑范围内。
这里使用的 mariadb 代替 mysql： https://hub.docker.com/_/mariadb 快速启动示例:
1 2 3 4 5 # 快速启动并暴露端口： docker run -d --name mysql-test -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 mariadb # 如果需要把数据保存在外面： docker run -d --name mysql-test -v /local/dir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 mariadb phpmyadmin - mysql web 管理工具 老牌 mysql web 管理工具。
仓库网址： https://hub.docker.com/r/phpmyadmin/phpmyadmin 快速启动示例:
1 2 # --link 参数前段是 mysql 的实例 name ，见上一段 mysql 的启动命令 docker run -itd --name phpmyadmin --link mysql-test:db -p 8080:80 phpmyadmin/phpmyadmin   </content></entry><entry><title>Devpi 常用操作</title><url>/post/software/devpi_note/</url><categories><category>software</category></categories><tags><tag>devpi</tag><tag>python</tag></tags><content type="html"><![CDATA[  Devpi 常用操作 client 1 2 3 4 5 6 7 8 9 10 11 12 13 # 切换仓库地址 devpi use http://localhost:8580/root/public # 登录 devpi login &lt;user&gt; # 列出仓库中的包 devpi list devpi list &lt;package_name&gt; devpi list --all &lt;package_name&gt; # 删除仓库中的包 devpi remove &lt;package_name&gt;==&lt;version&gt;   ]]></content></entry><entry><title>Linux 常用系统命令列表</title><url>/post/linux/linux_commands/</url><categories><category>linux</category></categories><tags><tag>linux</tag></tags><content type="html"><![CDATA[  Linux 常用系统命令列表 系统信息 1 2 3 4 5 6 7 8 9 10 uname -a # 查看内核和操作系统信息 hostname # 查看计算机名。修改可编辑 /etc/hostname cat /proc/cpuinfo # 查看 CPU 信息 env # 查看环境变量 lsmod # 列出加载的内核模块 uptime # 查看系统运行时间、用户数、负载 ps -ef # 查看所有进程 crontab -l # 查看当前用户的计划任务服务 硬件设备 1 2 3 lspci # 列出所有 PCI 设备 (可加参数 -t 或 -v) lsusb # 列出所有 USB 设备 (可加参数 -t 或 -v) sudo dmidecode # 显示服务器硬件和 BIOS 信息 (可查询到内存条信息) 内存和交换分区 1 2 3 4 free # 查看内存使用量和交换区使用量 cat /proc/meminfo # 查看内存信息 swapon # 查看所有交换分区 磁盘和占用空间 1 2 3 4 5 6 df -h # 查看各分区使用情况 du -sh &lt;目录名&gt; # 查看指定目录的大小 mount # 查看挂载的分区 sudo fdisk -l # 查看所有磁盘 网络 1 2 3 ip addr # 查看本机 ip 地址 sudo iptables -L # 查看防火墙设置 lsof -i:port # 查看端口占用 用户登录日志 1 2 3 4 5 6 7 id &lt;用户名&gt; # 查看指定用户信息 w # 查看当前活动用户（详细） users # 查看当前活动用户（只显示用户名） last # 查看用户登录日志。二进制日志: /var/log/wtmp lastlog # 查看用户最后一次的登录信息。二进制日志: /var/log/lastlog   ]]></content></entry><entry><title>各内部系统连接 ldaps 而导入可信根证书的操作步骤</title><url>/post/ssl/trusted_certs_config/</url><categories><category>ssl</category></categories><tags><tag>ssl</tag><tag>ldap</tag></tags><content type="html">  各内部系统连接 ldaps 而导入可信根证书的操作步骤 前言 由于使用了自签署证书，如果系统间连接需要使用 ssl ，难免会产生证书是否可信的问题。内部系统中主要是使用了 ldaps 进行账号验证，因此需要指明可信根证书的位置。
1. dokuwiki (PHP) dokuwiki 属于 php 应用，连接 ldap 主要使用了 php 的 adLDAP 扩展。
该扩展没有自己的配置文件，大部分配置信息通过参数传入。 而证书的配置未在参数中。
经过查询，其使用了系统 ldap 的相关配置进行 ldap 连接。 因此可以修改文件 /etc/ldap/ldap.conf ，达到为 php 应用设置可信证书的目的
1 2 3 4 sudo vi /etc/ldap/ldap.conf #修改该文件里的如下内容，使其指向自己的根证书： TLS_CACERT	/etc/ssl/certs/my_ca.crt 2. jira (JAVA) jira 主要使用了 java 进行编写，因此可信证书的导入需要用到 keytool 工具。用法介绍： JAVA 导入信任证书 (Keytool 的使用) jira 的 keystore 文件路径为：
1 /opt/atlassian/jira/jre/lib/security/cacerts 3. gitlab gitlab 高度集成，通过单一配置文件完成大量工作。
经过摸索，发现可直接把证书文件放到 /etc/gitlab/trusted-certs/ 目录中，然后执行
1 sudo gitlab-ctl reconfigure 更新配置，系统会自动识别证书文件，并创建链接到 /opt/gitlab/embedded/ssl/certs/ 目录中。
参考： https://docs.gitlab.com/omnibus/settings/ssl.html 验证 ldap 是否可用，可以使用以下命令进行检查：
1 sudo gitlab-rake gitlab:ldap:check 4. 把证书导入到系统的 ca-certificates 中 1 2 sudo cp ./MY_CA.crt /usr/local/share/ca-certificates/ sudo update-ca-certificates   </content></entry><entry><title>使用 openssl 生成证书</title><url>/post/ssl/openssl_manual/</url><categories><category>ssl</category></categories><tags><tag>ssl</tag><tag>openssl</tag></tags><content type="html"><![CDATA[  使用 openssl 生成证书 1. 前置知识 KEY 通常指私钥。
CSR 是 Certificate Signing Request 的缩写，即证书签名请求，这不是证书，只是包含申请证书的基本信息。生成证书时要把这个提交给权威的证书颁发机构，颁发机构审核通过之后，再根据这些申请信息生成相应的证书。
CRT 即 certificate的缩写，即证书。
X.509 是一种证书格式.对X.509证书来说，认证者总是CA或由CA指定的人，一份X.509证书是一些标准字段的集合，这些字段包含有关用户或设备及其相应公钥的信息。
X.509的证书文件，一般以.crt结尾，根据该文件的内容编码格式，可以分为以下二种格式：
PEM - Privacy Enhanced Mail，打开看文本格式，以&amp;quot;&amp;mdash;&amp;ndash;BEGIN&amp;hellip;&amp;ldquo;开头，&amp;rdquo;&amp;mdash;&amp;ndash;END&amp;hellip;&amp;ldquo;结尾，内容是 BASE64 编码。Apache 和 *NIX 服务器偏向于使用这种编码格式。
DER - Distinguished Encoding Rules，打开看是二进制格式，不可读。Java 和 Windows 服务器偏向于使用这种编码格式。
2. 生成一份 CA 根证书 1) 创建私钥 1 2 3 // 输出 key 密钥文件。 openssl genrsa -des3 -out ca.key 2048 // 长度为2048 参数说明：
genras 使用 rsa 算法生成密钥。 -des3 （可选）加密密钥，此时需要设置密码，后续使用该密钥时需要验证密码才能使用。 -out 生成私钥文件。 2) 生成证书请求文件(CSR) 1 2 3 // 输入 key 文件， 输出 csr 请求文件。 openssl req -new -key ca.key -out ca.csr 参数说明：
req 产生证书签发申请命令。 -new 新的申请。 -key 输入的 key 文件，由第一步生成。 -out 输出为 CSR 文件，这是一个请求文件。 运行此命令后进入交互模式，需要输入一些证书信息。
一般需要输入的信息如下：
C 国家 ST 省份 L 市 O 机构 OU 部门 CN (Common Name) 一般是域名 …  ]]></content></entry><entry><title>Nginx SSL 优化配置方法</title><url>/post/ssl/nginx_config/</url><categories><category>ssl</category></categories><tags><tag>ssl</tag><tag>nginx</tag></tags><content type="html"><![CDATA[  Nginx SSL 优化配置方法 参考：
https://wiki.mozilla.org/Security/Server_Side_TLS#Nginx https://mozilla.github.io/server-side-tls/ssl-config-generator/ 其中：
HSTS 慎用 http2 优势明显，但是不适合于 nginx 当反向代理的情况。比较适合的情况是，如 php 这类直接解析的。非代理的情况下建议用 http2 。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 server { listen 80 default_server; listen [::]:80 default_server; # Redirect all HTTP requests to HTTPS with a 301 Moved Permanently response. return 301 https://$host$request_uri; } server { listen 443 ssl http2; listen [::]:443 ssl http2; # certs sent to the client in SERVER HELLO are concatenated in ssl_certificate ssl_certificate /path/to/signed_cert_plus_intermediates; ssl_certificate_key /path/to/private_key; ssl_session_timeout 1d; ssl_session_cache shared:SSL:50m; ssl_session_tickets off; # modern configuration. tweak to your needs. ssl_protocols TLSv1.2; ssl_ciphers &#39;ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA256&#39;; ssl_prefer_server_ciphers on; # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months) add_header Strict-Transport-Security max-age=15768000; # OCSP Stapling --- # fetch OCSP records from URL in ssl_certificate and cache them ssl_stapling on; ssl_stapling_verify on; ## verify chain of trust of OCSP response using Root CA and Intermediate certs ssl_trusted_certificate /path/to/root_CA_cert_plus_intermediates; resolver &lt;IP DNS resolver&gt;; .... }   ]]></content></entry><entry><title>JAVA 导入信任证书 (Keytool 的使用)</title><url>/post/ssl/keytool_qa/</url><categories><category>ssl</category></categories><tags><tag>ssl</tag><tag>java</tag><tag>keytool</tag></tags><content type="html"><![CDATA[  JAVA 导入信任证书 (Keytool 的使用) 1. 问题背景 使用 ssl 连接时，遇到不信任的证书，应用程序一般都会拒绝连接。
浏览网站时，我们可以通过在浏览器的设置中导入证书，把证书加入到信任列表中。
而在 JAVA 直接进行 SSL 连接应用时，默认没有一个界面来导入证书。JAVA 进行不信任的 ssl 连接时，会报如下异常：
1 javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target 这时候，就要找到一种方式，在 JAVA 的运行环境中导入信任证书。
2. 诊断方式 参照链接：
https://confluence.atlassian.com/kb/unable-to-connect-to-ssl-services-due-to-pkix-path-building-failed-779355358.html 以上链接中提供了一种方式，用于诊断你的 Java 环境中是否包含了相应的信任证书。此方式可诊断 HTTPS, IMAPS, LDAPS 等。
下载 SSLPoke.class(原始地址) 或 。如下载 SSLPoke.zip ，需要解压得到 SSLPoke.class 文件，后续使用是需要用到 SSLPoke.class 。
运行如下命令，诊断连接是否可信。
1 $JAVA_HOME/bin/java SSLPoke jira.example.com 443 其中 java 是你要使用的 java 环境，后面是你要诊断的 url 和 port 。
如果连接成功，则出现如下结果： 1 2 $JAVA_HOME/bin/java SSLPoke jira.example.com 443 Successfully connected 而连接失败时，则出现如下异常： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387) at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292) at sun.security.validator.Validator.validate(Validator.java:260) at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324) at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229) at sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:124) at sun.security.ssl.ClientHandshaker.serverCertificate(ClientHandshaker.java:1351) at sun.security.ssl.ClientHandshaker.processMessage(ClientHandshaker.java:156) at sun.security.ssl.Handshaker.processLoop(Handshaker.java:925) at sun.security.ssl.Handshaker.process_record(Handshaker.java:860) at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:1043) at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1343) at sun.security.ssl.SSLSocketImpl.writeRecord(SSLSocketImpl.java:728) at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:123) at sun.security.ssl.AppOutputStream.write(AppOutputStream.java:138) at SSLPoke.main(SSLPoke.java:31) Caused by: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target at sun.security.provider.certpath.SunCertPathBuilder.build(SunCertPathBuilder.java:145) at sun.security.provider.certpath.SunCertPathBuilder.engineBuild(SunCertPathBuilder.java:131) at java.security.cert.CertPathBuilder.build(CertPathBuilder.java:280) at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:382) ... 15 more 补充： 此方式还能诊断 LDAPS 等 SSL 连接， 如 LDAPS 常用 636 端口：
1 2 $JAVA_HOME/bin/java SSLPoke ldap.example.com 636 Successfully connected 3. 解决方式 Java 使用了一种叫 keystore 的文件来存储证书 (默认是位于 $JAVA_HOME/lib/security/cacerts) 。 该文件使用 keytool 工具去管理 (该工具默认位于 $JAVA_HOME/bin/keytool)。
keytool 工具的使用不在这里展开，网上有比较详细的说明。这里主要列举几个会用到的命令。
命令1，列出 keystore 中的证书。
1 keytool -list 默认情况下，它会在你的 $HOME 目录下产生一个空的 .keystore 文件。如要指定 Java 正在用的 keystore 文件，使用以下参数
1 keytool -list -keystore $JAVA_HOME/lib/security/cacerts 注意一下， keystore 文件都受 密码 保护。生成新的 keystore 文件时，会要求你输入一个新密码；而当访问一个已有的 keystore 文件时，会要求你验证密码。
$JAVA_HOME/lib/security/cacerts 的默认密码为 &ldquo;changeit&rdquo; ！！！
$JAVA_HOME/lib/security/cacerts 的默认密码为 &ldquo;changeit&rdquo; ！！！
$JAVA_HOME/lib/security/cacerts 的默认密码为 &ldquo;changeit&rdquo; ！！！
重要的事情说三遍！！！
命令2，导入证书。
1 keytool -import -alias &lt;证书别名&gt; -keystore $JAVA_HOME/jre/lib/security/cacerts -file your.crt 导入时会需要验证密码，默认密码见上面。
4.附加内容：如何获取别人的证书 参考链接： https://confluence.atlassian.com/kb/connecting-to-ssl-services-802171215.html 以 google.com 为例。
Unix 方式 1 openssl s_client -connect google.com:443 &lt; /dev/null | sed -ne &#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#39; &gt; public.crt Windows 方式 1 openssl s_client -connect google.com:443 &lt; NUL | sed -ne &#39;/-BEGIN CERTIFICATE-/,/-END CERTIFICATE-/p&#39; &gt; public.crt   ]]></content></entry><entry><title>xrdp 远程桌面配置备注</title><url>/post/software/xrdp_config/</url><categories><category>software</category></categories><tags><tag>xrdp</tag><tag>linux</tag></tags><content type="html"><![CDATA[  xrdp 远程桌面配置备注 参考 https://wiki.archlinux.org/index.php/Xrdp 1. 安装 xrdp 1 sudo apt install xrdp 2. 配置 安装完成后，可以直接使用。如果远程连接时，客户端出现黑屏，则可以修改
1 2 3 4 5 6 sudo vi /etc/X11/Xwrapper.config # Change from allowed_users=console # to allowed_users=anybody 然后重启 Xorg， 此时远程连接可以正常显示。
补充说明： 在 xfce 环境下，本地和远程登录只能二选一，xfce4-session 一个用户只能运行一个，要么是从 lightdm 启动的（本地），要么是从 xrdp-sesman 启动的（远程）。若要切换，需要从已登录那端进行 logout 。
3. 错误备忘 3.1 login failed for display 0 如果出现**&quot; login failed for display 0&quot;**的提示，则表示输入的账号或密码不正确。
3.2 Oh No ! Something has gone wrong 对于 debian 11 ，可能会在远程登录时报 &ldquo;Oh No ! Something has gone wrong&rdquo; ，则可以尝试以下解决方案
1 2 wget https://snapshot.debian.org/archive/debian/20210302T032219Z/pool/main/x/xorgxrdp/xorgxrdp_0.2.15-1_amd64.deb wget https://snapshot.debian.org/archive/debian/20210302T032219Z/pool/main/x/xrdp/xrdp_0.9.15-1_amd64.deb 1 2 sudo apt install ./xorgxrdp_0.2.15-1_amd64.deb sudo apt install ./xrdp_0.9.15-1_amd64.deb 参考： https://bytexd.com/xrdp-debian/#black-screen-oh-no-something-has-gone-wrong 3.3 /etc/xrdp/key.pem: Permission denied 当查看 xrdp 的日志，发现上述错误时，那是因为 xrdp 需要读取 /etc/ssl/private/ssl-cert-snakeoil.key 路径下的证书，确没有权限。
可以考虑把 xrdp 用户加到 ssl-cert 组中，使其可以访问上述文件。
1 sudo adduser xrdp ssl-cert 参考： https://bytexd.com/xrdp-debian/   ]]></content></entry><entry><title>vsftp 配置说明</title><url>/post/software/vsftp_config/</url><categories><category>software</category></categories><tags><tag>vsftp</tag><tag>ftp</tag></tags><content type="html">  vsftp 配置说明 vsftp 是 linux 下非常有名的一个 ftp 服务器程序。不过其配置稍微有点复杂。以下对其配置作简单说明。
先贴一段目前在用的配置（已把注释部分去掉了），本配置的效果有：
启用了虚拟用户，并把虚拟用户允许访问的路径限定在了 /data/ftp_home/$USER 目录下； 允许虚拟用户读写； 启用了 SSL ； 使用了被动传输模式，并把端口号限定在12001~12002之间。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 listen=NO listen_ipv6=YES anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 dirmessage_enable=YES use_localtime=YES xferlog_enable=YES connect_from_port_20=YES secure_chroot_dir=/var/run/vsftpd/empty pam_service_name=vsftpd # 以上基本是一些默认的配置，后面的是自定义内容，详细的说明在后面。 ftpd_banner=&amp;amp;#34;Welcome to Gulucat FTP service.&amp;amp;#34; utf8_filesystem=YES guest_enable=YES virtual_use_local_privs=YES chroot_local_user=YES user_sub_token=$USER local_root=/data/ftp_home/$USER hide_ids=YES allow_writeable_chroot=YES rsa_cert_file=/etc/ssl/certs/ftp_example_com.crt rsa_private_key_file=/etc/ssl/private/ftp_example_com.key ssl_enable=YES force_anon_data_ssl=YES force_anon_logins_ssl=YES …  </content></entry><entry><title>Nextcloud 安装备注</title><url>/post/software/nextcloud_install/</url><categories><category>software</category></categories><tags><tag>nextcloud</tag><tag>docker</tag><tag>onlyoffice</tag></tags><content type="html">  Nextcloud 安装备注 安装 待补充。
docker 方式安装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 version: &amp;amp;#39;3&amp;amp;#39; services: db: image: mariadb:latest command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW restart: always volumes: - db:/var/lib/mysql environment: - MYSQL_ALLOW_EMPTY_PASSWORD=yes - MYSQL_PASSWORD=nextcloud - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud networks: - nextcloud redis: image: redis:alpine restart: always volumes: - redis_data:/data networks: - nextcloud app: image: nextcloud:fpm-alpine restart: always volumes: - nextcloud:/var/www/html environment: - MYSQL_HOST=db - REDIS_HOST=redis - MYSQL_PASSWORD=nextcloud - MYSQL_DATABASE=nextcloud - MYSQL_USER=nextcloud depends_on: - db - redis networks: - nextcloud …  </content></entry><entry><title>Onlyoffice 安装指南</title><url>/post/software/onlyoffice_install/</url><categories><category>software</category></categories><tags><tag>onlyoffice</tag><tag>docker</tag></tags><content type="html">  Onlyoffice 安装指南 1. 安装 docker 略
2. 使用 docker 运行 onlyoffice 1 2 3 4 5 6 7 docker run -i -t -d -p 8380:80 -p 8343:443 \ -v /var/onlyoffice/DocumentServer/logs:/var/log/onlyoffice \ -v /var/onlyoffice/DocumentServer/data:/var/www/onlyoffice/Data \ -v /var/onlyoffice/DocumentServer/lib:/var/lib/onlyoffice \ -v /var/onlyoffice/DocumentServer/db:/var/lib/postgresql \ --name onlyoffice_ds \ onlyoffice/documentserver 3. 使用 ssl 证书 onlyoffice 的证书默认是加载 data 目录下的 certs/onlyoffice.crt 和 certs/onlyoffice.key ，把证书按该名字放入相应位置即可。
参考： https://github.com/ONLYOFFICE/Docker-DocumentServer 4. 自签署 https 回调问题 onlyoffice 作为一个 office 预览平台，需要被其他系统调用，也会涉及回调其他系统的地址。 当其他系统使用自签署 https 时，回调也会因为证书验证的问题而报错。
报错信息： Error: unable to verify the first certificate
解决方法：
参考： https://github.com/ONLYOFFICE/Docker-DocumentServer/issues/96 onlyoffice 使用 nodejs 去进行网络连接，证书参数是直接写在代码里的。 这里只能改 nodejs 的配置参数。
使用如下命令进入运行 onlyoffice 的 docker 容器中：
1 docker attach onlyoffice_ds 把 /etc/onlyoffice/documentserver/default.json 文件拷贝出来。（由于该容器里没有vi，因此修改只能在外部进行。可以 cp 到已经映射的目录，也可以直接输出终端。）
然后修改该文件中的这段设置 services.CoAuthoring.requestDefaults.rejectUnauthorized=false （由原来的 true 改为 false，关掉证书验证。）
把修改后的文件替换回去，重启 onlyoffice 即可。
注意： 这里改的是临时的容器，未提交容器的情况下，重新生成的容器需要重新修改。
  </content></entry><entry><title>Jupyterhub 安装指南</title><url>/post/software/jupyterhub_install/</url><categories><category>software</category></categories><tags><tag>jupyterhub</tag></tags><content type="html">  Jupyterhub 安装指南 Jupyter notebook 是一款很好用的在线开发 python 工具，不过它原生只能单用户使用，没有多用户登录功能。而 Jupyterhub 就是为解决这个问题而开发的。
一、安装 nodejs （若已安装则跳过） 参考：
https://nodejs.org/en/download/package-manager/ https://github.com/nodesource/distributions/blob/master/README.md 对于 debian 系的操作系统，推荐使用源安装：
1 2 3 4 5 6 7 8 9 10 11 # 添加源，以下版本选择一个即可。 # Node.js v12.x: curl -sL https://deb.nodesource.com/setup_12.x | sudo -E bash - # Node.js v11.x: curl -sL https://deb.nodesource.com/setup_11.x | sudo -E bash - # Node.js v10.x: curl -sL https://deb.nodesource.com/setup_10.x | sudo -E bash - # 安装 sudo apt-get update sudo apt-get install nodejs 二、安装 jupyterhub jupyterhub 支持 docker 部署，这块后续可以尝试，下面以传统的方式进行安装。
安装比较简单，直接使用 pip 和 npm 安装即可：
1 2 3 4 5 python3 -m pip install jupyterhub npm install -g configurable-http-proxy # nodeboot 可选 python3 -m pip install notebook 安装完成后，直接运行 jupyterhub 即可启动。
三、配置 jupyterhub 配置 jupyterhub 既可以直接在命令后面加参数，也可以直接写一个 python 格式的配置文件 jupyterhub_config.py ，其中配置文件中的配置项都要以 c. 开头。
使用以下命令在当前目录 /etc/jupyterhub 目录 …  </content></entry><entry><title>JIRA 7.3 安装指南 (Ubuntu 16.04)</title><url>/post/software/jira_install/</url><categories><category>software</category></categories><tags><tag>jira</tag><tag>atlassian</tag></tags><content type="html">  JIRA 7.3 安装指南 (Ubuntu 16.04) 1. 下载 jira 7.3.8 安装包 1 wget https://downloads.atlassian.com/software/jira/downloads/atlassian-jira-software-7.3.8-x64.bin 2. 下载 jira 7.3 破解包 从以下地址下载破解包：
1 略 或者从附件中获取。 (jira7.3-crack.zip)
3. 安装 mysql （若已安装则跳过） 安装 mysql :
1 sudo apt-get install mysql-server 在 mysql 命令行中运行下面命令:
1 2 3 4 5 6 -- 创建数据库： create database jira default character set utf8 collate utf8_bin; -- 添加用户并授权： grant all privileges on jira.* to jira@localhost identified by &amp;#39;password&amp;#39;; -- 刷新数据库权限： flush privileges; 4. 开始安装 运行命令：
1 sudo ./atlassian-jira-software-7.3.8-x64.bin 然后按照提示一步步设置。
安装完成后，
默认 jira 安装在 /opt/atlassian/jira 默认数据存放在 /var/atlassian/application-data/jira 默认端口 8080 (后续修改端口: ///opt/atlassian/jira/conf/server.xml//) 安装完成后暂时不要启动 jira 。
5. 进行破解 解压 jira7.3-crack.zip 破解包，得到两个文件：
atlassian-extras-3.2.jar (破解文件，替换同名文件) mysql-connector-java-5.1.39-bin.jar (mysql驱动) 把这两个文件复制到 /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/ 目录中。
6. 初始化 jira 启动 jira , 打开页面 http://localhost:8080 ，进入系统安装页面。
第一步，选择自己设置，用于生产环境。 第二步，配置数据库，根据实际需求填写。（还支持postgresql, oracle, ms sql server）(后续修改数据库配置： ///var/atlassian/application-data/jira/dbconfig.xml//) 第三步，填写系统名称和 url 。 第四步，输入许可证。 这里点击 “生成 JIRA 试用许可证” 链接，到官网申请一个试用许可证，再填到这里。 第五步，设置管理员账户。 第六步，设置邮件发送服务器。(可以选择以后再设置) 初始化完成。
由于之前已经替换了破解文件，这里在许可证界面看到的服务截止时间已经改为到2033年，相当于不受试用时间限制了。
7. 使用 nginx 进行端口转发 参照官方文档： https://confluence.atlassian.com/jirakb/integrating-jira-with-nginx-426115340.html   </content></entry><entry><title>dokuwiki 安装指南 (基于 Ubuntu 16.04 和 php 7.0)</title><url>/post/software/dokuwiki_install/</url><categories><category>software</category></categories><tags><tag>dokuwiki</tag></tags><content type="html">  dokuwiki 安装指南 (基于 Ubuntu 16.04 和 php 7.0) 1、安装 nginx （若已安装则跳过） 运行命令:
1 sudo apt-get install nginx 编辑 /etc/nginx/nginx.conf 文件，把 server_tokens off 前的注释删除，防止暴露 nginx 和服务器的版本号
2、安装 php （若已安装则跳过） 运行命令:
1 sudo apt-get install php php-xml 3、下载 dokuwiki 源码 进入官网( https://www.dokuwiki.org/dokuwiki )下载 dokuwiki 源码， 解压到 /var/www/dokuwiki 路径下，并使用以下命令更改 dokuwiki 的目录权限 1 sudo chown -R www-data:www-data /var/www/dokuwiki 4、增加 nginx 配置 在 /etc/nginx/sites-available 目录下增加一个文件名叫 dokuwiki
1 sudo vi /etc/nginx/sites-available/dokuwiki 内容如下：(也可参考官方说明 https://www.dokuwiki.org/install:nginx )
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 server { listen 80; server_name _; # Maximum file upload size is 4MB client_max_body_size 4M; client_body_buffer_size 128k; root /var/www/dokuwiki; index index.php; # 安装结束后，启用下面这句配置，防止重新安装。 #location ~ /(data/|conf/|bin/|inc/|install.php) { deny all; } location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # location ~ \.php$ { include snippets/fastcgi-php.conf; # With php7.0-cgi alone: #fastcgi_pass 127.0.0.1:9000; # With php7.0-fpm: fastcgi_pass unix:/run/php/php7.0-fpm.sock; } # deny access to .htaccess files, if Apache&amp;#39;s document root # concurs with nginx&amp;#39;s one # location ~ /\.ht { deny all; } } 启用该站点配置，在sites-enabled目录下创建一个软链接：
1 sudo ln -s /etc/nginx/sites-available/dokuwiki /etc/nginx/sites-enabled/ 5、启动 nginx 运行命令
1 sudo service nginx start 6、安装 打开浏览器，输入 http://localhost/install.php ， 按照页面提示步骤进行安装。
7、禁止再次安装 重新修改 /etc/nginx/sites-available/dokuwiki ，
把
1 2 # 安装结束后，启用下面这句配置，防止重新安装。 #location ~ /(data/|conf/|bin/|inc/|install.php) { deny all; } 这句前的注释删除，然后重新加载 nginx
1 sudo service nginx reload   </content></entry><entry><title>Crowd 2.7.2 安装指南</title><url>/post/software/crowd_install/</url><categories><category>software</category></categories><tags><tag>atlassian</tag></tags><content type="html">  Crowd 2.7.2 安装指南 安装 Crowd 2.7.2 是最后的可以用 jira 的 extras-3.2 包进行破解的版本。 Crowd 2.8 以后的版本变更了部分接口。
与各系统集成 参考：
https://confluence.atlassian.com/crowd/adding-an-application-18579591.html SSO 单点登录无法生效 问题排查：
https://confluence.atlassian.com/crowd/troubleshooting-sso-with-crowd-131466214.html   </content></entry><entry><title>Confluence 6.3.4 安装指南 (Ubuntu 16.04)</title><url>/post/software/confluence_install/</url><categories><category>software</category></categories><tags><tag>atlassian</tag></tags><content type="html"><![CDATA[  Confluence 6.3.4 安装指南 (Ubuntu 16.04) 1. 下载 Confluence 6.3.4 安装包 1 wget https://www.atlassian.com/software/confluence/downloads/binary/atlassian-confluence-6.3.4-x64.bin 安装较低版本是为了可以使用 onlyoffice 的插件，该插件 1.1.0 版本只支持到 confluence 6.4。
2. 获取 Confluence 6.3.4 破解包 从附件中下载 经测试 atlassian-extras-decoder-v2-3.2.jar 可以使用在更高版本的 confluence 。 如 Confluence 6.10，使用的是 atlassian-extras-decoder-v2-3.4.1.jar，替换后同样可用。
3. 安装 mysql （若已安装则跳过） 安装 mysql :
1 sudo apt-get install mysql-server 在 mysql 命令行中运行下面命令:
1 2 3 4 5 6 7 8 -- 创建数据库： create database confluence character set utf8 collate utf8_bin; -- 添加用户并授权： grant all privileges on confluence.* to confluence@localhost identified by &#39;password&#39;; -- 刷新数据库权限： flush privileges; 4. 开始安装 运行命令：
1 sudo ./atlassian-confluence-6.3.4-x64.bin 然后按照提示一步步设置。
安装完成后，
默认 confluence 安装在 /opt/atlassian/confluence 默认数据存放在 /var/atlassian/application-data/confluence 默认端口 8090 (后续修改端口: ///opt/atlassian/confluence/conf/server.xml//) 安装完成后暂时不要启动 confluence 。
5. 进行破解 解压 atlassian-extras-decoder-v2-3.2.tgz 破解包，得到文件：
atlassian-extras-decoder-v2-3.2.jar (破解文件，替换同名文件) 下载 mysql connector 5.1.46 驱动：
1 wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.zip 解压得到
mysql-connector-java-5.1.46-bin.jar (mysql驱动) 把上述两个文件复制到 /opt/atlassian/confluence/confluence/WEB-INF/lib/ 目录中。
6. 初始化 confluence 1 service confluence start 启动 confluence , 打开页面 http://localhost:8090 ，进入系统安装页面。
第一步，选择自己设置，用于生产环境。 第二步，配置数据库，根据实际需求填写。（还支持postgresql, oracle, ms sql server） 第三步，输入许可证。 这里点击 “生成 JIRA 试用许可证” 链接，到官网申请一个试用许可证，再填到这里。 第四步，设置管理员账户。 （注意，mysql 需要加额外参数，示例如下： jdbc:mysql://localhost:3306/confluence?sessionVariables=tx_isolation=&lsquo;READ-COMMITTED&rsquo; 参数链接：https://confluence.atlassian.com/confkb/confluence-fails-to-start-and-throws-mysql-session-isolation-level-repeatable-read-is-no-longer-supported-error-241568536.html）
初始化完成。
由于之前已经替换了破解文件，这里在许可证界面看到的服务截止时间已经改得非常长，相当于不受试用时间限制了。
7. 使用 nginx 进行端口转发 参照官方文档： https://confluence.atlassian.com/confkb/how-to-use-nginx-to-proxy-requests-for-confluence-313459790.html https://confluence.atlassian.com/doc/running-confluence-behind-nginx-with-ssl-858772080.html   ]]></content></entry><entry><title>docker 部署 postgresql</title><url>/post/docker/app/postgres/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>postgresql</tag></tags><content type="html"><![CDATA[  docker 部署 postgresql docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 version: &#34;3.7&#34; services: db: image: postgres:alpine restart: always volumes: - db_data:/var/lib/postgresql/data # - ./init.sql:/docker-entrypoint-initdb.d/init.sql ports: - &#34;5432:5432&#34; # env_file: # - .env environment: # default user name: postgres # - POSTGRES_USER=postgres - POSTGRES_PASSWORD=123456 # - POSTGRES_DB=postgres - TZ=Asia/Shanghai healthcheck: test: [&#34;CMD-SHELL&#34;, &#34;pg_isready -U postgres&#34;] interval: 5m timeout: 5s retries: 3 # start_period: 1m adminer: image: adminer restart: always ports: - &#34;8080:8080&#34; volumes: db_data:   ]]></content></entry><entry><title>docker 部署 mysql</title><url>/post/docker/app/mysql/</url><categories><category>docker</category></categories><tags><tag>docker</tag><tag>mysql</tag><tag>mariadb</tag></tags><content type="html"><![CDATA[  docker 部署 mysql 运行 mysql
# 2019-01-07 修改： mysql 修改成 mariadb
1 2 3 4 5 docker run -itd --name mysql-test -e MYSQL_ROOT_PASSWORD=123456 mariadb # 如果需要docker外的程序连接，则暴露端口： docker run -itd --name mysql-test -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 mariadb # 如果需要把数据保存在外面： docker run -itd --name mysql-test -v /local/dir:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 mariadb 运行 phpmyadmin
1 docker run -itd --name phpmyadmin --link mysql-test:db -p 8080:80 phpmyadmin/phpmyadmin # 2019-03-22 增加：
使用 docker-compose 方式运行
docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: &#34;3&#34; services: db: image: mariadb volumes: - ./data:/var/lib/mysql ports: - &#34;3306:3306&#34; environment: - MYSQL_ROOT_PASSWORD=123456 phpmyadmin: image: phpmyadmin/phpmyadmin ports: - &#34;8080:80&#34; links: - db # 2019-10-30 修改： 使用 adminer 代替 phpmyadmin
docker-compose.yml 示例：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 version: &#34;3.7&#34; services: db: image: mariadb restart: always volumes: - db_data:/var/lib/mysql ports: - &#34;3306:3306&#34; environment: # default user name: root - MYSQL_ROOT_PASSWORD=123456 #- TZ=Asia/Shanghai adminer: image: adminer restart: always ports: - &#34;8080:8080&#34; # phpmyadmin: # image: phpmyadmin/phpmyadmin # restart: always # ports: # - &#34;8080:80&#34; # links: # - db volumes: db_data:   ]]></content></entry><entry><title>Maven 简介</title><url>/post/java/maven/</url><categories><category>java</category></categories><tags><tag>java</tag><tag>maven</tag></tags><content type="html">  Maven 简介 环境变量 只需要设置 PATH 即可。
Maven 3.5.0 之后的版本，会自动获取 M2_HOME 信息，不再需要设置环境变量。 详见 MNG-5607 和 Release Notes 若运行 mvn -v 能打印出 maven 的版本信息，则说明安装成功。
配置文件 全局配置文件位于 maven 安装目录下的 conf/settings.xml ， 用户级的配置文件位于 ${user.home}/.m2/settings.xml ， 用户级的配置文件需要自行创建。
大部分情况下，使用默认的配置文件足够了，一般修改配置文件的原因为： * 使用私有仓库 由于官方仓库服务器在国外，有时下载依赖包会比较慢；或者私有的包不想上传到公共仓库上，那么则可以搭建私有仓库。通过配置文件可以修改仓库服务器地址。 * 修改本地仓库的保存路径 下载的依赖包默认存放在 ${user.home}/.m2/repository 下，由于依赖包是全局共享，因此以后可能会占用大量的磁盘空间。可以通过修改配置文件来修改依赖包保存路径。
常用命令 1 2 3 4 mvn clean # 清除生成文件 mvn compile # 只编译。 可以用来快速验证编译错误。 mvn test # 编译并测试。 mvn package # 编译、测试、打包。 打包过程分几步： 资源文件处理、编译、测试、打包。 上面的后三个命令分别让 maven 的执行流程停止在后三个步骤中，可以从打印信息中看到打包步骤。
标准项目结构 1 2 3 4 5 6 7 8 9 10 ├── pom.xml # maven 配置文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。 ├── src │ ├── main # 主要代码目录 │ │ ├── java # java 源码，需要编译 │ │ ├── resources # 配置文件，不需要编译 │ │ └── webapp # 只针对 web 工程，存放 static 文件和模板文件。 │ └── test # 测试代码目录 │ ├── java │ └── resources └── target # 最终生成文件路径。不需要自己创建，构建的时候会自己生成。   </content></entry><entry><title>zenity 使用方法备忘</title><url>/post/linux/zenity/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>zenity</tag></tags><content type="html"><![CDATA[  zenity 使用方法备忘 zenity 可以帮助你使用脚本创建常用的 gtk+ 对话框。
1、使用日历控件
1 2 szDate=$(zenity --calendar --text &#34;Pick a day&#34; --title &#34;Medical Leave&#34; --day 13 --month 5 --year 2010); echo $szDate 2、创建一个Entry对话框
1 szAnswer=$(zenity --entry --text &#34;where are you?&#34; --entry-text &#34;at home&#34;); echo $szAnswer 3、创建一个错误对话框
1 zenity --error --text &#34;Installation failed! &#34; 4、创建一个Info对话框
1 zenity --info --text &#34;Join us at irc.freenode.net #lbe.&#34; 5、创建一个文件选择对话框
1 szSavePath=$(zenity --file-selection --save --confirm-overwrite);echo $szSavePath 6、创建一个通知对话框
1 zenity --notification --window-icon=update.png --text &#34;Please update your system.&#34; 7、创建一个进度对话框
1 gksudo lsof | tee &gt;(zenity --progress --pulsate) &gt;lsof.txt 8、创建一个question对话框
1 zenity --question --text &#34;Are you sure you want to shutdown?&#34;; echo $? 9、创建一个警告对话框
1 zenity --warning --text &#34;This will kill, are you sure?&#34;;echo $? 10、创建一个滑动scale对话框
1 2 ans=$(zenity --scale --text &#34;pick a number&#34; --min-value=2 --max-value=100 --value=2 --step 2);echo $ans 11、创建一个文本信息对话框
1 gksudo lsof | zenity --text-info --width 530 12、创建一个列表对话框
radiolist:
1 2 3 ans=$(zenity --list --text &#34;Is linux.byexamples.com helpful?&#34; --radiolist --column &#34;Pick&#34; --column &#34;Opinion&#34; TRUE Amazing FALSE Average FALSE &#34;Difficult to follow&#34; FALSE &#34;Not helpful&#34;); echo $ans checklist:
1 2 3 4 ans=$(zenity --list --text &#34;How linux.byexamples can be improved?&#34; --checklist --column &#34;Pick&#34; --column &#34;options&#34; TRUE &#34;More pictures&#34; TRUE &#34;More complete post&#34; FALSE &#34; Includes Installation guidelines&#34; FALSE &#34;Create a forum for question queries&#34; --separator=&#34;:&#34;); echo $ans   ]]></content></entry><entry><title>wget 用法备忘</title><url>/post/linux/wget/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>wget</tag></tags><content type="html">  wget 用法备忘 wget 常用命令 1 wget -b -c -o wget.log url 参数说明:
b: 后台下载 c: 支持断点续传 -o logfile: 下载日志   </content></entry><entry><title>使用 zenity 制作 shell 版提醒工具</title><url>/post/linux/zenity_reminder/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>zenity</tag></tags><content type="html"><![CDATA[  使用 zenity 制作 shell 版提醒工具 点击 这里 查看 zenity 的基本用法。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 #!/bin/bash # This will wait one second and then steal focus and make the Zenity dialog box always-on-top (aka. &#39;above&#39;). # 一秒后运行wmctrl，把zenity的窗口置顶，注意title要一致 (sleep 1 &amp;&amp; wmctrl -F -a &#34;take a rest :)&#34; -b add,above) &amp; # 显示提示框 # zenity --info --title=&#34;take a rest :)&#34; --width=800 --height=600 --text=&#34;休息时间到了，活动一下筋骨吧！&#34; # 显示时间进度条 # 提示文字要加#号 ( rest_time=120 for (i=1;i&lt;${rest_time};i++); do echo &#34;# 休息时间到了，活动一下筋骨吧！剩余时间 $(rest_time-i) s&#34; echo $(i*100/rest_time) sleep 1 done ) | zenity --progress \ --title=&#34;take a rest :)&#34; \ --width=800 \ --height=600 \ --percentage=0 \ --text=&#34;休息时间到了，活动一下筋骨吧！&#34;   ]]></content></entry><entry><title>cron 用法</title><url>/post/linux/cron/</url><categories><category>linux</category></categories><tags><tag>linux</tag><tag>cron</tag></tags><content type="html">  cron 用法 一、 cron 简介 crond 是 linux 下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与 windows 下的计划任务类似。
linux 默认会安装此服务工具，并自动启动 crond 进程。
Linux 下的任务调度分为两类，系统任务调度和用户任务调度。
1. 系统任务调度 系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。在 /etc 目录下有一个 crontab 文件，这个就是系统任务调度的配置文件。（尽量不要动该文件）
2. 用户任务调度 所有用户定义的 crontab 文件都被保存在 /var/spool/cron 目录中。其文件名与用户名一致。（管理员查看有哪些用户设置了 cron 任务，可以到该目录下查看）
二、 crond 服务 1 2 3 4 5 6 7 8 9 service crond start #启动服务 service crond stop #关闭服务 service crond restart #重启服务 service crond reload #重新载入配置 service crond status #查看服务状态 三、 crontab 命令 用户需要通过 crontab 命令来操作定时任务。
命令格式：
1 2 3 crontab [-u user] file crontab [-u user] [ -e | -l | -r ] -u user： 以某个用户来运行任务。此参数一般由 root 用户来使用。
file： file 是命令文件的名字,表示将 file 做为 crontab 的任务列表文件并载入 crontab 。如果在命令行中没有指定这个文件， crontab 命令将接受标准输入（键盘）上键入的命令，并将它们载入 crontab 。（键盘上的命令需要结束时按 ctrl+d ）
-e： 编辑某个用户的 crontab 文件内容。如果不指定用户，则表示编辑当前用户的 crontab 文件。
-l： 显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。
-r： 从 /var/spool/cron 目录中删除某个用户的 crontab 文件，如果不指定用户，则默认删除当前用户的 crontab 文件。
-i： 在删除用户的 …  </content></entry><entry><title>python 发送邮件示例</title><url>/post/python/send_email/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html"><![CDATA[  python 发送邮件示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 #!/usr/bin/python #-*- coding: utf-8 -*- import smtplib from email.mime.text import MIMEText from email.header import Header from email.utils import formataddr, formatdate def sendEmail(): smtpHost = &#34;smtp.mxhichina.com&#34; #smtpPort = 25 sslPort = 465 username = &#34;abc@example.com&#34; password = &#34;123456&#34; fromTuple = (u&#34;发送用户&#34;, &#34;abc@example.com&#34;) toTuples = [(u&#34;接收用户1&#34;, &#34;111@example.com&#34;), (u&#34;接收用户2&#34;,&#34;222@example.com&#34;)] encoding = &#39;utf-8&#39; fromAddr = fromTuple[1] fromHeader = formataddr((Header(fromTuple[0], encoding).encode(), fromTuple[1].encode(encoding))) toAddr = [] toHeader = [] for addrPair in toTuples: toAddr.append(addrPair[1]) h = formataddr((Header(addrPair[0], encoding).encode(), addrPair[1].encode(encoding))) toHeader.append(h) msg = MIMEText(u&#34;这里是正文。&#34;, &#34;plain&#34;, encoding) msg[&#39;Subject&#39;] = Header(u&#39;这是主题&#39;, encoding).encode() msg[&#39;From&#39;] = fromHeader msg[&#39;To&#39;] = &#39;,&#39;.join(toHeader) msg[&#39;Date&#39;] = formatdate() #print (toAddr) #print (toHeader) #print (msg.as_string()) #三种方式： 明文/TLS/SSL #1.普通方式，通信过程不加密 (不推荐) #smtp = smtplib.SMTP(smtpHost, smtpPort) #smtp.ehlo() #smtp.login(username, password) #2.TLS加密方式，正常smtp端口，通信过程加密 #smtp = smtplib.SMTP(smtpHost, smtpPort) #smtp.ehlo() #smtp.starttls() #smtp.ehlo() #smtp.login(username, password) #3.SSL加密方式，使用ssl端口，通信过程加密 (推荐) smtp = smtplib.SMTP_SSL(smtpHost, sslPort, &#34;example.com&#34;) smtp.set_debuglevel(True) smtp.login(username, password) try: smtp.sendmail(fromAddr, toAddr, msg.as_string()) finally: smtp.quit() if __name__ == &#39;__main__&#39;: sendEmail() 2020/02/07 增加 python3 格式：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 import smtplib from email.mime.text import MIMEText from email.header import Header from email.utils import formataddr, formatdate def sendEmail(): smtpHost = &#34;smtp.mxhichina.com&#34; #smtpPort = 25 sslPort = 465 username = &#34;abc@example.com&#34; password = &#34;123456&#34; fromAddr = (&#34;发送用户&#34;, &#34;abc@example.com&#34;) toAddr = [(&#34;接收用户1&#34;, &#34;111@example.com&#34;), (&#34;接收用户2&#34;,&#34;222@example.com&#34;)] encoding = &#39;utf-8&#39; msg = MIMEText(&#34;这里是正文。&#34;, &#34;plain&#34;, encoding) msg[&#39;Subject&#39;] = Header(&#39;这是主题&#39;, encoding) msg[&#39;From&#39;] = formataddr(fromAddr) msg[&#39;To&#39;] = &#39;,&#39;.join([formataddr(addr) for addr in toAddr]) msg[&#39;Date&#39;] = formatdate() #print (msg.as_string()) #三种方式： 明文/TLS/SSL #1.普通方式，通信过程不加密 (不推荐) #smtp = smtplib.SMTP(smtpHost, smtpPort) #smtp.ehlo() #smtp.login(username, password) #2.TLS加密方式，正常smtp端口，通信过程加密 #smtp = smtplib.SMTP(smtpHost, smtpPort) #smtp.ehlo() #smtp.starttls() #smtp.ehlo() #smtp.login(username, password) #3.SSL加密方式，使用ssl端口，通信过程加密 (推荐) smtp = smtplib.SMTP_SSL(smtpHost, sslPort, &#34;example.com&#34;) #smtp.set_debuglevel(True) smtp.login(username, password) try: smtp.sendmail(fromAddr[1], [addr[1] for addr in toAddr], msg.as_string()) finally: smtp.quit() if __name__ == &#39;__main__&#39;: sendEmail()   ]]></content></entry><entry><title>Css 制作方形相框，并让图片居中</title><url>/post/html/css_square_container/</url><categories><category>html</category></categories><tags><tag>html</tag><tag>css</tag></tags><content type="html"><![CDATA[  Css 制作方形相框，并让图片居中 css container css 方案一：
1 2 3 4 5 6 7 8 9 10 .square-container { position: relative; width: 100%; padding-bottom: 100%; overflow: hidden; background-color: #e9eef1; border: 1px solid #aaa; border-radius: 4px; box-shadow: 3px 3px 3px #ccc; } container css 方案二： （更优，可以解决 min-height 无效的问题）
1 2 3 4 5 6 7 8 9 10 11 12 13 14 .square-container { position: relative; width: 100%; overflow: hidden; background-color: #e9eef1; border: 1px solid #aaa; border-radius: 4px; box-shadow: 3px 3px 3px #ccc; } .square-container:after { content: &#39;&#39;; display: block; margin-top: 100%; } 原理： padding 和 margin 的百分比是以容器的宽度为基数的，因此 padding-bottom 和 margin-top 的 100% 大小和宽度一致。
item css:
1 2 3 4 5 6 7 8 9 10 .square-container-item { position: absolute; max-width: 100%; max-height: 100%; left: 0; right: 0; top: 0; bottom: 0; margin: auto; } html 1 2 3 &lt;div class=&#34;square-container&#34;&gt; &lt;img class=&#34;square-container-item&#34; src=&#34;img.jpg&#34;&gt; &lt;/div&gt;   ]]></content></entry><entry><title>Css 元素居中</title><url>/post/html/css_align_center/</url><categories><category>html</category></categories><tags><tag>html</tag><tag>css</tag></tags><content type="html">  Css 元素居中 relative 元素水平居中 居中的首要条件就是指定宽度。使用以下 css：
1 margin: 0, auto; relative 元素绝对居中 待补充。
absolute 元素绝对居中 方案一： absolutea 元素一般都会指定了宽高，使用以下 css 可以绝对居中：
1 2 3 4 5 6 position: absolute; left: 0; right: 0; top: 0; bottom: 0; margin: auto; 方案二： 据说此方案在某些情况下会有bug，尽量少用。
1 2 3 4 position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%);   </content></entry><entry><title>纯 css 制作 switch button</title><url>/post/html/css_switch_button/</url><categories><category>html</category></categories><tags><tag>html</tag><tag>css</tag></tags><content type="html"><![CDATA[  纯 Css 制作 switch button css 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 /* The switch - the box around the slider */ .switch-button { position: relative; display: inline-block; width: 48px; height: 24px; } /* Hide default HTML checkbox */ .switch-button input { display:none; } /* The slider */ .switch-button .slider { position: absolute; cursor: pointer; top: 0; left: 0; right: 0; bottom: 0; background-color: #aaa; -webkit-transition: .4s; transition: .4s; } .switch-button .slider:before { position: absolute; content: &#34;&#34;; height: 80%; width: 40%; left: 10%; bottom: 10%; background-color: white; -webkit-transition: .4s; transition: .4s; } .switch-button input:checked + .slider { background-color: #2196F3; } .switch-button input:focus + .slider { box-shadow: 0 0 1px #2196F3; } .switch-button input:checked + .slider:before { -webkit-transform: translateX(100%); -ms-transform: translateX(100%); transform: translateX(100%); } .switch-button input:checked[disabled] + .slider { background-color: #96cbf5; cursor: not-allowed; } .switch-button input[disabled] + .slider { background-color: #ccc; cursor: not-allowed; } /* Rounded sliders */ .switch-button .slider.round { border-radius: 30px; } .switch-button .slider.round:before { border-radius: 50%; } 使用方式 使用如下 html 代码结构，可以得到一个直角的 switch button
1 2 3 4 &lt;label class=&#34;switch-button&#34;&gt; &lt;input type=&#34;checkbox&#34;&gt; &lt;span class=&#34;slider&#34;&gt;&lt;/span&gt; &lt;/label&gt; 如果需要圆角的 switch button ， 则在 slider 中增加 round 类
1 2 3 4 &lt;label class=&#34;switch-button&#34;&gt; &lt;input type=&#34;checkbox&#34;&gt; &lt;span class=&#34;slider round&#34;&gt;&lt;/span&gt; &lt;/label&gt;   ]]></content></entry></search>